{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d30f95a4-3c22-4873-8710-cac499454d4d",
   "metadata": {},
   "source": [
    "# Informer Autoformer DLinear Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75c9a6-0cba-4bd8-8ab5-aedebe169d9e",
   "metadata": {},
   "source": [
    "The aim of this code is to run the experiment for Informer Autoformer and DLinear. The execution happens by calling run.py with the necessary arguments. Each model is run 2 times to ensure reliability of the results. The data is scaled and splitted automatically within the process. Then the results are processed in the following way in the below code.\n",
    "1. Capture the ouput of the scripts.\n",
    "2. Filter the output to the path where the results for each model is saved.\n",
    "3. Open the metrics.npy under this path and extract the mae and mse for each of the two model repetitions and calculate the overall mean. The final relevant mean mae and mse results are under the file transformer_results_averaged_over_iterations.txt.\n",
    "4. Informer\n",
    "5. Autoformer\n",
    "6. DLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56aa5a24-b1ed-4e08-aad2-498e92e722a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from statistics import mean\n",
    "from statistics import stdev\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "085878bb-7935-427a-a69e-890e56bacadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_directory = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "script_path = os.path.join(parent_directory, \"run.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51550301-bac6-423c-9509-86a4038ec412",
   "metadata": {},
   "source": [
    "## 1. Capture the output of the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01fe3dd2-700a-47a2-912c-198ac9b91975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_and_capture_script_output(script_path, script_arguments):\n",
    "    try:\n",
    "        # Execute the script and capture the output\n",
    "        command = [\"python\", \"-u\", script_path] + script_arguments\n",
    "        output = subprocess.check_output(command, universal_newlines=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        output = e.output  # If there's an error, capture the error message\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50e377f-b578-4838-bb09-91b5720d9af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_settings_prints(output_lines):\n",
    "    prefix = \"testing : long_term_forecast_\"  # Hardcoded prefix to extract\n",
    "    return [line.strip() for line in output_lines if prefix in line]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ad27a-6936-4533-a6de-e5dbb4aeecd7",
   "metadata": {},
   "source": [
    "## 2. Extract MAE and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a3ed15d-f48b-4980-9c78-32a5fb30cfdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pattern_matching(setting_prints):\n",
    "\n",
    "    # Now there are the prints related to the \"testing : long_term_forecast_\"\n",
    "    for i in range (len(settings_prints)):\n",
    "        input_string = settings_prints[i]\n",
    "        # Define a regular expression pattern to match the desired part\n",
    "        pattern = r\"testing : (long_term_forecast_[^<]+)<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\"\n",
    "\n",
    "        # Use re.search to find the match\n",
    "        match = re.search(pattern, input_string)\n",
    "        # Extract the matched part\n",
    "        if match:\n",
    "            extracted_part = match.group(1)\n",
    "            settings_prints[i] = extracted_part\n",
    "            print(\"Extracted Part:\", settings_prints[i])\n",
    "        else:\n",
    "            print(\"No match found.\")\n",
    "            print(\"Setting Print:\", setting_print)\n",
    "    return settings_prints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad304e-3071-4c58-b0bb-7e8a70d551da",
   "metadata": {},
   "source": [
    "## 3. Average MAE and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ca35ea-94a3-42d9-afe3-6516c106719b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize_results(matched_patterns):\n",
    "    mse=[]\n",
    "    mae=[]\n",
    "    for i in range(len(matched_patterns)):\n",
    "        metrics = np.load('./results/'+matched_patterns[i]+'/metrics.npy')\n",
    "        mse.append(metrics[1])\n",
    "        mae.append(metrics[0])\n",
    "    np_mse=np.array(mse)\n",
    "    np_mae=np.array(mae)\n",
    "    \n",
    "    std_mse=np.std(np_mse)\n",
    "    std_mae=np.std(np_mae)\n",
    "    \n",
    "    overall_mse=mean(mse)\n",
    "    overall_mae=mean(mae)\n",
    "    # Create a text file if it doesn't exist or open it for writing\n",
    "    file_path = \"transformer_results_averaged_over_iterations.txt\"  \n",
    "    with open(file_path, \"a\") as file:\n",
    "        file.write(\"Settings Prints: {}\\n\".format(settings_prints[0]))\n",
    "        file.write(\"Overall MSE: {:.6f}\\n\".format(overall_mse))\n",
    "        file.write(\"Overall MAE: {:.6f}\\n\".format(overall_mae))\n",
    "        file.write(\"Std. dev. MSE: {:.6f}\\n\".format(std_mse))\n",
    "        file.write(\"Std. dev. MSE: {:.6f}\\n\".format(std_mae))\n",
    "    print(\"Results saved to:\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6cef1d-d078-4231-97ee-67476ee996e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Autoformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06458abb-2ddb-46aa-8d04-304a566b8b77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This calls the run.py with the relevant parameters for the multivariate setting.\n",
    "# List of data paths and prediction lengths for the grid search\n",
    "data_paths = [\"df_all_columns.csv\", \"df_most_important_columns.csv\", \"df_only_generation_columns.csv\"]\n",
    "prediction_lengths = [\"24\", \"48\", \"96\", \"192\"]\n",
    "for data_path in data_paths:\n",
    "    full_data_path = \"../../../01_datasets/\" + data_path\n",
    "    df = pd.read_csv(full_data_path)\n",
    "    num_columns = len(df.columns)\n",
    "    for pred_len in prediction_lengths:\n",
    "        # Define the script arguments as a list\n",
    "        model_id = f\"_{pred_len}_{data_path.replace('.csv', '')}\"  # Create the model_id\n",
    "        script_arguments = [\n",
    "            \"--task_name\", \"long_term_forecast\",\n",
    "            \"--is_training\", \"1\", #True\n",
    "            \"--root_path\", \"../../../01_datasets/\",\n",
    "            \"--data_path\", data_path,\n",
    "            \"--model_id\", model_id,\n",
    "            \"--model\", \"Autoformer\",\n",
    "            \"--data\", \"custom\", # This ensures a 70%,10%,20% train,val,test split see data_provider/data_loader.py\n",
    "            \"--features\", \"M\", # Multivariate\n",
    "            \"--seq_len\", \"96\",\n",
    "            \"--label_len\", \"48\",\n",
    "            \"--pred_len\", pred_len,\n",
    "            \"--e_layers\", \"2\", # Hyperparameters as in original model\n",
    "            \"--d_layers\", \"5\",\n",
    "            \"--factor\", \"5\",\n",
    "            \"--enc_in\", str((num_columns)-1),\n",
    "            \"--dec_in\", str((num_columns)-1),\n",
    "            \"--c_out\", str((num_columns)-1),\n",
    "            \"--des\", \"Exp\",\n",
    "            \"--itr\", \"2\"\n",
    "        ]\n",
    "\n",
    "        script_output = run_and_capture_script_output(script_path, script_arguments)\n",
    "\n",
    "        print(\"Captured Output:\")\n",
    "        print(script_output)\n",
    "\n",
    "        # Extract and save the prints related to the settings variable\n",
    "        settings_prints = extract_settings_prints(script_output.splitlines())\n",
    "\n",
    "        matched_patterns = pattern_matching(settings_prints)\n",
    "\n",
    "        summarize_results(matched_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b7774-b26a-4361-8706-1167bb51b661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This calls the run.py with the relevant parameters for the univariate setting.\n",
    "# List of columns and prediction lengths for the grid search\n",
    "columns = [\"DE_load_actual_entsoe_transparency\", \"DE_solar_generation_actual\", \"DE_wind_generation_actual\"]\n",
    "prediction_lengths = [\"24\", \"48\", \"96\", \"192\"]\n",
    "for column in columns:\n",
    "    for pred_len in prediction_lengths:\n",
    "        # Define the script arguments as a list\n",
    "        model_id = f\"_{pred_len}_{column}\"  # Create the model_id\n",
    "        script_arguments = [\n",
    "            \"--task_name\", \"long_term_forecast\",\n",
    "            \"--is_training\", \"1\",\n",
    "            \"--root_path\", \"../../../01_datasets/\",\n",
    "            \"--data_path\", \"df_most_important_columns.csv\",\n",
    "            \"--model_id\", model_id,\n",
    "            \"--model\", \"Autoformer\",\n",
    "            \"--data\", \"custom\",\n",
    "            \"--features\", \"S\",\n",
    "            \"--target\", str(column),\n",
    "            \"--seq_len\", \"96\",\n",
    "            \"--label_len\", \"48\",\n",
    "            \"--pred_len\", pred_len,\n",
    "            \"--e_layers\", \"2\",\n",
    "            \"--d_layers\", \"5\",\n",
    "            \"--factor\", \"5\",\n",
    "            \"--enc_in\", \"1\",\n",
    "            \"--dec_in\", \"1\",\n",
    "            \"--c_out\", \"1\",\n",
    "            \"--des\", \"Exp\",\n",
    "            \"--itr\", \"2\"\n",
    "        ]\n",
    "\n",
    "        script_output = run_and_capture_script_output(script_path, script_arguments)\n",
    "\n",
    "        print(\"Captured Output:\")\n",
    "        print(script_output)\n",
    "\n",
    "        # Extract and save the prints related to the settings variable\n",
    "        settings_prints = extract_settings_prints(script_output.splitlines())\n",
    "\n",
    "        matched_patterns = pattern_matching(settings_prints)\n",
    "\n",
    "        summarize_results(matched_patterns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aad334e-b2e3-4acb-9615-549d83836a73",
   "metadata": {},
   "source": [
    "## 5. Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed868491-b511-4406-bfef-e690a6479d76",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=29, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_all_columns.csv', dec_in=29, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=29, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_24_df_all_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=24, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_df_all_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.4944406\n",
      "\tspeed: 0.1091s/iter; left time: 1029.7127s\n",
      "\titers: 200, epoch: 1 | loss: 0.3713011\n",
      "\tspeed: 0.0999s/iter; left time: 932.9840s\n",
      "\titers: 300, epoch: 1 | loss: 0.3993874\n",
      "\tspeed: 0.0968s/iter; left time: 894.6295s\n",
      "\titers: 400, epoch: 1 | loss: 0.3028048\n",
      "\tspeed: 0.1081s/iter; left time: 987.7886s\n",
      "\titers: 500, epoch: 1 | loss: 0.3033108\n",
      "\tspeed: 0.0947s/iter; left time: 856.5810s\n",
      "\titers: 600, epoch: 1 | loss: 0.2682946\n",
      "\tspeed: 0.0953s/iter; left time: 852.2127s\n",
      "\titers: 700, epoch: 1 | loss: 0.2905912\n",
      "\tspeed: 0.0925s/iter; left time: 818.1051s\n",
      "\titers: 800, epoch: 1 | loss: 0.2655034\n",
      "\tspeed: 0.0914s/iter; left time: 798.5001s\n",
      "\titers: 900, epoch: 1 | loss: 0.2469680\n",
      "\tspeed: 0.0971s/iter; left time: 838.7118s\n",
      "Epoch: 1 cost time: 93.599356174469\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.3620797 Vali Loss: 0.4938100 Test Loss: 0.9210697\n",
      "Validation loss decreased (inf --> 0.493810).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3301416\n",
      "\tspeed: 1.7302s/iter; left time: 14684.4415s\n",
      "\titers: 200, epoch: 2 | loss: 0.2684842\n",
      "\tspeed: 0.1012s/iter; left time: 848.6412s\n",
      "\titers: 300, epoch: 2 | loss: 0.2220307\n",
      "\tspeed: 0.1015s/iter; left time: 841.5141s\n",
      "\titers: 400, epoch: 2 | loss: 0.2376742\n",
      "\tspeed: 0.1010s/iter; left time: 826.8739s\n",
      "\titers: 500, epoch: 2 | loss: 0.2424951\n",
      "\tspeed: 0.0931s/iter; left time: 752.9195s\n",
      "\titers: 600, epoch: 2 | loss: 0.2716434\n",
      "\tspeed: 0.0916s/iter; left time: 731.9681s\n",
      "\titers: 700, epoch: 2 | loss: 0.2923169\n",
      "\tspeed: 0.0949s/iter; left time: 748.1386s\n",
      "\titers: 800, epoch: 2 | loss: 0.2110031\n",
      "\tspeed: 0.0910s/iter; left time: 708.8914s\n",
      "\titers: 900, epoch: 2 | loss: 0.1977397\n",
      "\tspeed: 0.0980s/iter; left time: 753.4197s\n",
      "Epoch: 2 cost time: 92.8695502281189\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.2387938 Vali Loss: 0.6234041 Test Loss: 1.3871071\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2437251\n",
      "\tspeed: 1.7350s/iter; left time: 13069.7465s\n",
      "\titers: 200, epoch: 3 | loss: 0.2221469\n",
      "\tspeed: 0.1044s/iter; left time: 775.8955s\n",
      "\titers: 300, epoch: 3 | loss: 0.1514663\n",
      "\tspeed: 0.1110s/iter; left time: 814.0614s\n",
      "\titers: 400, epoch: 3 | loss: 0.1915925\n",
      "\tspeed: 0.0995s/iter; left time: 719.3301s\n",
      "\titers: 500, epoch: 3 | loss: 0.1434785\n",
      "\tspeed: 0.1070s/iter; left time: 763.1151s\n",
      "\titers: 600, epoch: 3 | loss: 0.1796873\n",
      "\tspeed: 0.0954s/iter; left time: 670.6640s\n",
      "\titers: 700, epoch: 3 | loss: 0.1799372\n",
      "\tspeed: 0.0929s/iter; left time: 644.0187s\n",
      "\titers: 800, epoch: 3 | loss: 0.1833301\n",
      "\tspeed: 0.0904s/iter; left time: 617.6855s\n",
      "\titers: 900, epoch: 3 | loss: 0.1803981\n",
      "\tspeed: 0.0922s/iter; left time: 621.0700s\n",
      "Epoch: 3 cost time: 93.85294890403748\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.1821282 Vali Loss: 0.6607585 Test Loss: 1.4256800\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1689308\n",
      "\tspeed: 1.7036s/iter; left time: 11207.7494s\n",
      "\titers: 200, epoch: 4 | loss: 0.1331835\n",
      "\tspeed: 0.0920s/iter; left time: 596.1943s\n",
      "\titers: 300, epoch: 4 | loss: 0.1449822\n",
      "\tspeed: 0.0932s/iter; left time: 594.4601s\n",
      "\titers: 400, epoch: 4 | loss: 0.1732228\n",
      "\tspeed: 0.0955s/iter; left time: 599.9167s\n",
      "\titers: 500, epoch: 4 | loss: 0.1212347\n",
      "\tspeed: 0.0924s/iter; left time: 570.8665s\n",
      "\titers: 600, epoch: 4 | loss: 0.1460537\n",
      "\tspeed: 0.0934s/iter; left time: 567.8301s\n",
      "\titers: 700, epoch: 4 | loss: 0.1323018\n",
      "\tspeed: 0.0926s/iter; left time: 553.6942s\n",
      "\titers: 800, epoch: 4 | loss: 0.1391273\n",
      "\tspeed: 0.0920s/iter; left time: 540.8230s\n",
      "\titers: 900, epoch: 4 | loss: 0.1393117\n",
      "\tspeed: 0.0909s/iter; left time: 525.4137s\n",
      "Epoch: 4 cost time: 88.6630311012268\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.1520746 Vali Loss: 0.6242080 Test Loss: 1.2988878\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_df_all_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 29) (8735, 1, 24, 29)\n",
      "test shape: (8735, 24, 29) (8735, 24, 29)\n",
      "mse:0.9210613369941711, mae:0.6809441447257996\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_df_all_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.5299371\n",
      "\tspeed: 0.1133s/iter; left time: 1069.5884s\n",
      "\titers: 200, epoch: 1 | loss: 0.3820197\n",
      "\tspeed: 0.0850s/iter; left time: 793.6229s\n",
      "\titers: 300, epoch: 1 | loss: 0.3751996\n",
      "\tspeed: 0.1095s/iter; left time: 1011.6824s\n",
      "\titers: 400, epoch: 1 | loss: 0.3253911\n",
      "\tspeed: 0.1088s/iter; left time: 994.9253s\n",
      "\titers: 500, epoch: 1 | loss: 0.2565869\n",
      "\tspeed: 0.1033s/iter; left time: 933.9469s\n",
      "\titers: 600, epoch: 1 | loss: 0.4111024\n",
      "\tspeed: 0.1032s/iter; left time: 922.7498s\n",
      "\titers: 700, epoch: 1 | loss: 0.2712270\n",
      "\tspeed: 0.0987s/iter; left time: 872.7870s\n",
      "\titers: 800, epoch: 1 | loss: 0.2706424\n",
      "\tspeed: 0.1005s/iter; left time: 878.6672s\n",
      "\titers: 900, epoch: 1 | loss: 0.2526707\n",
      "\tspeed: 0.0898s/iter; left time: 775.6490s\n",
      "Epoch: 1 cost time: 97.02409386634827\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.3575931 Vali Loss: 0.5037190 Test Loss: 1.0017285\n",
      "Validation loss decreased (inf --> 0.503719).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2780028\n",
      "\tspeed: 1.7613s/iter; left time: 14947.8911s\n",
      "\titers: 200, epoch: 2 | loss: 0.2519660\n",
      "\tspeed: 0.0925s/iter; left time: 775.6756s\n",
      "\titers: 300, epoch: 2 | loss: 0.2414421\n",
      "\tspeed: 0.0896s/iter; left time: 742.1908s\n",
      "\titers: 400, epoch: 2 | loss: 0.2737043\n",
      "\tspeed: 0.0925s/iter; left time: 757.4643s\n",
      "\titers: 500, epoch: 2 | loss: 0.2280115\n",
      "\tspeed: 0.0916s/iter; left time: 740.8311s\n",
      "\titers: 600, epoch: 2 | loss: 0.1967751\n",
      "\tspeed: 0.0903s/iter; left time: 721.1081s\n",
      "\titers: 700, epoch: 2 | loss: 0.2478074\n",
      "\tspeed: 0.0791s/iter; left time: 624.0064s\n",
      "\titers: 800, epoch: 2 | loss: 0.1948644\n",
      "\tspeed: 0.1025s/iter; left time: 798.5106s\n",
      "\titers: 900, epoch: 2 | loss: 0.1812815\n",
      "\tspeed: 0.1068s/iter; left time: 820.6674s\n",
      "Epoch: 2 cost time: 89.88922476768494\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.2385016 Vali Loss: 0.5606648 Test Loss: 1.1883529\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1981573\n",
      "\tspeed: 1.7464s/iter; left time: 13155.8988s\n",
      "\titers: 200, epoch: 3 | loss: 0.1567013\n",
      "\tspeed: 0.0935s/iter; left time: 695.0765s\n",
      "\titers: 300, epoch: 3 | loss: 0.2108435\n",
      "\tspeed: 0.0937s/iter; left time: 686.8623s\n",
      "\titers: 400, epoch: 3 | loss: 0.1552967\n",
      "\tspeed: 0.0973s/iter; left time: 703.7810s\n",
      "\titers: 500, epoch: 3 | loss: 0.1634502\n",
      "\tspeed: 0.0974s/iter; left time: 694.4186s\n",
      "\titers: 600, epoch: 3 | loss: 0.1716579\n",
      "\tspeed: 0.0937s/iter; left time: 659.0694s\n",
      "\titers: 700, epoch: 3 | loss: 0.1578904\n",
      "\tspeed: 0.0955s/iter; left time: 661.9818s\n",
      "\titers: 800, epoch: 3 | loss: 0.1628588\n",
      "\tspeed: 0.0813s/iter; left time: 555.5390s\n",
      "\titers: 900, epoch: 3 | loss: 0.2246506\n",
      "\tspeed: 0.0916s/iter; left time: 616.8457s\n",
      "Epoch: 3 cost time: 90.14441990852356\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.1856347 Vali Loss: 0.5609279 Test Loss: 1.1297283\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1505482\n",
      "\tspeed: 1.7431s/iter; left time: 11467.5684s\n",
      "\titers: 200, epoch: 4 | loss: 0.1560417\n",
      "\tspeed: 0.1012s/iter; left time: 655.9002s\n",
      "\titers: 300, epoch: 4 | loss: 0.1492640\n",
      "\tspeed: 0.1092s/iter; left time: 696.8884s\n",
      "\titers: 400, epoch: 4 | loss: 0.1497181\n",
      "\tspeed: 0.1076s/iter; left time: 675.8983s\n",
      "\titers: 500, epoch: 4 | loss: 0.1443946\n",
      "\tspeed: 0.1017s/iter; left time: 628.4928s\n",
      "\titers: 600, epoch: 4 | loss: 0.1426338\n",
      "\tspeed: 0.1095s/iter; left time: 665.3925s\n",
      "\titers: 700, epoch: 4 | loss: 0.1657497\n",
      "\tspeed: 0.1030s/iter; left time: 616.0851s\n",
      "\titers: 800, epoch: 4 | loss: 0.1270515\n",
      "\tspeed: 0.0969s/iter; left time: 569.4804s\n",
      "\titers: 900, epoch: 4 | loss: 0.1500818\n",
      "\tspeed: 0.1017s/iter; left time: 587.9073s\n",
      "Epoch: 4 cost time: 99.35704231262207\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.1562787 Vali Loss: 0.5561346 Test Loss: 1.0902129\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_df_all_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 29) (8735, 1, 24, 29)\n",
      "test shape: (8735, 24, 29) (8735, 24, 29)\n",
      "mse:1.0013861656188965, mae:0.7042198181152344\n",
      "\n",
      "Extracted Part: long_term_forecast__24_df_all_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__24_df_all_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=29, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_all_columns.csv', dec_in=29, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=29, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_48_df_all_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=48, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_df_all_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.5879489\n",
      "\tspeed: 0.1248s/iter; left time: 1177.3587s\n",
      "\titers: 200, epoch: 1 | loss: 0.4654273\n",
      "\tspeed: 0.1063s/iter; left time: 991.9053s\n",
      "\titers: 300, epoch: 1 | loss: 0.3704866\n",
      "\tspeed: 0.1008s/iter; left time: 930.6917s\n",
      "\titers: 400, epoch: 1 | loss: 0.3633068\n",
      "\tspeed: 0.1066s/iter; left time: 973.4956s\n",
      "\titers: 500, epoch: 1 | loss: 0.4060717\n",
      "\tspeed: 0.1056s/iter; left time: 953.9332s\n",
      "\titers: 600, epoch: 1 | loss: 0.3667853\n",
      "\tspeed: 0.0925s/iter; left time: 825.9533s\n",
      "\titers: 700, epoch: 1 | loss: 0.3596174\n",
      "\tspeed: 0.0832s/iter; left time: 734.8515s\n",
      "\titers: 800, epoch: 1 | loss: 0.3107867\n",
      "\tspeed: 0.0903s/iter; left time: 788.6553s\n",
      "\titers: 900, epoch: 1 | loss: 0.2874934\n",
      "\tspeed: 0.0860s/iter; left time: 742.1660s\n",
      "Epoch: 1 cost time: 94.2269492149353\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.4321806 Vali Loss: 0.6328138 Test Loss: 1.2140670\n",
      "Validation loss decreased (inf --> 0.632814).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3765093\n",
      "\tspeed: 1.5607s/iter; left time: 13231.3575s\n",
      "\titers: 200, epoch: 2 | loss: 0.2587478\n",
      "\tspeed: 0.1078s/iter; left time: 903.0149s\n",
      "\titers: 300, epoch: 2 | loss: 0.2909568\n",
      "\tspeed: 0.1101s/iter; left time: 911.7831s\n",
      "\titers: 400, epoch: 2 | loss: 0.3189633\n",
      "\tspeed: 0.1065s/iter; left time: 870.8708s\n",
      "\titers: 500, epoch: 2 | loss: 0.2965091\n",
      "\tspeed: 0.0992s/iter; left time: 800.9441s\n",
      "\titers: 600, epoch: 2 | loss: 0.3518738\n",
      "\tspeed: 0.1040s/iter; left time: 829.6443s\n",
      "\titers: 700, epoch: 2 | loss: 0.2965907\n",
      "\tspeed: 0.1001s/iter; left time: 788.4115s\n",
      "\titers: 800, epoch: 2 | loss: 0.2411366\n",
      "\tspeed: 0.1030s/iter; left time: 801.5081s\n",
      "\titers: 900, epoch: 2 | loss: 0.2841355\n",
      "\tspeed: 0.1030s/iter; left time: 791.2027s\n",
      "Epoch: 2 cost time: 100.31309580802917\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.2937690 Vali Loss: 0.7419996 Test Loss: 1.5409489\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2248790\n",
      "\tspeed: 1.7449s/iter; left time: 13130.6935s\n",
      "\titers: 200, epoch: 3 | loss: 0.2557073\n",
      "\tspeed: 0.1079s/iter; left time: 800.8335s\n",
      "\titers: 300, epoch: 3 | loss: 0.2358596\n",
      "\tspeed: 0.1001s/iter; left time: 732.9311s\n",
      "\titers: 400, epoch: 3 | loss: 0.2079378\n",
      "\tspeed: 0.0865s/iter; left time: 624.9288s\n",
      "\titers: 500, epoch: 3 | loss: 0.2229723\n",
      "\tspeed: 0.0906s/iter; left time: 645.2208s\n",
      "\titers: 600, epoch: 3 | loss: 0.2047917\n",
      "\tspeed: 0.0926s/iter; left time: 650.1751s\n",
      "\titers: 700, epoch: 3 | loss: 0.2437487\n",
      "\tspeed: 0.0924s/iter; left time: 639.9168s\n",
      "\titers: 800, epoch: 3 | loss: 0.2553310\n",
      "\tspeed: 0.0938s/iter; left time: 640.2914s\n",
      "\titers: 900, epoch: 3 | loss: 0.2195072\n",
      "\tspeed: 0.0933s/iter; left time: 627.1721s\n",
      "Epoch: 3 cost time: 91.33136916160583\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.2257411 Vali Loss: 0.8567209 Test Loss: 1.9016155\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2207459\n",
      "\tspeed: 1.7629s/iter; left time: 11585.7798s\n",
      "\titers: 200, epoch: 4 | loss: 0.1953176\n",
      "\tspeed: 0.0993s/iter; left time: 642.7935s\n",
      "\titers: 300, epoch: 4 | loss: 0.1837141\n",
      "\tspeed: 0.1032s/iter; left time: 657.5932s\n",
      "\titers: 400, epoch: 4 | loss: 0.2161610\n",
      "\tspeed: 0.1120s/iter; left time: 702.6287s\n",
      "\titers: 500, epoch: 4 | loss: 0.1983631\n",
      "\tspeed: 0.1008s/iter; left time: 622.3233s\n",
      "\titers: 600, epoch: 4 | loss: 0.2134879\n",
      "\tspeed: 0.1010s/iter; left time: 613.0572s\n",
      "\titers: 700, epoch: 4 | loss: 0.1603798\n",
      "\tspeed: 0.1007s/iter; left time: 601.2335s\n",
      "\titers: 800, epoch: 4 | loss: 0.1820202\n",
      "\tspeed: 0.1037s/iter; left time: 608.8137s\n",
      "\titers: 900, epoch: 4 | loss: 0.1947780\n",
      "\tspeed: 0.1039s/iter; left time: 599.5322s\n",
      "Epoch: 4 cost time: 99.3484365940094\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.1931523 Vali Loss: 0.8732842 Test Loss: 1.8284699\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_df_all_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 29) (8711, 1, 48, 29)\n",
      "test shape: (8711, 48, 29) (8711, 48, 29)\n",
      "mse:1.213977575302124, mae:0.7810347080230713\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_df_all_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.6062679\n",
      "\tspeed: 0.1023s/iter; left time: 965.1438s\n",
      "\titers: 200, epoch: 1 | loss: 0.4603581\n",
      "\tspeed: 0.0846s/iter; left time: 789.6653s\n",
      "\titers: 300, epoch: 1 | loss: 0.3678226\n",
      "\tspeed: 0.0881s/iter; left time: 813.5590s\n",
      "\titers: 400, epoch: 1 | loss: 0.3540189\n",
      "\tspeed: 0.0856s/iter; left time: 781.5471s\n",
      "\titers: 500, epoch: 1 | loss: 0.3818545\n",
      "\tspeed: 0.0857s/iter; left time: 773.7624s\n",
      "\titers: 600, epoch: 1 | loss: 0.3905339\n",
      "\tspeed: 0.0884s/iter; left time: 789.1932s\n",
      "\titers: 700, epoch: 1 | loss: 0.3009404\n",
      "\tspeed: 0.0858s/iter; left time: 757.9082s\n",
      "\titers: 800, epoch: 1 | loss: 0.3585468\n",
      "\tspeed: 0.0880s/iter; left time: 768.3216s\n",
      "\titers: 900, epoch: 1 | loss: 0.4545961\n",
      "\tspeed: 0.0868s/iter; left time: 749.3448s\n",
      "Epoch: 1 cost time: 84.1750328540802\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.4359998 Vali Loss: 0.6071443 Test Loss: 1.2055727\n",
      "Validation loss decreased (inf --> 0.607144).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3048318\n",
      "\tspeed: 1.7080s/iter; left time: 14480.7446s\n",
      "\titers: 200, epoch: 2 | loss: 0.3571095\n",
      "\tspeed: 0.1138s/iter; left time: 953.1327s\n",
      "\titers: 300, epoch: 2 | loss: 0.2861847\n",
      "\tspeed: 0.1147s/iter; left time: 949.2585s\n",
      "\titers: 400, epoch: 2 | loss: 0.2818206\n",
      "\tspeed: 0.1137s/iter; left time: 929.8665s\n",
      "\titers: 500, epoch: 2 | loss: 0.2720204\n",
      "\tspeed: 0.1105s/iter; left time: 892.8116s\n",
      "\titers: 600, epoch: 2 | loss: 0.3093200\n",
      "\tspeed: 0.1137s/iter; left time: 907.1871s\n",
      "\titers: 700, epoch: 2 | loss: 0.3075661\n",
      "\tspeed: 0.1050s/iter; left time: 827.2169s\n",
      "\titers: 800, epoch: 2 | loss: 0.2502832\n",
      "\tspeed: 0.1116s/iter; left time: 868.2841s\n",
      "\titers: 900, epoch: 2 | loss: 0.2746629\n",
      "\tspeed: 0.1040s/iter; left time: 798.5247s\n",
      "Epoch: 2 cost time: 105.81573581695557\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.2973930 Vali Loss: 0.6880760 Test Loss: 1.3094629\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2486597\n",
      "\tspeed: 1.8338s/iter; left time: 13799.6340s\n",
      "\titers: 200, epoch: 3 | loss: 0.2548149\n",
      "\tspeed: 0.1111s/iter; left time: 825.0449s\n",
      "\titers: 300, epoch: 3 | loss: 0.2510777\n",
      "\tspeed: 0.1123s/iter; left time: 822.9298s\n",
      "\titers: 400, epoch: 3 | loss: 0.2187342\n",
      "\tspeed: 0.1117s/iter; left time: 807.1269s\n",
      "\titers: 500, epoch: 3 | loss: 0.2264565\n",
      "\tspeed: 0.1055s/iter; left time: 751.4517s\n",
      "\titers: 600, epoch: 3 | loss: 0.2164773\n",
      "\tspeed: 0.1072s/iter; left time: 753.3683s\n",
      "\titers: 700, epoch: 3 | loss: 0.2220227\n",
      "\tspeed: 0.1141s/iter; left time: 790.2216s\n",
      "\titers: 800, epoch: 3 | loss: 0.2501142\n",
      "\tspeed: 0.1154s/iter; left time: 787.8818s\n",
      "\titers: 900, epoch: 3 | loss: 0.2256346\n",
      "\tspeed: 0.1141s/iter; left time: 767.2252s\n",
      "Epoch: 3 cost time: 107.25913906097412\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.2298147 Vali Loss: 0.7890111 Test Loss: 1.5178739\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1731246\n",
      "\tspeed: 1.6725s/iter; left time: 10991.8205s\n",
      "\titers: 200, epoch: 4 | loss: 0.2436392\n",
      "\tspeed: 0.0847s/iter; left time: 548.2669s\n",
      "\titers: 300, epoch: 4 | loss: 0.1962738\n",
      "\tspeed: 0.0853s/iter; left time: 543.3718s\n",
      "\titers: 400, epoch: 4 | loss: 0.2083072\n",
      "\tspeed: 0.0840s/iter; left time: 526.9557s\n",
      "\titers: 500, epoch: 4 | loss: 0.1785685\n",
      "\tspeed: 0.1015s/iter; left time: 626.6940s\n",
      "\titers: 600, epoch: 4 | loss: 0.2135959\n",
      "\tspeed: 0.1138s/iter; left time: 690.9824s\n",
      "\titers: 700, epoch: 4 | loss: 0.2020771\n",
      "\tspeed: 0.1152s/iter; left time: 688.2572s\n",
      "\titers: 800, epoch: 4 | loss: 0.1671373\n",
      "\tspeed: 0.1086s/iter; left time: 637.9184s\n",
      "\titers: 900, epoch: 4 | loss: 0.1907749\n",
      "\tspeed: 0.1114s/iter; left time: 642.9895s\n",
      "Epoch: 4 cost time: 95.21637535095215\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.1962017 Vali Loss: 0.9043494 Test Loss: 1.7033201\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_df_all_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 29) (8711, 1, 48, 29)\n",
      "test shape: (8711, 48, 29) (8711, 48, 29)\n",
      "mse:1.2056951522827148, mae:0.7704637050628662\n",
      "\n",
      "Extracted Part: long_term_forecast__48_df_all_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__48_df_all_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=29, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_all_columns.csv', dec_in=29, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=29, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_96_df_all_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_df_all_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.8003607\n",
      "\tspeed: 0.1298s/iter; left time: 1222.9194s\n",
      "\titers: 200, epoch: 1 | loss: 0.6111086\n",
      "\tspeed: 0.1138s/iter; left time: 1061.1168s\n",
      "\titers: 300, epoch: 1 | loss: 0.4128542\n",
      "\tspeed: 0.1166s/iter; left time: 1074.9264s\n",
      "\titers: 400, epoch: 1 | loss: 0.4527340\n",
      "\tspeed: 0.1167s/iter; left time: 1064.2381s\n",
      "\titers: 500, epoch: 1 | loss: 0.4898345\n",
      "\tspeed: 0.1161s/iter; left time: 1046.9701s\n",
      "\titers: 600, epoch: 1 | loss: 0.5186327\n",
      "\tspeed: 0.1184s/iter; left time: 1056.6811s\n",
      "\titers: 700, epoch: 1 | loss: 0.4066541\n",
      "\tspeed: 0.1163s/iter; left time: 1025.6207s\n",
      "\titers: 800, epoch: 1 | loss: 0.3831158\n",
      "\tspeed: 0.1157s/iter; left time: 1008.9522s\n",
      "\titers: 900, epoch: 1 | loss: 0.3423863\n",
      "\tspeed: 0.1141s/iter; left time: 983.2591s\n",
      "Epoch: 1 cost time: 111.91791296005249\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.4906822 Vali Loss: 0.9119253 Test Loss: 1.7823193\n",
      "Validation loss decreased (inf --> 0.911925).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3484274\n",
      "\tspeed: 1.8524s/iter; left time: 15687.9395s\n",
      "\titers: 200, epoch: 2 | loss: 0.3386413\n",
      "\tspeed: 0.1175s/iter; left time: 983.0292s\n",
      "\titers: 300, epoch: 2 | loss: 0.3874925\n",
      "\tspeed: 0.1164s/iter; left time: 962.4558s\n",
      "\titers: 400, epoch: 2 | loss: 0.3596893\n",
      "\tspeed: 0.1203s/iter; left time: 982.9338s\n",
      "\titers: 500, epoch: 2 | loss: 0.2563710\n",
      "\tspeed: 0.1193s/iter; left time: 962.4448s\n",
      "\titers: 600, epoch: 2 | loss: 0.2875489\n",
      "\tspeed: 0.1212s/iter; left time: 965.7459s\n",
      "\titers: 700, epoch: 2 | loss: 0.2890921\n",
      "\tspeed: 0.1181s/iter; left time: 929.3602s\n",
      "\titers: 800, epoch: 2 | loss: 0.3210905\n",
      "\tspeed: 0.1195s/iter; left time: 928.2327s\n",
      "\titers: 900, epoch: 2 | loss: 0.3082602\n",
      "\tspeed: 0.1189s/iter; left time: 911.9265s\n",
      "Epoch: 2 cost time: 113.03013563156128\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.3197056 Vali Loss: 1.1824780 Test Loss: 2.3266020\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2619944\n",
      "\tspeed: 1.8896s/iter; left time: 14204.0621s\n",
      "\titers: 200, epoch: 3 | loss: 0.2647784\n",
      "\tspeed: 0.1207s/iter; left time: 895.5373s\n",
      "\titers: 300, epoch: 3 | loss: 0.2687544\n",
      "\tspeed: 0.1231s/iter; left time: 900.9414s\n",
      "\titers: 400, epoch: 3 | loss: 0.2938659\n",
      "\tspeed: 0.1237s/iter; left time: 892.6304s\n",
      "\titers: 500, epoch: 3 | loss: 0.2873255\n",
      "\tspeed: 0.1232s/iter; left time: 876.9725s\n",
      "\titers: 600, epoch: 3 | loss: 0.2583233\n",
      "\tspeed: 0.1037s/iter; left time: 727.4287s\n",
      "\titers: 700, epoch: 3 | loss: 0.2210939\n",
      "\tspeed: 0.1000s/iter; left time: 692.0249s\n",
      "\titers: 800, epoch: 3 | loss: 0.2474872\n",
      "\tspeed: 0.1157s/iter; left time: 789.0122s\n",
      "\titers: 900, epoch: 3 | loss: 0.2500723\n",
      "\tspeed: 0.1164s/iter; left time: 782.1423s\n",
      "Epoch: 3 cost time: 111.53176045417786\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.2495196 Vali Loss: 1.1714643 Test Loss: 2.3254151\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1928539\n",
      "\tspeed: 1.8702s/iter; left time: 12278.1097s\n",
      "\titers: 200, epoch: 4 | loss: 0.2338502\n",
      "\tspeed: 0.1148s/iter; left time: 742.1823s\n",
      "\titers: 300, epoch: 4 | loss: 0.1968537\n",
      "\tspeed: 0.1174s/iter; left time: 747.0674s\n",
      "\titers: 400, epoch: 4 | loss: 0.2055393\n",
      "\tspeed: 0.1184s/iter; left time: 741.6169s\n",
      "\titers: 500, epoch: 4 | loss: 0.2154053\n",
      "\tspeed: 0.1194s/iter; left time: 735.9897s\n",
      "\titers: 600, epoch: 4 | loss: 0.2086197\n",
      "\tspeed: 0.1024s/iter; left time: 620.9826s\n",
      "\titers: 700, epoch: 4 | loss: 0.2194577\n",
      "\tspeed: 0.1174s/iter; left time: 700.2263s\n",
      "\titers: 800, epoch: 4 | loss: 0.1970244\n",
      "\tspeed: 0.1166s/iter; left time: 684.1141s\n",
      "\titers: 900, epoch: 4 | loss: 0.2227145\n",
      "\tspeed: 0.1170s/iter; left time: 674.4451s\n",
      "Epoch: 4 cost time: 110.648996591568\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.2157673 Vali Loss: 1.2151687 Test Loss: 2.5104554\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_df_all_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 29) (8663, 1, 96, 29)\n",
      "test shape: (8663, 96, 29) (8663, 96, 29)\n",
      "mse:1.7822424173355103, mae:0.9866767525672913\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_df_all_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.6010650\n",
      "\tspeed: 0.1240s/iter; left time: 1168.6542s\n",
      "\titers: 200, epoch: 1 | loss: 0.6183646\n",
      "\tspeed: 0.1161s/iter; left time: 1082.1217s\n",
      "\titers: 300, epoch: 1 | loss: 0.5006549\n",
      "\tspeed: 0.1201s/iter; left time: 1107.4721s\n",
      "\titers: 400, epoch: 1 | loss: 0.5010536\n",
      "\tspeed: 0.1164s/iter; left time: 1062.1333s\n",
      "\titers: 500, epoch: 1 | loss: 0.4091432\n",
      "\tspeed: 0.1113s/iter; left time: 1003.8259s\n",
      "\titers: 600, epoch: 1 | loss: 0.4322121\n",
      "\tspeed: 0.1091s/iter; left time: 973.2466s\n",
      "\titers: 700, epoch: 1 | loss: 0.3478579\n",
      "\tspeed: 0.1069s/iter; left time: 943.2672s\n",
      "\titers: 800, epoch: 1 | loss: 0.3294761\n",
      "\tspeed: 0.1123s/iter; left time: 979.0262s\n",
      "\titers: 900, epoch: 1 | loss: 0.3512402\n",
      "\tspeed: 0.1214s/iter; left time: 1046.4302s\n",
      "Epoch: 1 cost time: 110.26572275161743\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.4888821 Vali Loss: 0.8059592 Test Loss: 1.5427015\n",
      "Validation loss decreased (inf --> 0.805959).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3712408\n",
      "\tspeed: 1.8495s/iter; left time: 15663.8167s\n",
      "\titers: 200, epoch: 2 | loss: 0.3040454\n",
      "\tspeed: 0.1149s/iter; left time: 961.7492s\n",
      "\titers: 300, epoch: 2 | loss: 0.3557193\n",
      "\tspeed: 0.1165s/iter; left time: 963.6348s\n",
      "\titers: 400, epoch: 2 | loss: 0.3479156\n",
      "\tspeed: 0.1186s/iter; left time: 969.1492s\n",
      "\titers: 500, epoch: 2 | loss: 0.3766363\n",
      "\tspeed: 0.1166s/iter; left time: 940.8478s\n",
      "\titers: 600, epoch: 2 | loss: 0.3063262\n",
      "\tspeed: 0.1138s/iter; left time: 906.9713s\n",
      "\titers: 700, epoch: 2 | loss: 0.3024649\n",
      "\tspeed: 0.1121s/iter; left time: 881.9645s\n",
      "\titers: 800, epoch: 2 | loss: 0.2587122\n",
      "\tspeed: 0.1165s/iter; left time: 904.9806s\n",
      "\titers: 900, epoch: 2 | loss: 0.2796543\n",
      "\tspeed: 0.1149s/iter; left time: 880.8720s\n",
      "Epoch: 2 cost time: 109.2832441329956\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.3281984 Vali Loss: 0.8574573 Test Loss: 1.6508880\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3053802\n",
      "\tspeed: 1.8726s/iter; left time: 14076.1244s\n",
      "\titers: 200, epoch: 3 | loss: 0.2563003\n",
      "\tspeed: 0.1202s/iter; left time: 891.8694s\n",
      "\titers: 300, epoch: 3 | loss: 0.2987041\n",
      "\tspeed: 0.1185s/iter; left time: 866.8326s\n",
      "\titers: 400, epoch: 3 | loss: 0.2411657\n",
      "\tspeed: 0.1160s/iter; left time: 836.8373s\n",
      "\titers: 500, epoch: 3 | loss: 0.2598181\n",
      "\tspeed: 0.1133s/iter; left time: 806.0886s\n",
      "\titers: 600, epoch: 3 | loss: 0.2436007\n",
      "\tspeed: 0.1136s/iter; left time: 797.2921s\n",
      "\titers: 700, epoch: 3 | loss: 0.2526474\n",
      "\tspeed: 0.1156s/iter; left time: 799.3427s\n",
      "\titers: 800, epoch: 3 | loss: 0.2701955\n",
      "\tspeed: 0.1181s/iter; left time: 804.7483s\n",
      "\titers: 900, epoch: 3 | loss: 0.2280901\n",
      "\tspeed: 0.1164s/iter; left time: 781.9392s\n",
      "Epoch: 3 cost time: 111.8312976360321\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.2538435 Vali Loss: 1.0096051 Test Loss: 1.8803059\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2305902\n",
      "\tspeed: 1.8910s/iter; left time: 12414.1055s\n",
      "\titers: 200, epoch: 4 | loss: 0.2170198\n",
      "\tspeed: 0.1105s/iter; left time: 714.5915s\n",
      "\titers: 300, epoch: 4 | loss: 0.2297603\n",
      "\tspeed: 0.1175s/iter; left time: 747.5797s\n",
      "\titers: 400, epoch: 4 | loss: 0.2084016\n",
      "\tspeed: 0.1193s/iter; left time: 747.6327s\n",
      "\titers: 500, epoch: 4 | loss: 0.2022545\n",
      "\tspeed: 0.1175s/iter; left time: 724.1045s\n",
      "\titers: 600, epoch: 4 | loss: 0.2133020\n",
      "\tspeed: 0.1158s/iter; left time: 702.5908s\n",
      "\titers: 700, epoch: 4 | loss: 0.2060025\n",
      "\tspeed: 0.1239s/iter; left time: 738.8417s\n",
      "\titers: 800, epoch: 4 | loss: 0.1823242\n",
      "\tspeed: 0.1217s/iter; left time: 713.7301s\n",
      "\titers: 900, epoch: 4 | loss: 0.2109756\n",
      "\tspeed: 0.1236s/iter; left time: 712.3801s\n",
      "Epoch: 4 cost time: 114.39094138145447\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.2184834 Vali Loss: 1.1135522 Test Loss: 2.1401613\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_df_all_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 29) (8663, 1, 96, 29)\n",
      "test shape: (8663, 96, 29) (8663, 96, 29)\n",
      "mse:1.5427368879318237, mae:0.9091850519180298\n",
      "\n",
      "Extracted Part: long_term_forecast__96_df_all_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__96_df_all_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=29, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_all_columns.csv', dec_in=29, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=29, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_192_df_all_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_df_all_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.7388511\n",
      "\tspeed: 0.1231s/iter; left time: 1155.8563s\n",
      "\titers: 200, epoch: 1 | loss: 0.6800718\n",
      "\tspeed: 0.1293s/iter; left time: 1200.9277s\n",
      "\titers: 300, epoch: 1 | loss: 0.5183632\n",
      "\tspeed: 0.1673s/iter; left time: 1537.8291s\n",
      "\titers: 400, epoch: 1 | loss: 0.4911261\n",
      "\tspeed: 0.1638s/iter; left time: 1489.4201s\n",
      "\titers: 500, epoch: 1 | loss: 0.4247931\n",
      "\tspeed: 0.1576s/iter; left time: 1416.9552s\n",
      "\titers: 600, epoch: 1 | loss: 0.4508580\n",
      "\tspeed: 0.1555s/iter; left time: 1382.7217s\n",
      "\titers: 700, epoch: 1 | loss: 0.4098893\n",
      "\tspeed: 0.1538s/iter; left time: 1352.3019s\n",
      "\titers: 800, epoch: 1 | loss: 0.4555836\n",
      "\tspeed: 0.1597s/iter; left time: 1387.9599s\n",
      "\titers: 900, epoch: 1 | loss: 0.3611766\n",
      "\tspeed: 0.1549s/iter; left time: 1330.6178s\n",
      "Epoch: 1 cost time: 143.96807026863098\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.5228397 Vali Loss: 0.8628885 Test Loss: 1.6221579\n",
      "Validation loss decreased (inf --> 0.862889).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4902279\n",
      "\tspeed: 3.8035s/iter; left time: 32109.0386s\n",
      "\titers: 200, epoch: 2 | loss: 0.3987584\n",
      "\tspeed: 0.1644s/iter; left time: 1371.6787s\n",
      "\titers: 300, epoch: 2 | loss: 0.3759297\n",
      "\tspeed: 0.1572s/iter; left time: 1295.6880s\n",
      "\titers: 400, epoch: 2 | loss: 0.3418137\n",
      "\tspeed: 0.1496s/iter; left time: 1217.8204s\n",
      "\titers: 500, epoch: 2 | loss: 0.3201081\n",
      "\tspeed: 0.1619s/iter; left time: 1301.7565s\n",
      "\titers: 600, epoch: 2 | loss: 0.3371969\n",
      "\tspeed: 0.1597s/iter; left time: 1268.2695s\n",
      "\titers: 700, epoch: 2 | loss: 0.3103253\n",
      "\tspeed: 0.1578s/iter; left time: 1237.0850s\n",
      "\titers: 800, epoch: 2 | loss: 0.2839722\n",
      "\tspeed: 0.1609s/iter; left time: 1245.5215s\n",
      "\titers: 900, epoch: 2 | loss: 0.2824698\n",
      "\tspeed: 0.1608s/iter; left time: 1228.9488s\n",
      "Epoch: 2 cost time: 151.25739932060242\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.3381411 Vali Loss: 1.0271298 Test Loss: 1.8049597\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2396690\n",
      "\tspeed: 2.0018s/iter; left time: 14999.6297s\n",
      "\titers: 200, epoch: 3 | loss: 0.2922293\n",
      "\tspeed: 0.1242s/iter; left time: 917.9786s\n",
      "\titers: 300, epoch: 3 | loss: 0.2642497\n",
      "\tspeed: 0.1235s/iter; left time: 900.3886s\n",
      "\titers: 400, epoch: 3 | loss: 0.2517490\n",
      "\tspeed: 0.1239s/iter; left time: 891.2271s\n",
      "\titers: 500, epoch: 3 | loss: 0.2250489\n",
      "\tspeed: 0.1249s/iter; left time: 886.0707s\n",
      "\titers: 600, epoch: 3 | loss: 0.2921692\n",
      "\tspeed: 0.1242s/iter; left time: 868.2881s\n",
      "\titers: 700, epoch: 3 | loss: 0.2474379\n",
      "\tspeed: 0.1242s/iter; left time: 855.8979s\n",
      "\titers: 800, epoch: 3 | loss: 0.2398254\n",
      "\tspeed: 0.1244s/iter; left time: 845.0834s\n",
      "\titers: 900, epoch: 3 | loss: 0.2423019\n",
      "\tspeed: 0.1235s/iter; left time: 826.8576s\n",
      "Epoch: 3 cost time: 118.31632018089294\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.2631562 Vali Loss: 1.0740712 Test Loss: 1.9108021\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2217898\n",
      "\tspeed: 1.5761s/iter; left time: 10314.0893s\n",
      "\titers: 200, epoch: 4 | loss: 0.2234044\n",
      "\tspeed: 0.1240s/iter; left time: 799.2011s\n",
      "\titers: 300, epoch: 4 | loss: 0.2342454\n",
      "\tspeed: 0.1238s/iter; left time: 785.4534s\n",
      "\titers: 400, epoch: 4 | loss: 0.2197751\n",
      "\tspeed: 0.1243s/iter; left time: 775.9491s\n",
      "\titers: 500, epoch: 4 | loss: 0.2381958\n",
      "\tspeed: 0.1481s/iter; left time: 909.9480s\n",
      "\titers: 600, epoch: 4 | loss: 0.2041676\n",
      "\tspeed: 0.1629s/iter; left time: 984.6941s\n",
      "\titers: 700, epoch: 4 | loss: 0.2070895\n",
      "\tspeed: 0.1579s/iter; left time: 938.6747s\n",
      "\titers: 800, epoch: 4 | loss: 0.2361990\n",
      "\tspeed: 0.1636s/iter; left time: 956.1368s\n",
      "\titers: 900, epoch: 4 | loss: 0.2118569\n",
      "\tspeed: 0.1474s/iter; left time: 846.6733s\n",
      "Epoch: 4 cost time: 135.5656430721283\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.2266182 Vali Loss: 1.1205173 Test Loss: 1.9967761\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_df_all_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 29) (8567, 1, 192, 29)\n",
      "test shape: (8567, 192, 29) (8567, 192, 29)\n",
      "mse:1.6223965883255005, mae:0.8938133120536804\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_df_all_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.6792501\n",
      "\tspeed: 0.1639s/iter; left time: 1538.7916s\n",
      "\titers: 200, epoch: 1 | loss: 0.6656716\n",
      "\tspeed: 0.1648s/iter; left time: 1530.8566s\n",
      "\titers: 300, epoch: 1 | loss: 0.5548840\n",
      "\tspeed: 0.1603s/iter; left time: 1473.7300s\n",
      "\titers: 400, epoch: 1 | loss: 0.4881791\n",
      "\tspeed: 0.1621s/iter; left time: 1473.2262s\n",
      "\titers: 500, epoch: 1 | loss: 0.4493335\n",
      "\tspeed: 0.1572s/iter; left time: 1412.9464s\n",
      "\titers: 600, epoch: 1 | loss: 0.4442217\n",
      "\tspeed: 0.1553s/iter; left time: 1380.9160s\n",
      "\titers: 700, epoch: 1 | loss: 0.4616631\n",
      "\tspeed: 0.1522s/iter; left time: 1337.7113s\n",
      "\titers: 800, epoch: 1 | loss: 0.4546468\n",
      "\tspeed: 0.1554s/iter; left time: 1350.3747s\n",
      "\titers: 900, epoch: 1 | loss: 0.3762706\n",
      "\tspeed: 0.1604s/iter; left time: 1378.1883s\n",
      "Epoch: 1 cost time: 151.1017611026764\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.5208580 Vali Loss: 0.8481905 Test Loss: 1.5413704\n",
      "Validation loss decreased (inf --> 0.848191).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3781310\n",
      "\tspeed: 2.9488s/iter; left time: 24894.1720s\n",
      "\titers: 200, epoch: 2 | loss: 0.3697416\n",
      "\tspeed: 0.1247s/iter; left time: 1039.8908s\n",
      "\titers: 300, epoch: 2 | loss: 0.3655930\n",
      "\tspeed: 0.1247s/iter; left time: 1027.9991s\n",
      "\titers: 400, epoch: 2 | loss: 0.3031989\n",
      "\tspeed: 0.1245s/iter; left time: 1013.8797s\n",
      "\titers: 500, epoch: 2 | loss: 0.3114567\n",
      "\tspeed: 0.1246s/iter; left time: 1002.0128s\n",
      "\titers: 600, epoch: 2 | loss: 0.3256952\n",
      "\tspeed: 0.1225s/iter; left time: 972.8135s\n",
      "\titers: 700, epoch: 2 | loss: 0.3028917\n",
      "\tspeed: 0.1254s/iter; left time: 983.5715s\n",
      "\titers: 800, epoch: 2 | loss: 0.2812339\n",
      "\tspeed: 0.1464s/iter; left time: 1133.1477s\n",
      "\titers: 900, epoch: 2 | loss: 0.2643798\n",
      "\tspeed: 0.1729s/iter; left time: 1321.6005s\n",
      "Epoch: 2 cost time: 128.1496284008026\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.3348136 Vali Loss: 0.9979461 Test Loss: 1.9023507\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2591017\n",
      "\tspeed: 3.1066s/iter; left time: 23278.0140s\n",
      "\titers: 200, epoch: 3 | loss: 0.2593065\n",
      "\tspeed: 0.1633s/iter; left time: 1207.3723s\n",
      "\titers: 300, epoch: 3 | loss: 0.2956409\n",
      "\tspeed: 0.1681s/iter; left time: 1226.0108s\n",
      "\titers: 400, epoch: 3 | loss: 0.2624054\n",
      "\tspeed: 0.1570s/iter; left time: 1129.3542s\n",
      "\titers: 500, epoch: 3 | loss: 0.2671688\n",
      "\tspeed: 0.1634s/iter; left time: 1158.7805s\n",
      "\titers: 600, epoch: 3 | loss: 0.2715755\n",
      "\tspeed: 0.1596s/iter; left time: 1116.2506s\n",
      "\titers: 700, epoch: 3 | loss: 0.2824415\n",
      "\tspeed: 0.1645s/iter; left time: 1133.9036s\n",
      "\titers: 800, epoch: 3 | loss: 0.2569746\n",
      "\tspeed: 0.1710s/iter; left time: 1161.2743s\n",
      "\titers: 900, epoch: 3 | loss: 0.2691851\n",
      "\tspeed: 0.1728s/iter; left time: 1156.7718s\n",
      "Epoch: 3 cost time: 157.20657968521118\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.2627174 Vali Loss: 1.0025108 Test Loss: 1.7310648\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2608000\n",
      "\tspeed: 3.0152s/iter; left time: 19731.2697s\n",
      "\titers: 200, epoch: 4 | loss: 0.2280855\n",
      "\tspeed: 0.1575s/iter; left time: 1015.0350s\n",
      "\titers: 300, epoch: 4 | loss: 0.2276298\n",
      "\tspeed: 0.1584s/iter; left time: 1005.1534s\n",
      "\titers: 400, epoch: 4 | loss: 0.2187738\n",
      "\tspeed: 0.1518s/iter; left time: 947.5943s\n",
      "\titers: 500, epoch: 4 | loss: 0.2388151\n",
      "\tspeed: 0.1564s/iter; left time: 960.7836s\n",
      "\titers: 600, epoch: 4 | loss: 0.2352335\n",
      "\tspeed: 0.1541s/iter; left time: 931.1490s\n",
      "\titers: 700, epoch: 4 | loss: 0.2483428\n",
      "\tspeed: 0.1543s/iter; left time: 917.2690s\n",
      "\titers: 800, epoch: 4 | loss: 0.2567798\n",
      "\tspeed: 0.1578s/iter; left time: 922.1928s\n",
      "\titers: 900, epoch: 4 | loss: 0.1954779\n",
      "\tspeed: 0.1360s/iter; left time: 781.1870s\n",
      "Epoch: 4 cost time: 145.1100516319275\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.2290867 Vali Loss: 1.0284555 Test Loss: 1.7599133\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_df_all_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 29) (8567, 1, 192, 29)\n",
      "test shape: (8567, 192, 29) (8567, 192, 29)\n",
      "mse:1.5414010286331177, mae:0.8669413924217224\n",
      "\n",
      "Extracted Part: long_term_forecast__192_df_all_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__192_df_all_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=3, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=3, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=3, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_24_df_most_important_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=24, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.4080254\n",
      "\tspeed: 0.0815s/iter; left time: 768.9752s\n",
      "\titers: 200, epoch: 1 | loss: 0.2200839\n",
      "\tspeed: 0.0667s/iter; left time: 623.4267s\n",
      "\titers: 300, epoch: 1 | loss: 0.2739810\n",
      "\tspeed: 0.0665s/iter; left time: 614.9620s\n",
      "\titers: 400, epoch: 1 | loss: 0.2564107\n",
      "\tspeed: 0.0665s/iter; left time: 607.7240s\n",
      "\titers: 500, epoch: 1 | loss: 0.2247405\n",
      "\tspeed: 0.0701s/iter; left time: 633.6556s\n",
      "\titers: 600, epoch: 1 | loss: 0.1952659\n",
      "\tspeed: 0.0650s/iter; left time: 581.0377s\n",
      "\titers: 700, epoch: 1 | loss: 0.1979437\n",
      "\tspeed: 0.0642s/iter; left time: 567.2169s\n",
      "\titers: 800, epoch: 1 | loss: 0.2504064\n",
      "\tspeed: 0.0641s/iter; left time: 560.0618s\n",
      "\titers: 900, epoch: 1 | loss: 0.2388328\n",
      "\tspeed: 0.0650s/iter; left time: 561.5618s\n",
      "Epoch: 1 cost time: 64.5459337234497\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.2971281 Vali Loss: 0.2569809 Test Loss: 0.3369955\n",
      "Validation loss decreased (inf --> 0.256981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2417658\n",
      "\tspeed: 1.6584s/iter; left time: 14074.6935s\n",
      "\titers: 200, epoch: 2 | loss: 0.1904698\n",
      "\tspeed: 0.0677s/iter; left time: 567.6593s\n",
      "\titers: 300, epoch: 2 | loss: 0.1864196\n",
      "\tspeed: 0.0684s/iter; left time: 566.6684s\n",
      "\titers: 400, epoch: 2 | loss: 0.1768855\n",
      "\tspeed: 0.0662s/iter; left time: 541.6131s\n",
      "\titers: 500, epoch: 2 | loss: 0.1981456\n",
      "\tspeed: 0.0651s/iter; left time: 526.5793s\n",
      "\titers: 600, epoch: 2 | loss: 0.2095433\n",
      "\tspeed: 0.0650s/iter; left time: 519.4345s\n",
      "\titers: 700, epoch: 2 | loss: 0.1585151\n",
      "\tspeed: 0.0650s/iter; left time: 512.6920s\n",
      "\titers: 800, epoch: 2 | loss: 0.2083254\n",
      "\tspeed: 0.0657s/iter; left time: 511.9301s\n",
      "\titers: 900, epoch: 2 | loss: 0.1944397\n",
      "\tspeed: 0.0648s/iter; left time: 498.0270s\n",
      "Epoch: 2 cost time: 63.64322280883789\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.1898281 Vali Loss: 0.2573974 Test Loss: 0.3032597\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1305923\n",
      "\tspeed: 1.6073s/iter; left time: 12107.8930s\n",
      "\titers: 200, epoch: 3 | loss: 0.1942063\n",
      "\tspeed: 0.0684s/iter; left time: 508.3791s\n",
      "\titers: 300, epoch: 3 | loss: 0.1702523\n",
      "\tspeed: 0.0645s/iter; left time: 472.9324s\n",
      "\titers: 400, epoch: 3 | loss: 0.1580675\n",
      "\tspeed: 0.0649s/iter; left time: 469.0831s\n",
      "\titers: 500, epoch: 3 | loss: 0.1493866\n",
      "\tspeed: 0.0643s/iter; left time: 458.4799s\n",
      "\titers: 600, epoch: 3 | loss: 0.1461297\n",
      "\tspeed: 0.0651s/iter; left time: 457.8950s\n",
      "\titers: 700, epoch: 3 | loss: 0.1241533\n",
      "\tspeed: 0.0662s/iter; left time: 458.6285s\n",
      "\titers: 800, epoch: 3 | loss: 0.1500745\n",
      "\tspeed: 0.0652s/iter; left time: 445.7806s\n",
      "\titers: 900, epoch: 3 | loss: 0.2008617\n",
      "\tspeed: 0.0654s/iter; left time: 440.4068s\n",
      "Epoch: 3 cost time: 63.12024474143982\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.1608601 Vali Loss: 0.2358138 Test Loss: 0.2848723\n",
      "Validation loss decreased (0.256981 --> 0.235814).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1283806\n",
      "\tspeed: 1.6597s/iter; left time: 10919.1037s\n",
      "\titers: 200, epoch: 4 | loss: 0.1698361\n",
      "\tspeed: 0.0669s/iter; left time: 433.3969s\n",
      "\titers: 300, epoch: 4 | loss: 0.1588208\n",
      "\tspeed: 0.0660s/iter; left time: 420.9492s\n",
      "\titers: 400, epoch: 4 | loss: 0.1604743\n",
      "\tspeed: 0.0664s/iter; left time: 416.7714s\n",
      "\titers: 500, epoch: 4 | loss: 0.1652845\n",
      "\tspeed: 0.0673s/iter; left time: 416.1205s\n",
      "\titers: 600, epoch: 4 | loss: 0.1277562\n",
      "\tspeed: 0.0691s/iter; left time: 420.3412s\n",
      "\titers: 700, epoch: 4 | loss: 0.1341572\n",
      "\tspeed: 0.0788s/iter; left time: 470.8909s\n",
      "\titers: 800, epoch: 4 | loss: 0.1101660\n",
      "\tspeed: 0.0786s/iter; left time: 462.1273s\n",
      "\titers: 900, epoch: 4 | loss: 0.1271918\n",
      "\tspeed: 0.0687s/iter; left time: 397.2606s\n",
      "Epoch: 4 cost time: 67.02501583099365\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.1419725 Vali Loss: 0.2308147 Test Loss: 0.2951312\n",
      "Validation loss decreased (0.235814 --> 0.230815).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1562762\n",
      "\tspeed: 1.6702s/iter; left time: 9394.8803s\n",
      "\titers: 200, epoch: 5 | loss: 0.1480708\n",
      "\tspeed: 0.0654s/iter; left time: 361.3087s\n",
      "\titers: 300, epoch: 5 | loss: 0.0980538\n",
      "\tspeed: 0.0667s/iter; left time: 362.0117s\n",
      "\titers: 400, epoch: 5 | loss: 0.1400365\n",
      "\tspeed: 0.0663s/iter; left time: 353.0986s\n",
      "\titers: 500, epoch: 5 | loss: 0.1602227\n",
      "\tspeed: 0.0657s/iter; left time: 343.3518s\n",
      "\titers: 600, epoch: 5 | loss: 0.1187214\n",
      "\tspeed: 0.0663s/iter; left time: 340.0416s\n",
      "\titers: 700, epoch: 5 | loss: 0.1275502\n",
      "\tspeed: 0.0695s/iter; left time: 349.0206s\n",
      "\titers: 800, epoch: 5 | loss: 0.1281557\n",
      "\tspeed: 0.0652s/iter; left time: 321.0667s\n",
      "\titers: 900, epoch: 5 | loss: 0.1341173\n",
      "\tspeed: 0.0684s/iter; left time: 330.0272s\n",
      "Epoch: 5 cost time: 64.06035089492798\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.1293219 Vali Loss: 0.2390344 Test Loss: 0.3047903\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1086524\n",
      "\tspeed: 1.6524s/iter; left time: 7718.5500s\n",
      "\titers: 200, epoch: 6 | loss: 0.1399738\n",
      "\tspeed: 0.0680s/iter; left time: 310.8550s\n",
      "\titers: 300, epoch: 6 | loss: 0.0916611\n",
      "\tspeed: 0.0670s/iter; left time: 299.4319s\n",
      "\titers: 400, epoch: 6 | loss: 0.0993210\n",
      "\tspeed: 0.0665s/iter; left time: 290.7170s\n",
      "\titers: 500, epoch: 6 | loss: 0.1253146\n",
      "\tspeed: 0.0660s/iter; left time: 282.0845s\n",
      "\titers: 600, epoch: 6 | loss: 0.1368469\n",
      "\tspeed: 0.0673s/iter; left time: 280.8582s\n",
      "\titers: 700, epoch: 6 | loss: 0.0997145\n",
      "\tspeed: 0.0698s/iter; left time: 284.2492s\n",
      "\titers: 800, epoch: 6 | loss: 0.1183596\n",
      "\tspeed: 0.0678s/iter; left time: 269.3349s\n",
      "\titers: 900, epoch: 6 | loss: 0.1158228\n",
      "\tspeed: 0.0679s/iter; left time: 262.9003s\n",
      "Epoch: 6 cost time: 64.94698357582092\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.1219018 Vali Loss: 0.2502050 Test Loss: 0.3181742\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1153899\n",
      "\tspeed: 1.9392s/iter; left time: 7208.0213s\n",
      "\titers: 200, epoch: 7 | loss: 0.1431416\n",
      "\tspeed: 0.0853s/iter; left time: 308.6799s\n",
      "\titers: 300, epoch: 7 | loss: 0.1036021\n",
      "\tspeed: 0.0913s/iter; left time: 321.2013s\n",
      "\titers: 400, epoch: 7 | loss: 0.1347284\n",
      "\tspeed: 0.0844s/iter; left time: 288.3033s\n",
      "\titers: 500, epoch: 7 | loss: 0.1066426\n",
      "\tspeed: 0.0864s/iter; left time: 286.6358s\n",
      "\titers: 600, epoch: 7 | loss: 0.1073789\n",
      "\tspeed: 0.0928s/iter; left time: 298.3960s\n",
      "\titers: 700, epoch: 7 | loss: 0.1199338\n",
      "\tspeed: 0.0849s/iter; left time: 264.7370s\n",
      "\titers: 800, epoch: 7 | loss: 0.1526815\n",
      "\tspeed: 0.0849s/iter; left time: 256.0758s\n",
      "\titers: 900, epoch: 7 | loss: 0.1218256\n",
      "\tspeed: 0.0675s/iter; left time: 196.8127s\n",
      "Epoch: 7 cost time: 80.30393743515015\n",
      "Epoch: 7, Steps: 954 | Train Loss: 0.1176975 Vali Loss: 0.2526619 Test Loss: 0.3158075\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 3) (8735, 1, 24, 3)\n",
      "test shape: (8735, 24, 3) (8735, 24, 3)\n",
      "mse:0.29494455456733704, mae:0.32330238819122314\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.5378245\n",
      "\tspeed: 0.0736s/iter; left time: 694.5455s\n",
      "\titers: 200, epoch: 1 | loss: 0.3634390\n",
      "\tspeed: 0.0680s/iter; left time: 634.7409s\n",
      "\titers: 300, epoch: 1 | loss: 0.1973539\n",
      "\tspeed: 0.0689s/iter; left time: 636.4178s\n",
      "\titers: 400, epoch: 1 | loss: 0.2644503\n",
      "\tspeed: 0.0669s/iter; left time: 611.9166s\n",
      "\titers: 500, epoch: 1 | loss: 0.1827602\n",
      "\tspeed: 0.0690s/iter; left time: 624.1527s\n",
      "\titers: 600, epoch: 1 | loss: 0.2166292\n",
      "\tspeed: 0.0666s/iter; left time: 595.1515s\n",
      "\titers: 700, epoch: 1 | loss: 0.2213495\n",
      "\tspeed: 0.0682s/iter; left time: 603.0078s\n",
      "\titers: 800, epoch: 1 | loss: 0.2435577\n",
      "\tspeed: 0.0680s/iter; left time: 593.9894s\n",
      "\titers: 900, epoch: 1 | loss: 0.2444718\n",
      "\tspeed: 0.0701s/iter; left time: 605.5065s\n",
      "Epoch: 1 cost time: 65.64682960510254\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.3007058 Vali Loss: 0.2790485 Test Loss: 0.3341314\n",
      "Validation loss decreased (inf --> 0.279048).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2545100\n",
      "\tspeed: 1.6642s/iter; left time: 14124.1412s\n",
      "\titers: 200, epoch: 2 | loss: 0.2415627\n",
      "\tspeed: 0.0684s/iter; left time: 574.0897s\n",
      "\titers: 300, epoch: 2 | loss: 0.2663121\n",
      "\tspeed: 0.0698s/iter; left time: 578.4977s\n",
      "\titers: 400, epoch: 2 | loss: 0.1843022\n",
      "\tspeed: 0.0684s/iter; left time: 559.8464s\n",
      "\titers: 500, epoch: 2 | loss: 0.2448560\n",
      "\tspeed: 0.0688s/iter; left time: 556.1863s\n",
      "\titers: 600, epoch: 2 | loss: 0.2154176\n",
      "\tspeed: 0.0681s/iter; left time: 543.8071s\n",
      "\titers: 700, epoch: 2 | loss: 0.1649486\n",
      "\tspeed: 0.0676s/iter; left time: 533.4154s\n",
      "\titers: 800, epoch: 2 | loss: 0.1513043\n",
      "\tspeed: 0.0693s/iter; left time: 539.6070s\n",
      "\titers: 900, epoch: 2 | loss: 0.1608854\n",
      "\tspeed: 0.0690s/iter; left time: 530.0379s\n",
      "Epoch: 2 cost time: 66.36132025718689\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.1907999 Vali Loss: 0.2389922 Test Loss: 0.3013502\n",
      "Validation loss decreased (0.279048 --> 0.238992).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1256063\n",
      "\tspeed: 1.6763s/iter; left time: 12627.8760s\n",
      "\titers: 200, epoch: 3 | loss: 0.1515930\n",
      "\tspeed: 0.0828s/iter; left time: 615.5018s\n",
      "\titers: 300, epoch: 3 | loss: 0.1406147\n",
      "\tspeed: 0.0818s/iter; left time: 600.0525s\n",
      "\titers: 400, epoch: 3 | loss: 0.1664373\n",
      "\tspeed: 0.0808s/iter; left time: 584.3912s\n",
      "\titers: 500, epoch: 3 | loss: 0.1643086\n",
      "\tspeed: 0.0822s/iter; left time: 586.4722s\n",
      "\titers: 600, epoch: 3 | loss: 0.2168833\n",
      "\tspeed: 0.0791s/iter; left time: 556.6448s\n",
      "\titers: 700, epoch: 3 | loss: 0.1481030\n",
      "\tspeed: 0.0736s/iter; left time: 509.9516s\n",
      "\titers: 800, epoch: 3 | loss: 0.2241103\n",
      "\tspeed: 0.0743s/iter; left time: 507.5609s\n",
      "\titers: 900, epoch: 3 | loss: 0.1476080\n",
      "\tspeed: 0.0814s/iter; left time: 548.2097s\n",
      "Epoch: 3 cost time: 76.8037166595459\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.1591187 Vali Loss: 0.2333781 Test Loss: 0.2929426\n",
      "Validation loss decreased (0.238992 --> 0.233378).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1355337\n",
      "\tspeed: 1.4234s/iter; left time: 9364.8570s\n",
      "\titers: 200, epoch: 4 | loss: 0.1627446\n",
      "\tspeed: 0.0819s/iter; left time: 530.6842s\n",
      "\titers: 300, epoch: 4 | loss: 0.1268100\n",
      "\tspeed: 0.0818s/iter; left time: 521.9525s\n",
      "\titers: 400, epoch: 4 | loss: 0.1963444\n",
      "\tspeed: 0.0819s/iter; left time: 514.2887s\n",
      "\titers: 500, epoch: 4 | loss: 0.1976891\n",
      "\tspeed: 0.0825s/iter; left time: 509.9098s\n",
      "\titers: 600, epoch: 4 | loss: 0.1307392\n",
      "\tspeed: 0.0812s/iter; left time: 493.8078s\n",
      "\titers: 700, epoch: 4 | loss: 0.1094107\n",
      "\tspeed: 0.0819s/iter; left time: 489.5408s\n",
      "\titers: 800, epoch: 4 | loss: 0.1387938\n",
      "\tspeed: 0.0823s/iter; left time: 484.0405s\n",
      "\titers: 900, epoch: 4 | loss: 0.1201017\n",
      "\tspeed: 0.0835s/iter; left time: 482.7492s\n",
      "Epoch: 4 cost time: 78.97483944892883\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.1410334 Vali Loss: 0.2315306 Test Loss: 0.2996672\n",
      "Validation loss decreased (0.233378 --> 0.231531).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1441486\n",
      "\tspeed: 1.6641s/iter; left time: 9360.8068s\n",
      "\titers: 200, epoch: 5 | loss: 0.1001486\n",
      "\tspeed: 0.0678s/iter; left time: 374.8501s\n",
      "\titers: 300, epoch: 5 | loss: 0.1256024\n",
      "\tspeed: 0.0715s/iter; left time: 388.0544s\n",
      "\titers: 400, epoch: 5 | loss: 0.1629982\n",
      "\tspeed: 0.0685s/iter; left time: 364.4966s\n",
      "\titers: 500, epoch: 5 | loss: 0.1639863\n",
      "\tspeed: 0.0705s/iter; left time: 368.5580s\n",
      "\titers: 600, epoch: 5 | loss: 0.1404546\n",
      "\tspeed: 0.0669s/iter; left time: 343.0634s\n",
      "\titers: 700, epoch: 5 | loss: 0.1278243\n",
      "\tspeed: 0.0663s/iter; left time: 333.1264s\n",
      "\titers: 800, epoch: 5 | loss: 0.0961772\n",
      "\tspeed: 0.0677s/iter; left time: 333.2495s\n",
      "\titers: 900, epoch: 5 | loss: 0.1352309\n",
      "\tspeed: 0.0672s/iter; left time: 324.4222s\n",
      "Epoch: 5 cost time: 65.85525178909302\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.1278620 Vali Loss: 0.2282910 Test Loss: 0.3004054\n",
      "Validation loss decreased (0.231531 --> 0.228291).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1045330\n",
      "\tspeed: 1.6695s/iter; left time: 7798.1267s\n",
      "\titers: 200, epoch: 6 | loss: 0.1295880\n",
      "\tspeed: 0.0689s/iter; left time: 314.9177s\n",
      "\titers: 300, epoch: 6 | loss: 0.1400950\n",
      "\tspeed: 0.0681s/iter; left time: 304.6881s\n",
      "\titers: 400, epoch: 6 | loss: 0.1193996\n",
      "\tspeed: 0.0693s/iter; left time: 302.8071s\n",
      "\titers: 500, epoch: 6 | loss: 0.1480378\n",
      "\tspeed: 0.0657s/iter; left time: 280.4191s\n",
      "\titers: 600, epoch: 6 | loss: 0.1209277\n",
      "\tspeed: 0.0789s/iter; left time: 329.1155s\n",
      "\titers: 700, epoch: 6 | loss: 0.0998624\n",
      "\tspeed: 0.0675s/iter; left time: 274.7545s\n",
      "\titers: 800, epoch: 6 | loss: 0.1097173\n",
      "\tspeed: 0.0670s/iter; left time: 266.2063s\n",
      "\titers: 900, epoch: 6 | loss: 0.1154874\n",
      "\tspeed: 0.0667s/iter; left time: 258.3259s\n",
      "Epoch: 6 cost time: 66.46462678909302\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.1201732 Vali Loss: 0.2425013 Test Loss: 0.3178599\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0913505\n",
      "\tspeed: 1.6318s/iter; left time: 6065.2939s\n",
      "\titers: 200, epoch: 7 | loss: 0.0955252\n",
      "\tspeed: 0.0677s/iter; left time: 245.0367s\n",
      "\titers: 300, epoch: 7 | loss: 0.1450810\n",
      "\tspeed: 0.0687s/iter; left time: 241.4470s\n",
      "\titers: 400, epoch: 7 | loss: 0.1293962\n",
      "\tspeed: 0.0701s/iter; left time: 239.6972s\n",
      "\titers: 500, epoch: 7 | loss: 0.1125739\n",
      "\tspeed: 0.0697s/iter; left time: 231.1449s\n",
      "\titers: 600, epoch: 7 | loss: 0.1174089\n",
      "\tspeed: 0.0718s/iter; left time: 230.9253s\n",
      "\titers: 700, epoch: 7 | loss: 0.1087956\n",
      "\tspeed: 0.0679s/iter; left time: 211.6335s\n",
      "\titers: 800, epoch: 7 | loss: 0.0999698\n",
      "\tspeed: 0.0686s/iter; left time: 206.8356s\n",
      "\titers: 900, epoch: 7 | loss: 0.0902536\n",
      "\tspeed: 0.0671s/iter; left time: 195.5969s\n",
      "Epoch: 7 cost time: 66.98382592201233\n",
      "Epoch: 7, Steps: 954 | Train Loss: 0.1157170 Vali Loss: 0.2432739 Test Loss: 0.3114679\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1000718\n",
      "\tspeed: 1.6665s/iter; left time: 4604.4584s\n",
      "\titers: 200, epoch: 8 | loss: 0.1070752\n",
      "\tspeed: 0.0682s/iter; left time: 181.5218s\n",
      "\titers: 300, epoch: 8 | loss: 0.1193575\n",
      "\tspeed: 0.0697s/iter; left time: 178.7567s\n",
      "\titers: 400, epoch: 8 | loss: 0.1288965\n",
      "\tspeed: 0.0674s/iter; left time: 165.9167s\n",
      "\titers: 500, epoch: 8 | loss: 0.1086734\n",
      "\tspeed: 0.0673s/iter; left time: 159.0681s\n",
      "\titers: 600, epoch: 8 | loss: 0.1067028\n",
      "\tspeed: 0.0672s/iter; left time: 152.1429s\n",
      "\titers: 700, epoch: 8 | loss: 0.1158745\n",
      "\tspeed: 0.0668s/iter; left time: 144.5628s\n",
      "\titers: 800, epoch: 8 | loss: 0.1108849\n",
      "\tspeed: 0.0664s/iter; left time: 136.9256s\n",
      "\titers: 900, epoch: 8 | loss: 0.1213330\n",
      "\tspeed: 0.0660s/iter; left time: 129.6536s\n",
      "Epoch: 8 cost time: 65.11969542503357\n",
      "Epoch: 8, Steps: 954 | Train Loss: 0.1134348 Vali Loss: 0.2459007 Test Loss: 0.3230631\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 3) (8735, 1, 24, 3)\n",
      "test shape: (8735, 24, 3) (8735, 24, 3)\n",
      "mse:0.3005976676940918, mae:0.3250570595264435\n",
      "\n",
      "Extracted Part: long_term_forecast__24_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__24_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=3, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=3, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=3, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_48_df_most_important_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=48, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.4947831\n",
      "\tspeed: 0.0868s/iter; left time: 819.0474s\n",
      "\titers: 200, epoch: 1 | loss: 0.3399860\n",
      "\tspeed: 0.0729s/iter; left time: 680.4418s\n",
      "\titers: 300, epoch: 1 | loss: 0.3774102\n",
      "\tspeed: 0.0722s/iter; left time: 666.5583s\n",
      "\titers: 400, epoch: 1 | loss: 0.3484067\n",
      "\tspeed: 0.0716s/iter; left time: 653.8398s\n",
      "\titers: 500, epoch: 1 | loss: 0.3014530\n",
      "\tspeed: 0.0755s/iter; left time: 681.5328s\n",
      "\titers: 600, epoch: 1 | loss: 0.2556416\n",
      "\tspeed: 0.0710s/iter; left time: 634.3021s\n",
      "\titers: 700, epoch: 1 | loss: 0.2265736\n",
      "\tspeed: 0.0735s/iter; left time: 649.1830s\n",
      "\titers: 800, epoch: 1 | loss: 0.2569870\n",
      "\tspeed: 0.0718s/iter; left time: 626.6311s\n",
      "\titers: 900, epoch: 1 | loss: 0.2479905\n",
      "\tspeed: 0.0713s/iter; left time: 615.4348s\n",
      "Epoch: 1 cost time: 70.5468156337738\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.3625237 Vali Loss: 0.3303029 Test Loss: 0.4194180\n",
      "Validation loss decreased (inf --> 0.330303).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2294336\n",
      "\tspeed: 1.6938s/iter; left time: 14360.1182s\n",
      "\titers: 200, epoch: 2 | loss: 0.2461766\n",
      "\tspeed: 0.0720s/iter; left time: 603.2531s\n",
      "\titers: 300, epoch: 2 | loss: 0.2560768\n",
      "\tspeed: 0.0725s/iter; left time: 600.0621s\n",
      "\titers: 400, epoch: 2 | loss: 0.2770925\n",
      "\tspeed: 0.0732s/iter; left time: 598.6423s\n",
      "\titers: 500, epoch: 2 | loss: 0.3806101\n",
      "\tspeed: 0.0732s/iter; left time: 591.1349s\n",
      "\titers: 600, epoch: 2 | loss: 0.2196987\n",
      "\tspeed: 0.0736s/iter; left time: 587.3636s\n",
      "\titers: 700, epoch: 2 | loss: 0.2704328\n",
      "\tspeed: 0.0711s/iter; left time: 560.0699s\n",
      "\titers: 800, epoch: 2 | loss: 0.2357928\n",
      "\tspeed: 0.0730s/iter; left time: 567.9580s\n",
      "\titers: 900, epoch: 2 | loss: 0.3341541\n",
      "\tspeed: 0.0724s/iter; left time: 555.6188s\n",
      "Epoch: 2 cost time: 69.98574495315552\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.2594388 Vali Loss: 0.3709855 Test Loss: 0.4969513\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2199658\n",
      "\tspeed: 1.6573s/iter; left time: 12471.1615s\n",
      "\titers: 200, epoch: 3 | loss: 0.2551757\n",
      "\tspeed: 0.0712s/iter; left time: 528.4313s\n",
      "\titers: 300, epoch: 3 | loss: 0.2090864\n",
      "\tspeed: 0.0716s/iter; left time: 524.1296s\n",
      "\titers: 400, epoch: 3 | loss: 0.3219405\n",
      "\tspeed: 0.0723s/iter; left time: 522.6992s\n",
      "\titers: 500, epoch: 3 | loss: 0.2059031\n",
      "\tspeed: 0.0719s/iter; left time: 512.5169s\n",
      "\titers: 600, epoch: 3 | loss: 0.2108619\n",
      "\tspeed: 0.0741s/iter; left time: 520.3556s\n",
      "\titers: 700, epoch: 3 | loss: 0.1737506\n",
      "\tspeed: 0.0740s/iter; left time: 512.5429s\n",
      "\titers: 800, epoch: 3 | loss: 0.2192276\n",
      "\tspeed: 0.0712s/iter; left time: 485.9969s\n",
      "\titers: 900, epoch: 3 | loss: 0.1984433\n",
      "\tspeed: 0.0728s/iter; left time: 489.8429s\n",
      "Epoch: 3 cost time: 69.45461344718933\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.2236300 Vali Loss: 0.3455983 Test Loss: 0.4306214\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2298089\n",
      "\tspeed: 1.6990s/iter; left time: 11165.5217s\n",
      "\titers: 200, epoch: 4 | loss: 0.1909670\n",
      "\tspeed: 0.0741s/iter; left time: 479.8534s\n",
      "\titers: 300, epoch: 4 | loss: 0.1741229\n",
      "\tspeed: 0.0745s/iter; left time: 474.5673s\n",
      "\titers: 400, epoch: 4 | loss: 0.1862239\n",
      "\tspeed: 0.0719s/iter; left time: 450.9382s\n",
      "\titers: 500, epoch: 4 | loss: 0.1731460\n",
      "\tspeed: 0.0746s/iter; left time: 460.6194s\n",
      "\titers: 600, epoch: 4 | loss: 0.1925493\n",
      "\tspeed: 0.0720s/iter; left time: 437.3997s\n",
      "\titers: 700, epoch: 4 | loss: 0.1664674\n",
      "\tspeed: 0.0716s/iter; left time: 427.5591s\n",
      "\titers: 800, epoch: 4 | loss: 0.2176184\n",
      "\tspeed: 0.0716s/iter; left time: 420.5226s\n",
      "\titers: 900, epoch: 4 | loss: 0.1796983\n",
      "\tspeed: 0.0748s/iter; left time: 431.9964s\n",
      "Epoch: 4 cost time: 70.3837640285492\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.1965490 Vali Loss: 0.3450731 Test Loss: 0.4514112\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 3) (8711, 1, 48, 3)\n",
      "test shape: (8711, 48, 3) (8711, 48, 3)\n",
      "mse:0.41910311579704285, mae:0.41033366322517395\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.5942676\n",
      "\tspeed: 0.0816s/iter; left time: 769.7103s\n",
      "\titers: 200, epoch: 1 | loss: 0.3459440\n",
      "\tspeed: 0.0733s/iter; left time: 683.9139s\n",
      "\titers: 300, epoch: 1 | loss: 0.3591637\n",
      "\tspeed: 0.0752s/iter; left time: 694.5138s\n",
      "\titers: 400, epoch: 1 | loss: 0.3638292\n",
      "\tspeed: 0.0728s/iter; left time: 664.7231s\n",
      "\titers: 500, epoch: 1 | loss: 0.2777740\n",
      "\tspeed: 0.0726s/iter; left time: 655.4156s\n",
      "\titers: 600, epoch: 1 | loss: 0.2884893\n",
      "\tspeed: 0.0738s/iter; left time: 659.1096s\n",
      "\titers: 700, epoch: 1 | loss: 0.2864561\n",
      "\tspeed: 0.0755s/iter; left time: 666.6922s\n",
      "\titers: 800, epoch: 1 | loss: 0.3465585\n",
      "\tspeed: 0.0725s/iter; left time: 633.2547s\n",
      "\titers: 900, epoch: 1 | loss: 0.2545505\n",
      "\tspeed: 0.0726s/iter; left time: 626.7184s\n",
      "Epoch: 1 cost time: 71.05176329612732\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.3760273 Vali Loss: 0.3374059 Test Loss: 0.4081350\n",
      "Validation loss decreased (inf --> 0.337406).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2904187\n",
      "\tspeed: 1.7199s/iter; left time: 14581.5459s\n",
      "\titers: 200, epoch: 2 | loss: 0.2251544\n",
      "\tspeed: 0.0756s/iter; left time: 633.1755s\n",
      "\titers: 300, epoch: 2 | loss: 0.2441740\n",
      "\tspeed: 0.0738s/iter; left time: 610.9419s\n",
      "\titers: 400, epoch: 2 | loss: 0.2290262\n",
      "\tspeed: 0.0748s/iter; left time: 611.8784s\n",
      "\titers: 500, epoch: 2 | loss: 0.2464476\n",
      "\tspeed: 0.0752s/iter; left time: 607.3903s\n",
      "\titers: 600, epoch: 2 | loss: 0.2657027\n",
      "\tspeed: 0.0753s/iter; left time: 600.7260s\n",
      "\titers: 700, epoch: 2 | loss: 0.2740399\n",
      "\tspeed: 0.0787s/iter; left time: 620.3915s\n",
      "\titers: 800, epoch: 2 | loss: 0.2193218\n",
      "\tspeed: 0.0792s/iter; left time: 615.9628s\n",
      "\titers: 900, epoch: 2 | loss: 0.2697219\n",
      "\tspeed: 0.0842s/iter; left time: 646.8630s\n",
      "Epoch: 2 cost time: 74.3230185508728\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.2617627 Vali Loss: 0.3534050 Test Loss: 0.4179718\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1783215\n",
      "\tspeed: 1.7220s/iter; left time: 12958.1526s\n",
      "\titers: 200, epoch: 3 | loss: 0.2119255\n",
      "\tspeed: 0.0732s/iter; left time: 543.7341s\n",
      "\titers: 300, epoch: 3 | loss: 0.1540675\n",
      "\tspeed: 0.0746s/iter; left time: 546.5784s\n",
      "\titers: 400, epoch: 3 | loss: 0.2735644\n",
      "\tspeed: 0.0752s/iter; left time: 543.5970s\n",
      "\titers: 500, epoch: 3 | loss: 0.2368320\n",
      "\tspeed: 0.0758s/iter; left time: 540.4209s\n",
      "\titers: 600, epoch: 3 | loss: 0.2122998\n",
      "\tspeed: 0.0738s/iter; left time: 518.2698s\n",
      "\titers: 700, epoch: 3 | loss: 0.3255269\n",
      "\tspeed: 0.0738s/iter; left time: 511.0708s\n",
      "\titers: 800, epoch: 3 | loss: 0.2161624\n",
      "\tspeed: 0.0747s/iter; left time: 509.8592s\n",
      "\titers: 900, epoch: 3 | loss: 0.2284332\n",
      "\tspeed: 0.0742s/iter; left time: 499.1770s\n",
      "Epoch: 3 cost time: 71.96743845939636\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.2210659 Vali Loss: 0.3458451 Test Loss: 0.4231018\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2273211\n",
      "\tspeed: 1.7099s/iter; left time: 11237.4747s\n",
      "\titers: 200, epoch: 4 | loss: 0.1925080\n",
      "\tspeed: 0.0734s/iter; left time: 475.2086s\n",
      "\titers: 300, epoch: 4 | loss: 0.1679826\n",
      "\tspeed: 0.0752s/iter; left time: 478.9160s\n",
      "\titers: 400, epoch: 4 | loss: 0.2324582\n",
      "\tspeed: 0.0752s/iter; left time: 471.3454s\n",
      "\titers: 500, epoch: 4 | loss: 0.1800382\n",
      "\tspeed: 0.0741s/iter; left time: 457.6055s\n",
      "\titers: 600, epoch: 4 | loss: 0.1811461\n",
      "\tspeed: 0.0745s/iter; left time: 452.4637s\n",
      "\titers: 700, epoch: 4 | loss: 0.1644507\n",
      "\tspeed: 0.0759s/iter; left time: 453.0004s\n",
      "\titers: 800, epoch: 4 | loss: 0.1512504\n",
      "\tspeed: 0.0740s/iter; left time: 434.6041s\n",
      "\titers: 900, epoch: 4 | loss: 0.1854727\n",
      "\tspeed: 0.0746s/iter; left time: 430.4629s\n",
      "Epoch: 4 cost time: 72.03660249710083\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.1913902 Vali Loss: 0.3522579 Test Loss: 0.4805111\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 3) (8711, 1, 48, 3)\n",
      "test shape: (8711, 48, 3) (8711, 48, 3)\n",
      "mse:0.4079429805278778, mae:0.4083959758281708\n",
      "\n",
      "Extracted Part: long_term_forecast__48_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__48_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=3, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=3, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=3, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_96_df_most_important_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.5760780\n",
      "\tspeed: 0.0991s/iter; left time: 934.0824s\n",
      "\titers: 200, epoch: 1 | loss: 0.3795919\n",
      "\tspeed: 0.0850s/iter; left time: 792.6640s\n",
      "\titers: 300, epoch: 1 | loss: 0.3554002\n",
      "\tspeed: 0.0861s/iter; left time: 793.5172s\n",
      "\titers: 400, epoch: 1 | loss: 0.4030716\n",
      "\tspeed: 0.0840s/iter; left time: 766.5081s\n",
      "\titers: 500, epoch: 1 | loss: 0.3292475\n",
      "\tspeed: 0.0849s/iter; left time: 765.5899s\n",
      "\titers: 600, epoch: 1 | loss: 0.3906990\n",
      "\tspeed: 0.0849s/iter; left time: 757.4817s\n",
      "\titers: 700, epoch: 1 | loss: 0.3298019\n",
      "\tspeed: 0.0836s/iter; left time: 737.7001s\n",
      "\titers: 800, epoch: 1 | loss: 0.3621620\n",
      "\tspeed: 0.0834s/iter; left time: 727.0395s\n",
      "\titers: 900, epoch: 1 | loss: 0.2440109\n",
      "\tspeed: 0.0837s/iter; left time: 721.6425s\n",
      "Epoch: 1 cost time: 81.90043044090271\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.4158011 Vali Loss: 0.4130497 Test Loss: 0.5728039\n",
      "Validation loss decreased (inf --> 0.413050).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2437423\n",
      "\tspeed: 1.6866s/iter; left time: 14284.0448s\n",
      "\titers: 200, epoch: 2 | loss: 0.2592677\n",
      "\tspeed: 0.0864s/iter; left time: 723.3518s\n",
      "\titers: 300, epoch: 2 | loss: 0.4460568\n",
      "\tspeed: 0.0851s/iter; left time: 703.4679s\n",
      "\titers: 400, epoch: 2 | loss: 0.3199164\n",
      "\tspeed: 0.0836s/iter; left time: 682.6956s\n",
      "\titers: 500, epoch: 2 | loss: 0.2868301\n",
      "\tspeed: 0.0834s/iter; left time: 673.0743s\n",
      "\titers: 600, epoch: 2 | loss: 0.3138946\n",
      "\tspeed: 0.0838s/iter; left time: 667.7723s\n",
      "\titers: 700, epoch: 2 | loss: 0.3474869\n",
      "\tspeed: 0.0834s/iter; left time: 656.1498s\n",
      "\titers: 800, epoch: 2 | loss: 0.3097253\n",
      "\tspeed: 0.0831s/iter; left time: 645.9707s\n",
      "\titers: 900, epoch: 2 | loss: 0.3018311\n",
      "\tspeed: 0.0835s/iter; left time: 640.0340s\n",
      "Epoch: 2 cost time: 80.53701210021973\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.3111230 Vali Loss: 0.4091030 Test Loss: 0.5292308\n",
      "Validation loss decreased (0.413050 --> 0.409103).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3005141\n",
      "\tspeed: 1.7144s/iter; left time: 12887.2025s\n",
      "\titers: 200, epoch: 3 | loss: 0.2425861\n",
      "\tspeed: 0.0832s/iter; left time: 617.0171s\n",
      "\titers: 300, epoch: 3 | loss: 0.2771462\n",
      "\tspeed: 0.0853s/iter; left time: 624.4984s\n",
      "\titers: 400, epoch: 3 | loss: 0.2477970\n",
      "\tspeed: 0.0834s/iter; left time: 601.5601s\n",
      "\titers: 500, epoch: 3 | loss: 0.3083025\n",
      "\tspeed: 0.0835s/iter; left time: 594.5102s\n",
      "\titers: 600, epoch: 3 | loss: 0.3153781\n",
      "\tspeed: 0.0869s/iter; left time: 610.0726s\n",
      "\titers: 700, epoch: 3 | loss: 0.2627264\n",
      "\tspeed: 0.0834s/iter; left time: 577.0589s\n",
      "\titers: 800, epoch: 3 | loss: 0.2985581\n",
      "\tspeed: 0.0835s/iter; left time: 568.9190s\n",
      "\titers: 900, epoch: 3 | loss: 0.1934946\n",
      "\tspeed: 0.0838s/iter; left time: 562.8355s\n",
      "Epoch: 3 cost time: 80.57177472114563\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.2698338 Vali Loss: 0.4017366 Test Loss: 0.5495641\n",
      "Validation loss decreased (0.409103 --> 0.401737).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2335492\n",
      "\tspeed: 1.7021s/iter; left time: 11174.5509s\n",
      "\titers: 200, epoch: 4 | loss: 0.2248739\n",
      "\tspeed: 0.0840s/iter; left time: 543.2668s\n",
      "\titers: 300, epoch: 4 | loss: 0.2265854\n",
      "\tspeed: 0.0848s/iter; left time: 539.6638s\n",
      "\titers: 400, epoch: 4 | loss: 0.2316777\n",
      "\tspeed: 0.0853s/iter; left time: 534.0987s\n",
      "\titers: 500, epoch: 4 | loss: 0.2147962\n",
      "\tspeed: 0.0834s/iter; left time: 513.9504s\n",
      "\titers: 600, epoch: 4 | loss: 0.2531391\n",
      "\tspeed: 0.0833s/iter; left time: 505.4248s\n",
      "\titers: 700, epoch: 4 | loss: 0.2129237\n",
      "\tspeed: 0.0846s/iter; left time: 504.4712s\n",
      "\titers: 800, epoch: 4 | loss: 0.2321342\n",
      "\tspeed: 0.0835s/iter; left time: 489.6737s\n",
      "\titers: 900, epoch: 4 | loss: 0.2415047\n",
      "\tspeed: 0.0833s/iter; left time: 480.3579s\n",
      "Epoch: 4 cost time: 80.56679010391235\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.2367461 Vali Loss: 0.4097069 Test Loss: 0.5839455\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1873506\n",
      "\tspeed: 1.7209s/iter; left time: 9659.4812s\n",
      "\titers: 200, epoch: 5 | loss: 0.1980049\n",
      "\tspeed: 0.0846s/iter; left time: 466.2673s\n",
      "\titers: 300, epoch: 5 | loss: 0.2650806\n",
      "\tspeed: 0.0868s/iter; left time: 469.5803s\n",
      "\titers: 400, epoch: 5 | loss: 0.1764837\n",
      "\tspeed: 0.0877s/iter; left time: 465.7303s\n",
      "\titers: 500, epoch: 5 | loss: 0.2188104\n",
      "\tspeed: 0.0896s/iter; left time: 467.1625s\n",
      "\titers: 600, epoch: 5 | loss: 0.2832552\n",
      "\tspeed: 0.0880s/iter; left time: 449.9351s\n",
      "\titers: 700, epoch: 5 | loss: 0.2178590\n",
      "\tspeed: 0.0873s/iter; left time: 437.6825s\n",
      "\titers: 800, epoch: 5 | loss: 0.1869754\n",
      "\tspeed: 0.0871s/iter; left time: 427.7888s\n",
      "\titers: 900, epoch: 5 | loss: 0.1851596\n",
      "\tspeed: 0.0981s/iter; left time: 471.9495s\n",
      "Epoch: 5 cost time: 85.26941132545471\n",
      "Epoch: 5, Steps: 952 | Train Loss: 0.2147033 Vali Loss: 0.4287606 Test Loss: 0.6061994\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1966578\n",
      "\tspeed: 1.7107s/iter; left time: 7973.6040s\n",
      "\titers: 200, epoch: 6 | loss: 0.2550942\n",
      "\tspeed: 0.0851s/iter; left time: 388.0757s\n",
      "\titers: 300, epoch: 6 | loss: 0.2342430\n",
      "\tspeed: 0.0853s/iter; left time: 380.6329s\n",
      "\titers: 400, epoch: 6 | loss: 0.2155097\n",
      "\tspeed: 0.0842s/iter; left time: 367.0082s\n",
      "\titers: 500, epoch: 6 | loss: 0.2003654\n",
      "\tspeed: 0.0842s/iter; left time: 358.5684s\n",
      "\titers: 600, epoch: 6 | loss: 0.1798928\n",
      "\tspeed: 0.0842s/iter; left time: 350.4704s\n",
      "\titers: 700, epoch: 6 | loss: 0.2228365\n",
      "\tspeed: 0.0854s/iter; left time: 346.9797s\n",
      "\titers: 800, epoch: 6 | loss: 0.1867958\n",
      "\tspeed: 0.0850s/iter; left time: 336.6669s\n",
      "\titers: 900, epoch: 6 | loss: 0.2035910\n",
      "\tspeed: 0.0856s/iter; left time: 330.6166s\n",
      "Epoch: 6 cost time: 81.6117811203003\n",
      "Epoch: 6, Steps: 952 | Train Loss: 0.2023676 Vali Loss: 0.4366264 Test Loss: 0.6044548\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 3) (8663, 1, 96, 3)\n",
      "test shape: (8663, 96, 3) (8663, 96, 3)\n",
      "mse:0.5494276881217957, mae:0.44576695561408997\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.6375396\n",
      "\tspeed: 0.0904s/iter; left time: 852.0481s\n",
      "\titers: 200, epoch: 1 | loss: 0.4397675\n",
      "\tspeed: 0.0844s/iter; left time: 786.9246s\n",
      "\titers: 300, epoch: 1 | loss: 0.3842961\n",
      "\tspeed: 0.0871s/iter; left time: 802.8056s\n",
      "\titers: 400, epoch: 1 | loss: 0.3720740\n",
      "\tspeed: 0.0864s/iter; left time: 787.9275s\n",
      "\titers: 500, epoch: 1 | loss: 0.3111324\n",
      "\tspeed: 0.0845s/iter; left time: 762.5230s\n",
      "\titers: 600, epoch: 1 | loss: 0.3855393\n",
      "\tspeed: 0.0849s/iter; left time: 757.2890s\n",
      "\titers: 700, epoch: 1 | loss: 0.2512271\n",
      "\tspeed: 0.0878s/iter; left time: 774.7531s\n",
      "\titers: 800, epoch: 1 | loss: 0.3178282\n",
      "\tspeed: 0.0863s/iter; left time: 752.4768s\n",
      "\titers: 900, epoch: 1 | loss: 0.2454650\n",
      "\tspeed: 0.0874s/iter; left time: 753.8951s\n",
      "Epoch: 1 cost time: 82.54312109947205\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.4211591 Vali Loss: 0.4122949 Test Loss: 0.5586355\n",
      "Validation loss decreased (inf --> 0.412295).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2890050\n",
      "\tspeed: 1.7236s/iter; left time: 14597.2466s\n",
      "\titers: 200, epoch: 2 | loss: 0.3896029\n",
      "\tspeed: 0.0888s/iter; left time: 743.5186s\n",
      "\titers: 300, epoch: 2 | loss: 0.2502782\n",
      "\tspeed: 0.0906s/iter; left time: 748.8703s\n",
      "\titers: 400, epoch: 2 | loss: 0.2723255\n",
      "\tspeed: 0.0984s/iter; left time: 803.4820s\n",
      "\titers: 500, epoch: 2 | loss: 0.2945232\n",
      "\tspeed: 0.0933s/iter; left time: 753.0096s\n",
      "\titers: 600, epoch: 2 | loss: 0.2626269\n",
      "\tspeed: 0.0858s/iter; left time: 683.3579s\n",
      "\titers: 700, epoch: 2 | loss: 0.2710239\n",
      "\tspeed: 0.0844s/iter; left time: 664.1902s\n",
      "\titers: 800, epoch: 2 | loss: 0.2524828\n",
      "\tspeed: 0.0878s/iter; left time: 682.3627s\n",
      "\titers: 900, epoch: 2 | loss: 0.2838294\n",
      "\tspeed: 0.0915s/iter; left time: 701.8357s\n",
      "Epoch: 2 cost time: 85.96991467475891\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.3082803 Vali Loss: 0.4173740 Test Loss: 0.5541765\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3166218\n",
      "\tspeed: 1.7139s/iter; left time: 12883.2539s\n",
      "\titers: 200, epoch: 3 | loss: 0.2533204\n",
      "\tspeed: 0.0879s/iter; left time: 652.1459s\n",
      "\titers: 300, epoch: 3 | loss: 0.2337244\n",
      "\tspeed: 0.0874s/iter; left time: 639.7899s\n",
      "\titers: 400, epoch: 3 | loss: 0.2703046\n",
      "\tspeed: 0.0849s/iter; left time: 612.7951s\n",
      "\titers: 500, epoch: 3 | loss: 0.2895947\n",
      "\tspeed: 0.0856s/iter; left time: 608.8819s\n",
      "\titers: 600, epoch: 3 | loss: 0.2713299\n",
      "\tspeed: 0.0851s/iter; left time: 596.9680s\n",
      "\titers: 700, epoch: 3 | loss: 0.3142773\n",
      "\tspeed: 0.0847s/iter; left time: 586.0789s\n",
      "\titers: 800, epoch: 3 | loss: 0.2059990\n",
      "\tspeed: 0.0861s/iter; left time: 587.1556s\n",
      "\titers: 900, epoch: 3 | loss: 0.2867036\n",
      "\tspeed: 0.0850s/iter; left time: 571.0966s\n",
      "Epoch: 3 cost time: 82.70761728286743\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.2650832 Vali Loss: 0.4554992 Test Loss: 0.5777044\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2729027\n",
      "\tspeed: 1.6884s/iter; left time: 11084.2048s\n",
      "\titers: 200, epoch: 4 | loss: 0.2660388\n",
      "\tspeed: 0.0868s/iter; left time: 561.0830s\n",
      "\titers: 300, epoch: 4 | loss: 0.2008140\n",
      "\tspeed: 0.0875s/iter; left time: 556.9973s\n",
      "\titers: 400, epoch: 4 | loss: 0.2436838\n",
      "\tspeed: 0.0862s/iter; left time: 540.2954s\n",
      "\titers: 500, epoch: 4 | loss: 0.3073000\n",
      "\tspeed: 0.0914s/iter; left time: 563.1965s\n",
      "\titers: 600, epoch: 4 | loss: 0.2254767\n",
      "\tspeed: 0.0893s/iter; left time: 541.7989s\n",
      "\titers: 700, epoch: 4 | loss: 0.2544756\n",
      "\tspeed: 0.0892s/iter; left time: 531.7819s\n",
      "\titers: 800, epoch: 4 | loss: 0.2444292\n",
      "\tspeed: 0.0858s/iter; left time: 503.2839s\n",
      "\titers: 900, epoch: 4 | loss: 0.1961796\n",
      "\tspeed: 0.0853s/iter; left time: 491.9870s\n",
      "Epoch: 4 cost time: 84.04768252372742\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.2321059 Vali Loss: 0.4491215 Test Loss: 0.5985995\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 3) (8663, 1, 96, 3)\n",
      "test shape: (8663, 96, 3) (8663, 96, 3)\n",
      "mse:0.5587029457092285, mae:0.46208295226097107\n",
      "\n",
      "Extracted Part: long_term_forecast__96_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__96_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=3, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=3, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=3, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_192_df_most_important_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.7820331\n",
      "\tspeed: 0.1489s/iter; left time: 1398.7591s\n",
      "\titers: 200, epoch: 1 | loss: 0.4751909\n",
      "\tspeed: 0.1380s/iter; left time: 1281.9050s\n",
      "\titers: 300, epoch: 1 | loss: 0.3914768\n",
      "\tspeed: 0.1416s/iter; left time: 1301.1592s\n",
      "\titers: 400, epoch: 1 | loss: 0.4709057\n",
      "\tspeed: 0.1474s/iter; left time: 1339.6354s\n",
      "\titers: 500, epoch: 1 | loss: 0.4189619\n",
      "\tspeed: 0.1410s/iter; left time: 1267.8647s\n",
      "\titers: 600, epoch: 1 | loss: 0.3792740\n",
      "\tspeed: 0.1336s/iter; left time: 1187.6039s\n",
      "\titers: 700, epoch: 1 | loss: 0.3467959\n",
      "\tspeed: 0.1378s/iter; left time: 1211.2592s\n",
      "\titers: 800, epoch: 1 | loss: 0.3332714\n",
      "\tspeed: 0.1396s/iter; left time: 1213.2316s\n",
      "\titers: 900, epoch: 1 | loss: 0.3490864\n",
      "\tspeed: 0.1428s/iter; left time: 1226.6661s\n",
      "Epoch: 1 cost time: 133.98890852928162\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.4596112 Vali Loss: 0.4275362 Test Loss: 0.6005841\n",
      "Validation loss decreased (inf --> 0.427536).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3627777\n",
      "\tspeed: 1.6684s/iter; left time: 14084.9520s\n",
      "\titers: 200, epoch: 2 | loss: 0.3248400\n",
      "\tspeed: 0.1229s/iter; left time: 1025.0476s\n",
      "\titers: 300, epoch: 2 | loss: 0.3187482\n",
      "\tspeed: 0.1226s/iter; left time: 1010.4546s\n",
      "\titers: 400, epoch: 2 | loss: 0.3035946\n",
      "\tspeed: 0.1238s/iter; left time: 1008.3850s\n",
      "\titers: 500, epoch: 2 | loss: 0.3340133\n",
      "\tspeed: 0.1237s/iter; left time: 995.1795s\n",
      "\titers: 600, epoch: 2 | loss: 0.3919866\n",
      "\tspeed: 0.1226s/iter; left time: 973.5575s\n",
      "\titers: 700, epoch: 2 | loss: 0.3170897\n",
      "\tspeed: 0.1233s/iter; left time: 967.2972s\n",
      "\titers: 800, epoch: 2 | loss: 0.3243478\n",
      "\tspeed: 0.1245s/iter; left time: 963.7418s\n",
      "\titers: 900, epoch: 2 | loss: 0.2622808\n",
      "\tspeed: 0.1235s/iter; left time: 943.8561s\n",
      "Epoch: 2 cost time: 117.32773995399475\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.3280862 Vali Loss: 0.4994956 Test Loss: 0.5646729\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2266743\n",
      "\tspeed: 2.4640s/iter; left time: 18462.5415s\n",
      "\titers: 200, epoch: 3 | loss: 0.2858144\n",
      "\tspeed: 0.1363s/iter; left time: 1007.7227s\n",
      "\titers: 300, epoch: 3 | loss: 0.2917936\n",
      "\tspeed: 0.1465s/iter; left time: 1068.4893s\n",
      "\titers: 400, epoch: 3 | loss: 0.2654240\n",
      "\tspeed: 0.1507s/iter; left time: 1084.0804s\n",
      "\titers: 500, epoch: 3 | loss: 0.2537719\n",
      "\tspeed: 0.1408s/iter; left time: 999.0411s\n",
      "\titers: 600, epoch: 3 | loss: 0.2670581\n",
      "\tspeed: 0.1466s/iter; left time: 1025.2402s\n",
      "\titers: 700, epoch: 3 | loss: 0.2675520\n",
      "\tspeed: 0.1463s/iter; left time: 1008.1813s\n",
      "\titers: 800, epoch: 3 | loss: 0.2697260\n",
      "\tspeed: 0.1432s/iter; left time: 972.8599s\n",
      "\titers: 900, epoch: 3 | loss: 0.2182853\n",
      "\tspeed: 0.1391s/iter; left time: 930.8584s\n",
      "Epoch: 3 cost time: 136.41428089141846\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.2732298 Vali Loss: 0.5008235 Test Loss: 0.5895364\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2563602\n",
      "\tspeed: 2.9282s/iter; left time: 19162.3102s\n",
      "\titers: 200, epoch: 4 | loss: 0.2133233\n",
      "\tspeed: 0.1490s/iter; left time: 959.8882s\n",
      "\titers: 300, epoch: 4 | loss: 0.2154693\n",
      "\tspeed: 0.1429s/iter; left time: 906.4830s\n",
      "\titers: 400, epoch: 4 | loss: 0.2323818\n",
      "\tspeed: 0.1447s/iter; left time: 903.6027s\n",
      "\titers: 500, epoch: 4 | loss: 0.2121462\n",
      "\tspeed: 0.1214s/iter; left time: 745.8710s\n",
      "\titers: 600, epoch: 4 | loss: 0.2029511\n",
      "\tspeed: 0.1484s/iter; left time: 897.1999s\n",
      "\titers: 700, epoch: 4 | loss: 0.2161813\n",
      "\tspeed: 0.1461s/iter; left time: 868.2760s\n",
      "\titers: 800, epoch: 4 | loss: 0.1981397\n",
      "\tspeed: 0.1455s/iter; left time: 850.4150s\n",
      "\titers: 900, epoch: 4 | loss: 0.2342406\n",
      "\tspeed: 0.1471s/iter; left time: 844.9244s\n",
      "Epoch: 4 cost time: 136.45932936668396\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.2319090 Vali Loss: 0.5265238 Test Loss: 0.6034769\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 3) (8567, 1, 192, 3)\n",
      "test shape: (8567, 192, 3) (8567, 192, 3)\n",
      "mse:0.6005516052246094, mae:0.4696665406227112\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.8998774\n",
      "\tspeed: 0.1846s/iter; left time: 1733.5161s\n",
      "\titers: 200, epoch: 1 | loss: 0.4828479\n",
      "\tspeed: 0.1834s/iter; left time: 1703.7715s\n",
      "\titers: 300, epoch: 1 | loss: 0.4486383\n",
      "\tspeed: 0.1806s/iter; left time: 1659.4715s\n",
      "\titers: 400, epoch: 1 | loss: 0.3599792\n",
      "\tspeed: 0.1767s/iter; left time: 1606.1316s\n",
      "\titers: 500, epoch: 1 | loss: 0.3968504\n",
      "\tspeed: 0.1690s/iter; left time: 1519.0987s\n",
      "\titers: 600, epoch: 1 | loss: 0.3588940\n",
      "\tspeed: 0.1785s/iter; left time: 1586.9736s\n",
      "\titers: 700, epoch: 1 | loss: 0.3528767\n",
      "\tspeed: 0.1836s/iter; left time: 1613.6964s\n",
      "\titers: 800, epoch: 1 | loss: 0.3343278\n",
      "\tspeed: 0.1893s/iter; left time: 1645.3353s\n",
      "\titers: 900, epoch: 1 | loss: 0.3456652\n",
      "\tspeed: 0.1883s/iter; left time: 1617.5678s\n",
      "Epoch: 1 cost time: 172.29847884178162\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.4616723 Vali Loss: 0.4328429 Test Loss: 0.5979369\n",
      "Validation loss decreased (inf --> 0.432843).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3813852\n",
      "\tspeed: 3.2771s/iter; left time: 27664.9670s\n",
      "\titers: 200, epoch: 2 | loss: 0.3411986\n",
      "\tspeed: 0.1719s/iter; left time: 1433.8014s\n",
      "\titers: 300, epoch: 2 | loss: 0.3549267\n",
      "\tspeed: 0.1825s/iter; left time: 1504.1171s\n",
      "\titers: 400, epoch: 2 | loss: 0.2996150\n",
      "\tspeed: 0.1820s/iter; left time: 1481.8446s\n",
      "\titers: 500, epoch: 2 | loss: 0.2777213\n",
      "\tspeed: 0.1757s/iter; left time: 1413.2310s\n",
      "\titers: 600, epoch: 2 | loss: 0.3064475\n",
      "\tspeed: 0.1746s/iter; left time: 1386.5476s\n",
      "\titers: 700, epoch: 2 | loss: 0.3558201\n",
      "\tspeed: 0.1760s/iter; left time: 1380.5347s\n",
      "\titers: 800, epoch: 2 | loss: 0.2779791\n",
      "\tspeed: 0.1807s/iter; left time: 1399.0240s\n",
      "\titers: 900, epoch: 2 | loss: 0.2878124\n",
      "\tspeed: 0.1853s/iter; left time: 1415.8272s\n",
      "Epoch: 2 cost time: 168.00743556022644\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.3290023 Vali Loss: 0.4749085 Test Loss: 0.5798363\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3091886\n",
      "\tspeed: 3.1689s/iter; left time: 23744.7430s\n",
      "\titers: 200, epoch: 3 | loss: 0.3028897\n",
      "\tspeed: 0.1328s/iter; left time: 982.1398s\n",
      "\titers: 300, epoch: 3 | loss: 0.2435458\n",
      "\tspeed: 0.1432s/iter; left time: 1044.0464s\n",
      "\titers: 400, epoch: 3 | loss: 0.2784395\n",
      "\tspeed: 0.1434s/iter; left time: 1031.8127s\n",
      "\titers: 500, epoch: 3 | loss: 0.2435205\n",
      "\tspeed: 0.1427s/iter; left time: 1012.2948s\n",
      "\titers: 600, epoch: 3 | loss: 0.2579586\n",
      "\tspeed: 0.1459s/iter; left time: 1020.1447s\n",
      "\titers: 700, epoch: 3 | loss: 0.2832144\n",
      "\tspeed: 0.1418s/iter; left time: 977.2617s\n",
      "\titers: 800, epoch: 3 | loss: 0.2496013\n",
      "\tspeed: 0.1403s/iter; left time: 952.8816s\n",
      "\titers: 900, epoch: 3 | loss: 0.2585966\n",
      "\tspeed: 0.1403s/iter; left time: 939.0788s\n",
      "Epoch: 3 cost time: 133.43667817115784\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.2761398 Vali Loss: 0.5034714 Test Loss: 0.6098951\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2789121\n",
      "\tspeed: 2.9280s/iter; left time: 19160.5197s\n",
      "\titers: 200, epoch: 4 | loss: 0.2696958\n",
      "\tspeed: 0.1426s/iter; left time: 918.9241s\n",
      "\titers: 300, epoch: 4 | loss: 0.2352586\n",
      "\tspeed: 0.1387s/iter; left time: 879.9089s\n",
      "\titers: 400, epoch: 4 | loss: 0.2099506\n",
      "\tspeed: 0.1443s/iter; left time: 900.9974s\n",
      "\titers: 500, epoch: 4 | loss: 0.2645361\n",
      "\tspeed: 0.1536s/iter; left time: 943.6097s\n",
      "\titers: 600, epoch: 4 | loss: 0.2554338\n",
      "\tspeed: 0.1359s/iter; left time: 821.4837s\n",
      "\titers: 700, epoch: 4 | loss: 0.2122688\n",
      "\tspeed: 0.1312s/iter; left time: 779.9989s\n",
      "\titers: 800, epoch: 4 | loss: 0.2464209\n",
      "\tspeed: 0.1604s/iter; left time: 937.1790s\n",
      "\titers: 900, epoch: 4 | loss: 0.1989734\n",
      "\tspeed: 0.1449s/iter; left time: 832.4213s\n",
      "Epoch: 4 cost time: 137.35170364379883\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.2364849 Vali Loss: 0.5401061 Test Loss: 0.6228794\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 3) (8567, 1, 192, 3)\n",
      "test shape: (8567, 192, 3) (8567, 192, 3)\n",
      "mse:0.5980015397071838, mae:0.4732331335544586\n",
      "\n",
      "Extracted Part: long_term_forecast__192_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__192_df_most_important_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=21, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_only_generation_columns.csv', dec_in=21, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=21, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_24_df_only_generation_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=24, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.4970494\n",
      "\tspeed: 0.1340s/iter; left time: 1264.8120s\n",
      "\titers: 200, epoch: 1 | loss: 0.4157662\n",
      "\tspeed: 0.1161s/iter; left time: 1084.3975s\n",
      "\titers: 300, epoch: 1 | loss: 0.3324640\n",
      "\tspeed: 0.1210s/iter; left time: 1117.7656s\n",
      "\titers: 400, epoch: 1 | loss: 0.3636383\n",
      "\tspeed: 0.1209s/iter; left time: 1105.5426s\n",
      "\titers: 500, epoch: 1 | loss: 0.3142765\n",
      "\tspeed: 0.1187s/iter; left time: 1072.9426s\n",
      "\titers: 600, epoch: 1 | loss: 0.3398776\n",
      "\tspeed: 0.1213s/iter; left time: 1084.7922s\n",
      "\titers: 700, epoch: 1 | loss: 0.2858424\n",
      "\tspeed: 0.1159s/iter; left time: 1024.2475s\n",
      "\titers: 800, epoch: 1 | loss: 0.3215401\n",
      "\tspeed: 0.1203s/iter; left time: 1051.7116s\n",
      "\titers: 900, epoch: 1 | loss: 0.2568589\n",
      "\tspeed: 0.1144s/iter; left time: 988.8111s\n",
      "Epoch: 1 cost time: 114.74680757522583\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.3816813 Vali Loss: 0.5130521 Test Loss: 0.8134651\n",
      "Validation loss decreased (inf --> 0.513052).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2213002\n",
      "\tspeed: 2.1627s/iter; left time: 18355.0949s\n",
      "\titers: 200, epoch: 2 | loss: 0.2263503\n",
      "\tspeed: 0.1087s/iter; left time: 911.9709s\n",
      "\titers: 300, epoch: 2 | loss: 0.3317213\n",
      "\tspeed: 0.1203s/iter; left time: 996.9372s\n",
      "\titers: 400, epoch: 2 | loss: 0.1945559\n",
      "\tspeed: 0.1127s/iter; left time: 922.7703s\n",
      "\titers: 500, epoch: 2 | loss: 0.2280364\n",
      "\tspeed: 0.1082s/iter; left time: 875.0905s\n",
      "\titers: 600, epoch: 2 | loss: 0.2344607\n",
      "\tspeed: 0.0987s/iter; left time: 788.2604s\n",
      "\titers: 700, epoch: 2 | loss: 0.2493783\n",
      "\tspeed: 0.1016s/iter; left time: 801.2193s\n",
      "\titers: 800, epoch: 2 | loss: 0.2289210\n",
      "\tspeed: 0.1021s/iter; left time: 794.6973s\n",
      "\titers: 900, epoch: 2 | loss: 0.2080201\n",
      "\tspeed: 0.1025s/iter; left time: 787.6451s\n",
      "Epoch: 2 cost time: 103.13805866241455\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.2608639 Vali Loss: 0.5688737 Test Loss: 0.8936830\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1910519\n",
      "\tspeed: 1.6883s/iter; left time: 12718.2461s\n",
      "\titers: 200, epoch: 3 | loss: 0.2627899\n",
      "\tspeed: 0.0794s/iter; left time: 590.0513s\n",
      "\titers: 300, epoch: 3 | loss: 0.2223265\n",
      "\tspeed: 0.0748s/iter; left time: 548.5207s\n",
      "\titers: 400, epoch: 3 | loss: 0.1916230\n",
      "\tspeed: 0.0766s/iter; left time: 553.9146s\n",
      "\titers: 500, epoch: 3 | loss: 0.1928529\n",
      "\tspeed: 0.0799s/iter; left time: 569.6608s\n",
      "\titers: 600, epoch: 3 | loss: 0.1968211\n",
      "\tspeed: 0.0768s/iter; left time: 540.2610s\n",
      "\titers: 700, epoch: 3 | loss: 0.2958678\n",
      "\tspeed: 0.0820s/iter; left time: 568.1867s\n",
      "\titers: 800, epoch: 3 | loss: 0.1741132\n",
      "\tspeed: 0.0822s/iter; left time: 561.5470s\n",
      "\titers: 900, epoch: 3 | loss: 0.1897612\n",
      "\tspeed: 0.0936s/iter; left time: 629.9944s\n",
      "Epoch: 3 cost time: 77.83339929580688\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.2048569 Vali Loss: 0.5912305 Test Loss: 1.0240670\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1679880\n",
      "\tspeed: 1.7187s/iter; left time: 11307.2563s\n",
      "\titers: 200, epoch: 4 | loss: 0.1725513\n",
      "\tspeed: 0.1011s/iter; left time: 655.2115s\n",
      "\titers: 300, epoch: 4 | loss: 0.1808447\n",
      "\tspeed: 0.1034s/iter; left time: 659.8921s\n",
      "\titers: 400, epoch: 4 | loss: 0.1781065\n",
      "\tspeed: 0.0937s/iter; left time: 588.3991s\n",
      "\titers: 500, epoch: 4 | loss: 0.1875107\n",
      "\tspeed: 0.1009s/iter; left time: 623.2434s\n",
      "\titers: 600, epoch: 4 | loss: 0.1699902\n",
      "\tspeed: 0.0934s/iter; left time: 567.6035s\n",
      "\titers: 700, epoch: 4 | loss: 0.1607461\n",
      "\tspeed: 0.0943s/iter; left time: 563.6640s\n",
      "\titers: 800, epoch: 4 | loss: 0.1729813\n",
      "\tspeed: 0.1045s/iter; left time: 614.2834s\n",
      "\titers: 900, epoch: 4 | loss: 0.1957078\n",
      "\tspeed: 0.1026s/iter; left time: 592.8926s\n",
      "Epoch: 4 cost time: 95.69663572311401\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.1725313 Vali Loss: 0.6457179 Test Loss: 1.0899341\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 21) (8735, 1, 24, 21)\n",
      "test shape: (8735, 24, 21) (8735, 24, 21)\n",
      "mse:0.813408374786377, mae:0.5908473134040833\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.4989800\n",
      "\tspeed: 0.1077s/iter; left time: 1017.2511s\n",
      "\titers: 200, epoch: 1 | loss: 0.3879168\n",
      "\tspeed: 0.0913s/iter; left time: 852.3779s\n",
      "\titers: 300, epoch: 1 | loss: 0.4359685\n",
      "\tspeed: 0.0953s/iter; left time: 880.5430s\n",
      "\titers: 400, epoch: 1 | loss: 0.3248253\n",
      "\tspeed: 0.0947s/iter; left time: 865.3538s\n",
      "\titers: 500, epoch: 1 | loss: 0.3038437\n",
      "\tspeed: 0.0971s/iter; left time: 878.1196s\n",
      "\titers: 600, epoch: 1 | loss: 0.2846685\n",
      "\tspeed: 0.0934s/iter; left time: 835.1388s\n",
      "\titers: 700, epoch: 1 | loss: 0.2363172\n",
      "\tspeed: 0.0893s/iter; left time: 789.2546s\n",
      "\titers: 800, epoch: 1 | loss: 0.3568657\n",
      "\tspeed: 0.0770s/iter; left time: 672.6802s\n",
      "\titers: 900, epoch: 1 | loss: 0.2776672\n",
      "\tspeed: 0.0750s/iter; left time: 647.7392s\n",
      "Epoch: 1 cost time: 86.46070981025696\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.3846824 Vali Loss: 0.5127885 Test Loss: 0.8062036\n",
      "Validation loss decreased (inf --> 0.512789).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2596295\n",
      "\tspeed: 1.4541s/iter; left time: 12340.6877s\n",
      "\titers: 200, epoch: 2 | loss: 0.2503251\n",
      "\tspeed: 0.1021s/iter; left time: 856.1935s\n",
      "\titers: 300, epoch: 2 | loss: 0.2542784\n",
      "\tspeed: 0.0958s/iter; left time: 794.1161s\n",
      "\titers: 400, epoch: 2 | loss: 0.2290561\n",
      "\tspeed: 0.1058s/iter; left time: 866.1977s\n",
      "\titers: 500, epoch: 2 | loss: 0.2466641\n",
      "\tspeed: 0.1039s/iter; left time: 840.2743s\n",
      "\titers: 600, epoch: 2 | loss: 0.2878223\n",
      "\tspeed: 0.0974s/iter; left time: 777.8003s\n",
      "\titers: 700, epoch: 2 | loss: 0.2664439\n",
      "\tspeed: 0.0974s/iter; left time: 767.8942s\n",
      "\titers: 800, epoch: 2 | loss: 0.2337512\n",
      "\tspeed: 0.1021s/iter; left time: 795.0639s\n",
      "\titers: 900, epoch: 2 | loss: 0.2174533\n",
      "\tspeed: 0.1013s/iter; left time: 778.6582s\n",
      "Epoch: 2 cost time: 96.51012825965881\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.2591209 Vali Loss: 0.5525206 Test Loss: 0.8628848\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1936200\n",
      "\tspeed: 1.7297s/iter; left time: 13029.8720s\n",
      "\titers: 200, epoch: 3 | loss: 0.1693256\n",
      "\tspeed: 0.0972s/iter; left time: 722.6779s\n",
      "\titers: 300, epoch: 3 | loss: 0.2274860\n",
      "\tspeed: 0.0999s/iter; left time: 732.2886s\n",
      "\titers: 400, epoch: 3 | loss: 0.1884356\n",
      "\tspeed: 0.1049s/iter; left time: 758.5810s\n",
      "\titers: 500, epoch: 3 | loss: 0.1798235\n",
      "\tspeed: 0.1086s/iter; left time: 774.4120s\n",
      "\titers: 600, epoch: 3 | loss: 0.1830242\n",
      "\tspeed: 0.1121s/iter; left time: 788.1976s\n",
      "\titers: 700, epoch: 3 | loss: 0.1631003\n",
      "\tspeed: 0.1110s/iter; left time: 769.2876s\n",
      "\titers: 800, epoch: 3 | loss: 0.1865519\n",
      "\tspeed: 0.1090s/iter; left time: 744.7226s\n",
      "\titers: 900, epoch: 3 | loss: 0.1694303\n",
      "\tspeed: 0.1058s/iter; left time: 712.4067s\n",
      "Epoch: 3 cost time: 100.3538236618042\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.2040148 Vali Loss: 0.5402602 Test Loss: 0.8413464\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1468169\n",
      "\tspeed: 1.5411s/iter; left time: 10138.8237s\n",
      "\titers: 200, epoch: 4 | loss: 0.1690230\n",
      "\tspeed: 0.0813s/iter; left time: 526.7045s\n",
      "\titers: 300, epoch: 4 | loss: 0.1487907\n",
      "\tspeed: 0.0786s/iter; left time: 501.3008s\n",
      "\titers: 400, epoch: 4 | loss: 0.1486514\n",
      "\tspeed: 0.0742s/iter; left time: 465.7569s\n",
      "\titers: 500, epoch: 4 | loss: 0.1683672\n",
      "\tspeed: 0.0795s/iter; left time: 491.1688s\n",
      "\titers: 600, epoch: 4 | loss: 0.1549937\n",
      "\tspeed: 0.0825s/iter; left time: 501.2447s\n",
      "\titers: 700, epoch: 4 | loss: 0.1684549\n",
      "\tspeed: 0.0832s/iter; left time: 497.2899s\n",
      "\titers: 800, epoch: 4 | loss: 0.1917190\n",
      "\tspeed: 0.0813s/iter; left time: 478.0313s\n",
      "\titers: 900, epoch: 4 | loss: 0.1539763\n",
      "\tspeed: 0.0834s/iter; left time: 481.8680s\n",
      "Epoch: 4 cost time: 77.6758964061737\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.1721661 Vali Loss: 0.5794854 Test Loss: 0.9834708\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 21) (8735, 1, 24, 21)\n",
      "test shape: (8735, 24, 21) (8735, 24, 21)\n",
      "mse:0.8061932325363159, mae:0.5790421962738037\n",
      "\n",
      "Extracted Part: long_term_forecast__24_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__24_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=21, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_only_generation_columns.csv', dec_in=21, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=21, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_48_df_only_generation_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=48, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.6340785\n",
      "\tspeed: 0.1155s/iter; left time: 1089.6292s\n",
      "\titers: 200, epoch: 1 | loss: 0.4608192\n",
      "\tspeed: 0.1131s/iter; left time: 1055.4886s\n",
      "\titers: 300, epoch: 1 | loss: 0.4797977\n",
      "\tspeed: 0.1096s/iter; left time: 1011.4489s\n",
      "\titers: 400, epoch: 1 | loss: 0.4876008\n",
      "\tspeed: 0.1076s/iter; left time: 982.8437s\n",
      "\titers: 500, epoch: 1 | loss: 0.4064793\n",
      "\tspeed: 0.0951s/iter; left time: 859.1190s\n",
      "\titers: 600, epoch: 1 | loss: 0.4156716\n",
      "\tspeed: 0.1037s/iter; left time: 925.7236s\n",
      "\titers: 700, epoch: 1 | loss: 0.4524978\n",
      "\tspeed: 0.1004s/iter; left time: 886.9231s\n",
      "\titers: 800, epoch: 1 | loss: 0.3108425\n",
      "\tspeed: 0.0998s/iter; left time: 870.9471s\n",
      "\titers: 900, epoch: 1 | loss: 0.3296126\n",
      "\tspeed: 0.0987s/iter; left time: 851.7840s\n",
      "Epoch: 1 cost time: 99.62791776657104\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.4699612 Vali Loss: 0.7163174 Test Loss: 1.1129408\n",
      "Validation loss decreased (inf --> 0.716317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3457670\n",
      "\tspeed: 1.7176s/iter; left time: 14561.7662s\n",
      "\titers: 200, epoch: 2 | loss: 0.2826612\n",
      "\tspeed: 0.0978s/iter; left time: 819.3597s\n",
      "\titers: 300, epoch: 2 | loss: 0.2656279\n",
      "\tspeed: 0.1026s/iter; left time: 849.0673s\n",
      "\titers: 400, epoch: 2 | loss: 0.3510799\n",
      "\tspeed: 0.1091s/iter; left time: 891.9727s\n",
      "\titers: 500, epoch: 2 | loss: 0.3075909\n",
      "\tspeed: 0.1031s/iter; left time: 832.8023s\n",
      "\titers: 600, epoch: 2 | loss: 0.3163109\n",
      "\tspeed: 0.1039s/iter; left time: 829.0516s\n",
      "\titers: 700, epoch: 2 | loss: 0.3344986\n",
      "\tspeed: 0.1085s/iter; left time: 854.8538s\n",
      "\titers: 800, epoch: 2 | loss: 0.2564925\n",
      "\tspeed: 0.1141s/iter; left time: 887.4296s\n",
      "\titers: 900, epoch: 2 | loss: 0.2805254\n",
      "\tspeed: 0.1121s/iter; left time: 860.4734s\n",
      "Epoch: 2 cost time: 101.59378266334534\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.3163708 Vali Loss: 0.7924200 Test Loss: 1.3222957\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3060685\n",
      "\tspeed: 1.4489s/iter; left time: 10903.0185s\n",
      "\titers: 200, epoch: 3 | loss: 0.2607705\n",
      "\tspeed: 0.0836s/iter; left time: 620.5890s\n",
      "\titers: 300, epoch: 3 | loss: 0.2274999\n",
      "\tspeed: 0.0692s/iter; left time: 506.9707s\n",
      "\titers: 400, epoch: 3 | loss: 0.1948382\n",
      "\tspeed: 0.0730s/iter; left time: 527.4055s\n",
      "\titers: 500, epoch: 3 | loss: 0.2034278\n",
      "\tspeed: 0.0714s/iter; left time: 508.8650s\n",
      "\titers: 600, epoch: 3 | loss: 0.2416977\n",
      "\tspeed: 0.0756s/iter; left time: 530.7784s\n",
      "\titers: 700, epoch: 3 | loss: 0.2340379\n",
      "\tspeed: 0.0825s/iter; left time: 571.0016s\n",
      "\titers: 800, epoch: 3 | loss: 0.2694272\n",
      "\tspeed: 0.0831s/iter; left time: 567.2456s\n",
      "\titers: 900, epoch: 3 | loss: 0.2093962\n",
      "\tspeed: 0.0816s/iter; left time: 548.5875s\n",
      "Epoch: 3 cost time: 74.4950270652771\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.2432841 Vali Loss: 0.7766587 Test Loss: 1.2199839\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2152082\n",
      "\tspeed: 1.6397s/iter; left time: 10775.8475s\n",
      "\titers: 200, epoch: 4 | loss: 0.2356840\n",
      "\tspeed: 0.1133s/iter; left time: 732.9751s\n",
      "\titers: 300, epoch: 4 | loss: 0.2396150\n",
      "\tspeed: 0.1023s/iter; left time: 651.7309s\n",
      "\titers: 400, epoch: 4 | loss: 0.1949007\n",
      "\tspeed: 0.1061s/iter; left time: 665.2782s\n",
      "\titers: 500, epoch: 4 | loss: 0.2079087\n",
      "\tspeed: 0.1131s/iter; left time: 697.7880s\n",
      "\titers: 600, epoch: 4 | loss: 0.1838572\n",
      "\tspeed: 0.1024s/iter; left time: 621.9860s\n",
      "\titers: 700, epoch: 4 | loss: 0.2388611\n",
      "\tspeed: 0.1060s/iter; left time: 632.8493s\n",
      "\titers: 800, epoch: 4 | loss: 0.2402433\n",
      "\tspeed: 0.1006s/iter; left time: 590.6115s\n",
      "\titers: 900, epoch: 4 | loss: 0.2000812\n",
      "\tspeed: 0.1071s/iter; left time: 618.4449s\n",
      "Epoch: 4 cost time: 100.83903169631958\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.2095422 Vali Loss: 0.8639054 Test Loss: 1.4045473\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 21) (8711, 1, 48, 21)\n",
      "test shape: (8711, 48, 21) (8711, 48, 21)\n",
      "mse:1.112667202949524, mae:0.7088061571121216\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.6137921\n",
      "\tspeed: 0.0871s/iter; left time: 821.2591s\n",
      "\titers: 200, epoch: 1 | loss: 0.5018080\n",
      "\tspeed: 0.0806s/iter; left time: 751.7094s\n",
      "\titers: 300, epoch: 1 | loss: 0.4705890\n",
      "\tspeed: 0.0846s/iter; left time: 781.3069s\n",
      "\titers: 400, epoch: 1 | loss: 0.3935365\n",
      "\tspeed: 0.0847s/iter; left time: 773.0817s\n",
      "\titers: 500, epoch: 1 | loss: 0.3638555\n",
      "\tspeed: 0.0843s/iter; left time: 761.7227s\n",
      "\titers: 600, epoch: 1 | loss: 0.3943830\n",
      "\tspeed: 0.0867s/iter; left time: 774.7267s\n",
      "\titers: 700, epoch: 1 | loss: 0.4167935\n",
      "\tspeed: 0.0855s/iter; left time: 755.1381s\n",
      "\titers: 800, epoch: 1 | loss: 0.3451663\n",
      "\tspeed: 0.0854s/iter; left time: 745.3812s\n",
      "\titers: 900, epoch: 1 | loss: 0.3191541\n",
      "\tspeed: 0.0841s/iter; left time: 725.5396s\n",
      "Epoch: 1 cost time: 80.89347672462463\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.4653459 Vali Loss: 0.7571127 Test Loss: 1.2166924\n",
      "Validation loss decreased (inf --> 0.757113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3592105\n",
      "\tspeed: 1.7073s/iter; left time: 14474.6539s\n",
      "\titers: 200, epoch: 2 | loss: 0.3496007\n",
      "\tspeed: 0.1087s/iter; left time: 910.5158s\n",
      "\titers: 300, epoch: 2 | loss: 0.3690518\n",
      "\tspeed: 0.1085s/iter; left time: 897.8793s\n",
      "\titers: 400, epoch: 2 | loss: 0.3764801\n",
      "\tspeed: 0.1130s/iter; left time: 924.3336s\n",
      "\titers: 500, epoch: 2 | loss: 0.3220086\n",
      "\tspeed: 0.1131s/iter; left time: 913.6687s\n",
      "\titers: 600, epoch: 2 | loss: 0.3430429\n",
      "\tspeed: 0.1152s/iter; left time: 918.8142s\n",
      "\titers: 700, epoch: 2 | loss: 0.3360385\n",
      "\tspeed: 0.1086s/iter; left time: 855.4174s\n",
      "\titers: 800, epoch: 2 | loss: 0.2998080\n",
      "\tspeed: 0.1135s/iter; left time: 882.4864s\n",
      "\titers: 900, epoch: 2 | loss: 0.3130454\n",
      "\tspeed: 0.1133s/iter; left time: 870.2248s\n",
      "Epoch: 2 cost time: 106.67680382728577\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.3182035 Vali Loss: 0.7314243 Test Loss: 1.2122459\n",
      "Validation loss decreased (0.757113 --> 0.731424).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2507588\n",
      "\tspeed: 1.8124s/iter; left time: 13638.2972s\n",
      "\titers: 200, epoch: 3 | loss: 0.2786272\n",
      "\tspeed: 0.1169s/iter; left time: 867.7118s\n",
      "\titers: 300, epoch: 3 | loss: 0.2497485\n",
      "\tspeed: 0.1122s/iter; left time: 821.6558s\n",
      "\titers: 400, epoch: 3 | loss: 0.2555096\n",
      "\tspeed: 0.1156s/iter; left time: 835.2630s\n",
      "\titers: 500, epoch: 3 | loss: 0.2053979\n",
      "\tspeed: 0.1110s/iter; left time: 791.1903s\n",
      "\titers: 600, epoch: 3 | loss: 0.2559828\n",
      "\tspeed: 0.1081s/iter; left time: 759.2208s\n",
      "\titers: 700, epoch: 3 | loss: 0.2540897\n",
      "\tspeed: 0.1206s/iter; left time: 834.9334s\n",
      "\titers: 800, epoch: 3 | loss: 0.2097183\n",
      "\tspeed: 0.1100s/iter; left time: 750.9246s\n",
      "\titers: 900, epoch: 3 | loss: 0.2657441\n",
      "\tspeed: 0.1142s/iter; left time: 768.2259s\n",
      "Epoch: 3 cost time: 109.29866933822632\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.2444638 Vali Loss: 0.7337899 Test Loss: 1.2384619\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1725882\n",
      "\tspeed: 1.7450s/iter; left time: 11468.1423s\n",
      "\titers: 200, epoch: 4 | loss: 0.1798379\n",
      "\tspeed: 0.0860s/iter; left time: 556.2907s\n",
      "\titers: 300, epoch: 4 | loss: 0.2156198\n",
      "\tspeed: 0.0838s/iter; left time: 534.0202s\n",
      "\titers: 400, epoch: 4 | loss: 0.2194384\n",
      "\tspeed: 0.0835s/iter; left time: 523.4185s\n",
      "\titers: 500, epoch: 4 | loss: 0.2398751\n",
      "\tspeed: 0.0828s/iter; left time: 511.2121s\n",
      "\titers: 600, epoch: 4 | loss: 0.1980441\n",
      "\tspeed: 0.0840s/iter; left time: 510.0548s\n",
      "\titers: 700, epoch: 4 | loss: 0.1642628\n",
      "\tspeed: 0.0838s/iter; left time: 500.1936s\n",
      "\titers: 800, epoch: 4 | loss: 0.1980352\n",
      "\tspeed: 0.0852s/iter; left time: 500.5872s\n",
      "\titers: 900, epoch: 4 | loss: 0.2060454\n",
      "\tspeed: 0.0829s/iter; left time: 478.7535s\n",
      "Epoch: 4 cost time: 80.84402966499329\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.2104792 Vali Loss: 0.8008674 Test Loss: 1.3533242\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1960401\n",
      "\tspeed: 1.4636s/iter; left time: 8223.7404s\n",
      "\titers: 200, epoch: 5 | loss: 0.1657701\n",
      "\tspeed: 0.0851s/iter; left time: 469.5996s\n",
      "\titers: 300, epoch: 5 | loss: 0.1935472\n",
      "\tspeed: 0.1001s/iter; left time: 542.2019s\n",
      "\titers: 400, epoch: 5 | loss: 0.1993113\n",
      "\tspeed: 0.1140s/iter; left time: 606.2974s\n",
      "\titers: 500, epoch: 5 | loss: 0.2067721\n",
      "\tspeed: 0.1131s/iter; left time: 590.2953s\n",
      "\titers: 600, epoch: 5 | loss: 0.1845563\n",
      "\tspeed: 0.1144s/iter; left time: 585.5901s\n",
      "\titers: 700, epoch: 5 | loss: 0.2000689\n",
      "\tspeed: 0.1115s/iter; left time: 559.8445s\n",
      "\titers: 800, epoch: 5 | loss: 0.1950844\n",
      "\tspeed: 0.1055s/iter; left time: 518.8143s\n",
      "\titers: 900, epoch: 5 | loss: 0.2030411\n",
      "\tspeed: 0.1026s/iter; left time: 494.2335s\n",
      "Epoch: 5 cost time: 98.91045260429382\n",
      "Epoch: 5, Steps: 953 | Train Loss: 0.1920976 Vali Loss: 0.8171709 Test Loss: 1.3852220\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 21) (8711, 1, 48, 21)\n",
      "test shape: (8711, 48, 21) (8711, 48, 21)\n",
      "mse:1.212468147277832, mae:0.7305185198783875\n",
      "\n",
      "Extracted Part: long_term_forecast__48_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__48_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=21, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_only_generation_columns.csv', dec_in=21, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=21, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_96_df_only_generation_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.8089766\n",
      "\tspeed: 0.1337s/iter; left time: 1259.9883s\n",
      "\titers: 200, epoch: 1 | loss: 0.4501925\n",
      "\tspeed: 0.1229s/iter; left time: 1145.3748s\n",
      "\titers: 300, epoch: 1 | loss: 0.5373460\n",
      "\tspeed: 0.1240s/iter; left time: 1143.5596s\n",
      "\titers: 400, epoch: 1 | loss: 0.4777343\n",
      "\tspeed: 0.1245s/iter; left time: 1135.2806s\n",
      "\titers: 500, epoch: 1 | loss: 0.4573356\n",
      "\tspeed: 0.1192s/iter; left time: 1075.4217s\n",
      "\titers: 600, epoch: 1 | loss: 0.4149964\n",
      "\tspeed: 0.1214s/iter; left time: 1082.7133s\n",
      "\titers: 700, epoch: 1 | loss: 0.3768793\n",
      "\tspeed: 0.1246s/iter; left time: 1098.8062s\n",
      "\titers: 800, epoch: 1 | loss: 0.4052552\n",
      "\tspeed: 0.1247s/iter; left time: 1087.6279s\n",
      "\titers: 900, epoch: 1 | loss: 0.4147534\n",
      "\tspeed: 0.1241s/iter; left time: 1069.8364s\n",
      "Epoch: 1 cost time: 118.36638903617859\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.5242637 Vali Loss: 0.8045967 Test Loss: 1.3166329\n",
      "Validation loss decreased (inf --> 0.804597).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3921773\n",
      "\tspeed: 1.6465s/iter; left time: 13943.7904s\n",
      "\titers: 200, epoch: 2 | loss: 0.4051872\n",
      "\tspeed: 0.1015s/iter; left time: 849.8192s\n",
      "\titers: 300, epoch: 2 | loss: 0.3104383\n",
      "\tspeed: 0.1018s/iter; left time: 841.7443s\n",
      "\titers: 400, epoch: 2 | loss: 0.3522615\n",
      "\tspeed: 0.1016s/iter; left time: 829.8620s\n",
      "\titers: 500, epoch: 2 | loss: 0.3487258\n",
      "\tspeed: 0.1015s/iter; left time: 819.3833s\n",
      "\titers: 600, epoch: 2 | loss: 0.3249381\n",
      "\tspeed: 0.1020s/iter; left time: 812.6667s\n",
      "\titers: 700, epoch: 2 | loss: 0.3827959\n",
      "\tspeed: 0.1026s/iter; left time: 807.1642s\n",
      "\titers: 800, epoch: 2 | loss: 0.3199018\n",
      "\tspeed: 0.1021s/iter; left time: 792.9363s\n",
      "\titers: 900, epoch: 2 | loss: 0.3835863\n",
      "\tspeed: 0.1031s/iter; left time: 790.6413s\n",
      "Epoch: 2 cost time: 97.01668405532837\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.3521963 Vali Loss: 0.8719001 Test Loss: 1.3895885\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2619430\n",
      "\tspeed: 1.8377s/iter; left time: 13814.3629s\n",
      "\titers: 200, epoch: 3 | loss: 0.3222249\n",
      "\tspeed: 0.1177s/iter; left time: 872.7654s\n",
      "\titers: 300, epoch: 3 | loss: 0.2910608\n",
      "\tspeed: 0.1160s/iter; left time: 848.5317s\n",
      "\titers: 400, epoch: 3 | loss: 0.3384683\n",
      "\tspeed: 0.1249s/iter; left time: 901.6050s\n",
      "\titers: 500, epoch: 3 | loss: 0.2619576\n",
      "\tspeed: 0.1187s/iter; left time: 844.5351s\n",
      "\titers: 600, epoch: 3 | loss: 0.2754183\n",
      "\tspeed: 0.1222s/iter; left time: 857.3896s\n",
      "\titers: 700, epoch: 3 | loss: 0.2473712\n",
      "\tspeed: 0.1264s/iter; left time: 874.1307s\n",
      "\titers: 800, epoch: 3 | loss: 0.2880812\n",
      "\tspeed: 0.1264s/iter; left time: 861.4203s\n",
      "\titers: 900, epoch: 3 | loss: 0.2840621\n",
      "\tspeed: 0.1279s/iter; left time: 858.9591s\n",
      "Epoch: 3 cost time: 116.85228443145752\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.2763504 Vali Loss: 0.9288978 Test Loss: 1.4185920\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2584261\n",
      "\tspeed: 1.8467s/iter; left time: 12123.4685s\n",
      "\titers: 200, epoch: 4 | loss: 0.2325090\n",
      "\tspeed: 0.1019s/iter; left time: 658.8060s\n",
      "\titers: 300, epoch: 4 | loss: 0.2485206\n",
      "\tspeed: 0.1025s/iter; left time: 652.6503s\n",
      "\titers: 400, epoch: 4 | loss: 0.2619343\n",
      "\tspeed: 0.1016s/iter; left time: 636.5147s\n",
      "\titers: 500, epoch: 4 | loss: 0.2442431\n",
      "\tspeed: 0.0898s/iter; left time: 553.5898s\n",
      "\titers: 600, epoch: 4 | loss: 0.2616167\n",
      "\tspeed: 0.1010s/iter; left time: 612.6951s\n",
      "\titers: 700, epoch: 4 | loss: 0.2469350\n",
      "\tspeed: 0.1039s/iter; left time: 619.7448s\n",
      "\titers: 800, epoch: 4 | loss: 0.2642134\n",
      "\tspeed: 0.1027s/iter; left time: 602.2535s\n",
      "\titers: 900, epoch: 4 | loss: 0.2153736\n",
      "\tspeed: 0.1034s/iter; left time: 595.8159s\n",
      "Epoch: 4 cost time: 96.4627742767334\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.2386328 Vali Loss: 0.9644587 Test Loss: 1.4914950\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 21) (8663, 1, 96, 21)\n",
      "test shape: (8663, 96, 21) (8663, 96, 21)\n",
      "mse:1.3166013956069946, mae:0.7882845997810364\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.7806251\n",
      "\tspeed: 0.1252s/iter; left time: 1179.0728s\n",
      "\titers: 200, epoch: 1 | loss: 0.5440325\n",
      "\tspeed: 0.1235s/iter; left time: 1150.7928s\n",
      "\titers: 300, epoch: 1 | loss: 0.4970377\n",
      "\tspeed: 0.1232s/iter; left time: 1135.9177s\n",
      "\titers: 400, epoch: 1 | loss: 0.4896188\n",
      "\tspeed: 0.1294s/iter; left time: 1180.1557s\n",
      "\titers: 500, epoch: 1 | loss: 0.5223831\n",
      "\tspeed: 0.1262s/iter; left time: 1138.2001s\n",
      "\titers: 600, epoch: 1 | loss: 0.3908894\n",
      "\tspeed: 0.1336s/iter; left time: 1192.2187s\n",
      "\titers: 700, epoch: 1 | loss: 0.3585870\n",
      "\tspeed: 0.1291s/iter; left time: 1138.9366s\n",
      "\titers: 800, epoch: 1 | loss: 0.3900751\n",
      "\tspeed: 0.1272s/iter; left time: 1109.2840s\n",
      "\titers: 900, epoch: 1 | loss: 0.3290035\n",
      "\tspeed: 0.1281s/iter; left time: 1104.6089s\n",
      "Epoch: 1 cost time: 121.34921908378601\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.5259866 Vali Loss: 0.7966085 Test Loss: 1.2026696\n",
      "Validation loss decreased (inf --> 0.796609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3352166\n",
      "\tspeed: 1.9159s/iter; left time: 16225.8700s\n",
      "\titers: 200, epoch: 2 | loss: 0.2746831\n",
      "\tspeed: 0.1051s/iter; left time: 879.7663s\n",
      "\titers: 300, epoch: 2 | loss: 0.3749622\n",
      "\tspeed: 0.1012s/iter; left time: 836.5389s\n",
      "\titers: 400, epoch: 2 | loss: 0.3370252\n",
      "\tspeed: 0.1030s/iter; left time: 841.2202s\n",
      "\titers: 500, epoch: 2 | loss: 0.3304309\n",
      "\tspeed: 0.1035s/iter; left time: 835.0575s\n",
      "\titers: 600, epoch: 2 | loss: 0.3475847\n",
      "\tspeed: 0.1041s/iter; left time: 829.6636s\n",
      "\titers: 700, epoch: 2 | loss: 0.2954451\n",
      "\tspeed: 0.1048s/iter; left time: 824.8256s\n",
      "\titers: 800, epoch: 2 | loss: 0.3548378\n",
      "\tspeed: 0.1039s/iter; left time: 807.0927s\n",
      "\titers: 900, epoch: 2 | loss: 0.2928069\n",
      "\tspeed: 0.1046s/iter; left time: 801.8269s\n",
      "Epoch: 2 cost time: 99.50484228134155\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.3528783 Vali Loss: 0.8352240 Test Loss: 1.3137999\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2815893\n",
      "\tspeed: 1.5069s/iter; left time: 11327.1344s\n",
      "\titers: 200, epoch: 3 | loss: 0.2925559\n",
      "\tspeed: 0.1041s/iter; left time: 771.7653s\n",
      "\titers: 300, epoch: 3 | loss: 0.2845055\n",
      "\tspeed: 0.1174s/iter; left time: 859.2788s\n",
      "\titers: 400, epoch: 3 | loss: 0.3368022\n",
      "\tspeed: 0.1242s/iter; left time: 896.4589s\n",
      "\titers: 500, epoch: 3 | loss: 0.2351069\n",
      "\tspeed: 0.1218s/iter; left time: 867.0344s\n",
      "\titers: 600, epoch: 3 | loss: 0.2914233\n",
      "\tspeed: 0.1232s/iter; left time: 864.5677s\n",
      "\titers: 700, epoch: 3 | loss: 0.2688614\n",
      "\tspeed: 0.1244s/iter; left time: 860.5230s\n",
      "\titers: 800, epoch: 3 | loss: 0.2506707\n",
      "\tspeed: 0.1176s/iter; left time: 801.8825s\n",
      "\titers: 900, epoch: 3 | loss: 0.2685557\n",
      "\tspeed: 0.1215s/iter; left time: 816.1242s\n",
      "Epoch: 3 cost time: 112.80380940437317\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.2800846 Vali Loss: 0.9060774 Test Loss: 1.4318841\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2341723\n",
      "\tspeed: 1.9891s/iter; left time: 13058.4393s\n",
      "\titers: 200, epoch: 4 | loss: 0.2413999\n",
      "\tspeed: 0.1176s/iter; left time: 759.9670s\n",
      "\titers: 300, epoch: 4 | loss: 0.2520123\n",
      "\tspeed: 0.1296s/iter; left time: 824.8183s\n",
      "\titers: 400, epoch: 4 | loss: 0.2355975\n",
      "\tspeed: 0.1288s/iter; left time: 806.9474s\n",
      "\titers: 500, epoch: 4 | loss: 0.2412702\n",
      "\tspeed: 0.1274s/iter; left time: 785.5421s\n",
      "\titers: 600, epoch: 4 | loss: 0.2507754\n",
      "\tspeed: 0.1269s/iter; left time: 769.6556s\n",
      "\titers: 700, epoch: 4 | loss: 0.2539033\n",
      "\tspeed: 0.1283s/iter; left time: 765.2038s\n",
      "\titers: 800, epoch: 4 | loss: 0.2130834\n",
      "\tspeed: 0.1214s/iter; left time: 711.7616s\n",
      "\titers: 900, epoch: 4 | loss: 0.2628781\n",
      "\tspeed: 0.1222s/iter; left time: 704.5040s\n",
      "Epoch: 4 cost time: 120.18477821350098\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.2431386 Vali Loss: 0.9092759 Test Loss: 1.3943096\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 21) (8663, 1, 96, 21)\n",
      "test shape: (8663, 96, 21) (8663, 96, 21)\n",
      "mse:1.2027889490127563, mae:0.7211087942123413\n",
      "\n",
      "Extracted Part: long_term_forecast__96_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__96_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=21, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_only_generation_columns.csv', dec_in=21, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=21, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_192_df_only_generation_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.8116308\n",
      "\tspeed: 0.1357s/iter; left time: 1274.4862s\n",
      "\titers: 200, epoch: 1 | loss: 0.6625121\n",
      "\tspeed: 0.1232s/iter; left time: 1144.6655s\n",
      "\titers: 300, epoch: 1 | loss: 0.5154924\n",
      "\tspeed: 0.1146s/iter; left time: 1053.2784s\n",
      "\titers: 400, epoch: 1 | loss: 0.4378469\n",
      "\tspeed: 0.1216s/iter; left time: 1105.7492s\n",
      "\titers: 500, epoch: 1 | loss: 0.4819108\n",
      "\tspeed: 0.1247s/iter; left time: 1121.0609s\n",
      "\titers: 600, epoch: 1 | loss: 0.5322217\n",
      "\tspeed: 0.1273s/iter; left time: 1131.6490s\n",
      "\titers: 700, epoch: 1 | loss: 0.4540476\n",
      "\tspeed: 0.1244s/iter; left time: 1093.8739s\n",
      "\titers: 800, epoch: 1 | loss: 0.4251911\n",
      "\tspeed: 0.1257s/iter; left time: 1092.6525s\n",
      "\titers: 900, epoch: 1 | loss: 0.4325361\n",
      "\tspeed: 0.1244s/iter; left time: 1069.0009s\n",
      "Epoch: 1 cost time: 118.3980119228363\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.5627742 Vali Loss: 0.7971871 Test Loss: 1.3372031\n",
      "Validation loss decreased (inf --> 0.797187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3916351\n",
      "\tspeed: 1.5769s/iter; left time: 13312.4928s\n",
      "\titers: 200, epoch: 2 | loss: 0.3503585\n",
      "\tspeed: 0.1264s/iter; left time: 1054.2827s\n",
      "\titers: 300, epoch: 2 | loss: 0.4429501\n",
      "\tspeed: 0.1254s/iter; left time: 1033.3892s\n",
      "\titers: 400, epoch: 2 | loss: 0.3620201\n",
      "\tspeed: 0.1257s/iter; left time: 1023.5664s\n",
      "\titers: 500, epoch: 2 | loss: 0.3954285\n",
      "\tspeed: 0.1253s/iter; left time: 1007.3877s\n",
      "\titers: 600, epoch: 2 | loss: 0.3602996\n",
      "\tspeed: 0.1261s/iter; left time: 1001.6627s\n",
      "\titers: 700, epoch: 2 | loss: 0.3338280\n",
      "\tspeed: 0.1328s/iter; left time: 1041.1711s\n",
      "\titers: 800, epoch: 2 | loss: 0.3440053\n",
      "\tspeed: 0.1530s/iter; left time: 1184.8731s\n",
      "\titers: 900, epoch: 2 | loss: 0.3576763\n",
      "\tspeed: 0.1628s/iter; left time: 1244.2680s\n",
      "Epoch: 2 cost time: 128.2944347858429\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.3718791 Vali Loss: 0.9490306 Test Loss: 1.4609127\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3414046\n",
      "\tspeed: 3.4060s/iter; left time: 25521.5302s\n",
      "\titers: 200, epoch: 3 | loss: 0.2788346\n",
      "\tspeed: 0.1605s/iter; left time: 1186.7410s\n",
      "\titers: 300, epoch: 3 | loss: 0.2898973\n",
      "\tspeed: 0.1699s/iter; left time: 1238.8527s\n",
      "\titers: 400, epoch: 3 | loss: 0.2850887\n",
      "\tspeed: 0.1718s/iter; left time: 1235.6762s\n",
      "\titers: 500, epoch: 3 | loss: 0.2766717\n",
      "\tspeed: 0.1660s/iter; left time: 1177.7138s\n",
      "\titers: 600, epoch: 3 | loss: 0.3445956\n",
      "\tspeed: 0.1566s/iter; left time: 1095.3285s\n",
      "\titers: 700, epoch: 3 | loss: 0.2758915\n",
      "\tspeed: 0.1571s/iter; left time: 1082.9873s\n",
      "\titers: 800, epoch: 3 | loss: 0.2832014\n",
      "\tspeed: 0.1579s/iter; left time: 1072.5130s\n",
      "\titers: 900, epoch: 3 | loss: 0.2537037\n",
      "\tspeed: 0.1517s/iter; left time: 1015.2965s\n",
      "Epoch: 3 cost time: 153.30840349197388\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.2916740 Vali Loss: 1.0126442 Test Loss: 1.5400621\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2803013\n",
      "\tspeed: 3.0872s/iter; left time: 20202.7867s\n",
      "\titers: 200, epoch: 4 | loss: 0.2846083\n",
      "\tspeed: 0.1245s/iter; left time: 802.1892s\n",
      "\titers: 300, epoch: 4 | loss: 0.2508963\n",
      "\tspeed: 0.1260s/iter; left time: 799.1091s\n",
      "\titers: 400, epoch: 4 | loss: 0.2462735\n",
      "\tspeed: 0.1243s/iter; left time: 776.2030s\n",
      "\titers: 500, epoch: 4 | loss: 0.2524271\n",
      "\tspeed: 0.1148s/iter; left time: 705.1519s\n",
      "\titers: 600, epoch: 4 | loss: 0.2508734\n",
      "\tspeed: 0.1250s/iter; left time: 755.6254s\n",
      "\titers: 700, epoch: 4 | loss: 0.2387749\n",
      "\tspeed: 0.1233s/iter; left time: 732.6970s\n",
      "\titers: 800, epoch: 4 | loss: 0.2583393\n",
      "\tspeed: 0.1237s/iter; left time: 723.1275s\n",
      "\titers: 900, epoch: 4 | loss: 0.2350561\n",
      "\tspeed: 0.1248s/iter; left time: 716.9352s\n",
      "Epoch: 4 cost time: 117.55514740943909\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.2520108 Vali Loss: 1.0132768 Test Loss: 1.5514582\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 21) (8567, 1, 192, 21)\n",
      "test shape: (8567, 192, 21) (8567, 192, 21)\n",
      "mse:1.3373079299926758, mae:0.7494999170303345\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.7923715\n",
      "\tspeed: 0.1801s/iter; left time: 1691.4734s\n",
      "\titers: 200, epoch: 1 | loss: 0.6400296\n",
      "\tspeed: 0.1632s/iter; left time: 1516.5715s\n",
      "\titers: 300, epoch: 1 | loss: 0.5724365\n",
      "\tspeed: 0.1661s/iter; left time: 1526.7324s\n",
      "\titers: 400, epoch: 1 | loss: 0.5610706\n",
      "\tspeed: 0.1570s/iter; left time: 1426.9934s\n",
      "\titers: 500, epoch: 1 | loss: 0.4338931\n",
      "\tspeed: 0.1570s/iter; left time: 1411.9017s\n",
      "\titers: 600, epoch: 1 | loss: 0.4365115\n",
      "\tspeed: 0.1564s/iter; left time: 1390.6231s\n",
      "\titers: 700, epoch: 1 | loss: 0.4635203\n",
      "\tspeed: 0.1530s/iter; left time: 1345.2727s\n",
      "\titers: 800, epoch: 1 | loss: 0.4310736\n",
      "\tspeed: 0.1565s/iter; left time: 1359.8442s\n",
      "\titers: 900, epoch: 1 | loss: 0.3818824\n",
      "\tspeed: 0.1613s/iter; left time: 1385.9551s\n",
      "Epoch: 1 cost time: 153.81700825691223\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.5545828 Vali Loss: 0.8116171 Test Loss: 1.3467610\n",
      "Validation loss decreased (inf --> 0.811617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3691622\n",
      "\tspeed: 3.3686s/iter; left time: 28438.1277s\n",
      "\titers: 200, epoch: 2 | loss: 0.4096893\n",
      "\tspeed: 0.1545s/iter; left time: 1289.0404s\n",
      "\titers: 300, epoch: 2 | loss: 0.4466930\n",
      "\tspeed: 0.1616s/iter; left time: 1331.8954s\n",
      "\titers: 400, epoch: 2 | loss: 0.4241002\n",
      "\tspeed: 0.1542s/iter; left time: 1255.7512s\n",
      "\titers: 500, epoch: 2 | loss: 0.3190912\n",
      "\tspeed: 0.1496s/iter; left time: 1202.8286s\n",
      "\titers: 600, epoch: 2 | loss: 0.3446817\n",
      "\tspeed: 0.1267s/iter; left time: 1006.1654s\n",
      "\titers: 700, epoch: 2 | loss: 0.3814688\n",
      "\tspeed: 0.1271s/iter; left time: 996.6831s\n",
      "\titers: 800, epoch: 2 | loss: 0.3499019\n",
      "\tspeed: 0.1297s/iter; left time: 1003.9167s\n",
      "\titers: 900, epoch: 2 | loss: 0.3346621\n",
      "\tspeed: 0.1225s/iter; left time: 936.4014s\n",
      "Epoch: 2 cost time: 135.4224989414215\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.3720620 Vali Loss: 0.9196419 Test Loss: 1.4561087\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2864945\n",
      "\tspeed: 1.6308s/iter; left time: 12219.5777s\n",
      "\titers: 200, epoch: 3 | loss: 0.2790862\n",
      "\tspeed: 0.1283s/iter; left time: 948.6888s\n",
      "\titers: 300, epoch: 3 | loss: 0.2804669\n",
      "\tspeed: 0.1260s/iter; left time: 918.6094s\n",
      "\titers: 400, epoch: 3 | loss: 0.3055105\n",
      "\tspeed: 0.1269s/iter; left time: 913.0667s\n",
      "\titers: 500, epoch: 3 | loss: 0.2979725\n",
      "\tspeed: 0.1241s/iter; left time: 880.0683s\n",
      "\titers: 600, epoch: 3 | loss: 0.2974136\n",
      "\tspeed: 0.1251s/iter; left time: 874.6075s\n",
      "\titers: 700, epoch: 3 | loss: 0.2676938\n",
      "\tspeed: 0.1286s/iter; left time: 886.4998s\n",
      "\titers: 800, epoch: 3 | loss: 0.2485688\n",
      "\tspeed: 0.1247s/iter; left time: 847.2402s\n",
      "\titers: 900, epoch: 3 | loss: 0.2936192\n",
      "\tspeed: 0.1267s/iter; left time: 847.9222s\n",
      "Epoch: 3 cost time: 120.75669431686401\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.2926233 Vali Loss: 0.9871745 Test Loss: 1.5994971\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2486688\n",
      "\tspeed: 3.3160s/iter; left time: 21699.6382s\n",
      "\titers: 200, epoch: 4 | loss: 0.2728274\n",
      "\tspeed: 0.1559s/iter; left time: 1004.4031s\n",
      "\titers: 300, epoch: 4 | loss: 0.2392611\n",
      "\tspeed: 0.1580s/iter; left time: 1002.5065s\n",
      "\titers: 400, epoch: 4 | loss: 0.2464463\n",
      "\tspeed: 0.1540s/iter; left time: 961.3648s\n",
      "\titers: 500, epoch: 4 | loss: 0.2370370\n",
      "\tspeed: 0.1536s/iter; left time: 943.6957s\n",
      "\titers: 600, epoch: 4 | loss: 0.2534043\n",
      "\tspeed: 0.1548s/iter; left time: 935.9119s\n",
      "\titers: 700, epoch: 4 | loss: 0.2416738\n",
      "\tspeed: 0.1554s/iter; left time: 923.6989s\n",
      "\titers: 800, epoch: 4 | loss: 0.2334326\n",
      "\tspeed: 0.1698s/iter; left time: 992.3393s\n",
      "\titers: 900, epoch: 4 | loss: 0.2346470\n",
      "\tspeed: 0.1736s/iter; left time: 997.3619s\n",
      "Epoch: 4 cost time: 154.00341987609863\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.2534546 Vali Loss: 1.0103891 Test Loss: 1.7049199\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 21) (8567, 1, 192, 21)\n",
      "test shape: (8567, 192, 21) (8567, 192, 21)\n",
      "mse:1.3467572927474976, mae:0.756934642791748\n",
      "\n",
      "Extracted Part: long_term_forecast__192_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__192_df_only_generation_columns_Informer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n"
     ]
    }
   ],
   "source": [
    "# List of data paths and prediction lengths for the grid search\n",
    "data_paths = [\"df_all_columns.csv\", \"df_most_important_columns.csv\", \"df_only_generation_columns.csv\"]\n",
    "prediction_lengths = [\"24\", \"48\", \"96\", \"192\"]\n",
    "for data_path in data_paths:\n",
    "    full_data_path = \"../../../01_datasets/\" + data_path\n",
    "    df = pd.read_csv(full_data_path)\n",
    "    num_columns = len(df.columns)\n",
    "    for pred_len in prediction_lengths:\n",
    "        # Define the script arguments as a list\n",
    "        model_id = f\"_{pred_len}_{data_path.replace('.csv', '')}\"  # Create the model_id\n",
    "        script_arguments = [\n",
    "            \"--task_name\", \"long_term_forecast\",\n",
    "            \"--is_training\", \"1\",\n",
    "            \"--root_path\", \"../../../01_datasets/\",\n",
    "            \"--data_path\", data_path,\n",
    "            \"--model_id\", model_id,\n",
    "            \"--model\", \"Informer\",\n",
    "            \"--data\", \"custom\",\n",
    "            \"--features\", \"M\",\n",
    "            \"--seq_len\", \"96\",\n",
    "            \"--label_len\", \"48\",\n",
    "            \"--pred_len\", pred_len,\n",
    "            \"--e_layers\", \"2\",\n",
    "            \"--d_layers\", \"5\",\n",
    "            \"--factor\", \"5\",\n",
    "            \"--enc_in\", str((num_columns)-1),\n",
    "            \"--dec_in\", str((num_columns)-1),\n",
    "            \"--c_out\", str((num_columns)-1),\n",
    "            \"--des\", \"Exp\",\n",
    "            \"--itr\", \"2\"\n",
    "        ]\n",
    "\n",
    "        script_output = run_and_capture_script_output(script_path, script_arguments)\n",
    "\n",
    "        print(\"Captured Output:\")\n",
    "        print(script_output)\n",
    "\n",
    "        # Extract and save the prints related to the settings variable\n",
    "        settings_prints = extract_settings_prints(script_output.splitlines())\n",
    "\n",
    "        matched_patterns = pattern_matching(settings_prints)\n",
    "\n",
    "        summarize_results(matched_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56297b80-d711-4a56-a05b-c2c3692633b1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=1, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=1, factor=5, features='S', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_24_DE_solar_generation_actual', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=24, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='DE_solar_generation_actual', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.1576255\n",
      "\tspeed: 0.0810s/iter; left time: 765.0343s\n",
      "\titers: 200, epoch: 1 | loss: 0.1927280\n",
      "\tspeed: 0.0736s/iter; left time: 687.2393s\n",
      "\titers: 300, epoch: 1 | loss: 0.1379473\n",
      "\tspeed: 0.0687s/iter; left time: 634.5465s\n",
      "\titers: 400, epoch: 1 | loss: 0.1406980\n",
      "\tspeed: 0.0663s/iter; left time: 606.1865s\n",
      "\titers: 500, epoch: 1 | loss: 0.1191094\n",
      "\tspeed: 0.0658s/iter; left time: 595.0642s\n",
      "\titers: 600, epoch: 1 | loss: 0.0930722\n",
      "\tspeed: 0.0663s/iter; left time: 592.8165s\n",
      "\titers: 700, epoch: 1 | loss: 0.0942083\n",
      "\tspeed: 0.0670s/iter; left time: 591.9974s\n",
      "\titers: 800, epoch: 1 | loss: 0.0960237\n",
      "\tspeed: 0.0677s/iter; left time: 591.6303s\n",
      "\titers: 900, epoch: 1 | loss: 0.0630061\n",
      "\tspeed: 0.0672s/iter; left time: 581.0566s\n",
      "Epoch: 1 cost time: 66.03292536735535\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.1468870 Vali Loss: 0.0934168 Test Loss: 0.1185988\n",
      "Validation loss decreased (inf --> 0.093417).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0971553\n",
      "\tspeed: 1.6919s/iter; left time: 14359.1884s\n",
      "\titers: 200, epoch: 2 | loss: 0.1590633\n",
      "\tspeed: 0.0659s/iter; left time: 553.0608s\n",
      "\titers: 300, epoch: 2 | loss: 0.0955668\n",
      "\tspeed: 0.0664s/iter; left time: 549.9481s\n",
      "\titers: 400, epoch: 2 | loss: 0.1089938\n",
      "\tspeed: 0.0667s/iter; left time: 546.3746s\n",
      "\titers: 500, epoch: 2 | loss: 0.0784482\n",
      "\tspeed: 0.0694s/iter; left time: 561.4553s\n",
      "\titers: 600, epoch: 2 | loss: 0.0853942\n",
      "\tspeed: 0.0686s/iter; left time: 548.0977s\n",
      "\titers: 700, epoch: 2 | loss: 0.0902706\n",
      "\tspeed: 0.0708s/iter; left time: 558.4083s\n",
      "\titers: 800, epoch: 2 | loss: 0.0756701\n",
      "\tspeed: 0.0684s/iter; left time: 532.9708s\n",
      "\titers: 900, epoch: 2 | loss: 0.0815669\n",
      "\tspeed: 0.0674s/iter; left time: 518.1323s\n",
      "Epoch: 2 cost time: 65.33869171142578\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.0937176 Vali Loss: 0.0936839 Test Loss: 0.1190624\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0794742\n",
      "\tspeed: 1.6858s/iter; left time: 12699.2731s\n",
      "\titers: 200, epoch: 3 | loss: 0.0626693\n",
      "\tspeed: 0.0704s/iter; left time: 523.2216s\n",
      "\titers: 300, epoch: 3 | loss: 0.0950216\n",
      "\tspeed: 0.0673s/iter; left time: 493.2068s\n",
      "\titers: 400, epoch: 3 | loss: 0.0761715\n",
      "\tspeed: 0.0676s/iter; left time: 489.2854s\n",
      "\titers: 500, epoch: 3 | loss: 0.0626284\n",
      "\tspeed: 0.0678s/iter; left time: 483.8311s\n",
      "\titers: 600, epoch: 3 | loss: 0.0706896\n",
      "\tspeed: 0.0702s/iter; left time: 493.4549s\n",
      "\titers: 700, epoch: 3 | loss: 0.0802737\n",
      "\tspeed: 0.0685s/iter; left time: 474.5922s\n",
      "\titers: 800, epoch: 3 | loss: 0.0938855\n",
      "\tspeed: 0.0678s/iter; left time: 463.1942s\n",
      "\titers: 900, epoch: 3 | loss: 0.0804001\n",
      "\tspeed: 0.0681s/iter; left time: 458.5274s\n",
      "Epoch: 3 cost time: 65.8834958076477\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.0809890 Vali Loss: 0.0832724 Test Loss: 0.1109960\n",
      "Validation loss decreased (0.093417 --> 0.083272).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0774109\n",
      "\tspeed: 1.5390s/iter; left time: 10125.1955s\n",
      "\titers: 200, epoch: 4 | loss: 0.0604938\n",
      "\tspeed: 0.0801s/iter; left time: 518.7116s\n",
      "\titers: 300, epoch: 4 | loss: 0.0909505\n",
      "\tspeed: 0.0806s/iter; left time: 513.8529s\n",
      "\titers: 400, epoch: 4 | loss: 0.1171887\n",
      "\tspeed: 0.0812s/iter; left time: 509.8883s\n",
      "\titers: 500, epoch: 4 | loss: 0.0709813\n",
      "\tspeed: 0.0790s/iter; left time: 487.8861s\n",
      "\titers: 600, epoch: 4 | loss: 0.0714017\n",
      "\tspeed: 0.0796s/iter; left time: 483.7295s\n",
      "\titers: 700, epoch: 4 | loss: 0.0958363\n",
      "\tspeed: 0.0784s/iter; left time: 468.6978s\n",
      "\titers: 800, epoch: 4 | loss: 0.0631916\n",
      "\tspeed: 0.0783s/iter; left time: 460.3877s\n",
      "\titers: 900, epoch: 4 | loss: 0.0946714\n",
      "\tspeed: 0.0797s/iter; left time: 460.8152s\n",
      "Epoch: 4 cost time: 76.34948062896729\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.0754957 Vali Loss: 0.0793750 Test Loss: 0.1052997\n",
      "Validation loss decreased (0.083272 --> 0.079375).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0884280\n",
      "\tspeed: 1.4923s/iter; left time: 8394.0053s\n",
      "\titers: 200, epoch: 5 | loss: 0.0528055\n",
      "\tspeed: 0.0701s/iter; left time: 387.3632s\n",
      "\titers: 300, epoch: 5 | loss: 0.1092380\n",
      "\tspeed: 0.0688s/iter; left time: 373.3393s\n",
      "\titers: 400, epoch: 5 | loss: 0.0493104\n",
      "\tspeed: 0.0686s/iter; left time: 365.0929s\n",
      "\titers: 500, epoch: 5 | loss: 0.1078867\n",
      "\tspeed: 0.0689s/iter; left time: 359.9732s\n",
      "\titers: 600, epoch: 5 | loss: 0.0657384\n",
      "\tspeed: 0.0692s/iter; left time: 354.4413s\n",
      "\titers: 700, epoch: 5 | loss: 0.0688443\n",
      "\tspeed: 0.0687s/iter; left time: 345.3882s\n",
      "\titers: 800, epoch: 5 | loss: 0.0790164\n",
      "\tspeed: 0.0686s/iter; left time: 338.0946s\n",
      "\titers: 900, epoch: 5 | loss: 0.0798088\n",
      "\tspeed: 0.0707s/iter; left time: 340.9144s\n",
      "Epoch: 5 cost time: 66.64456725120544\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.0723245 Vali Loss: 0.0786889 Test Loss: 0.1027972\n",
      "Validation loss decreased (0.079375 --> 0.078689).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1639964\n",
      "\tspeed: 1.6972s/iter; left time: 7927.8091s\n",
      "\titers: 200, epoch: 6 | loss: 0.0658485\n",
      "\tspeed: 0.0687s/iter; left time: 314.0316s\n",
      "\titers: 300, epoch: 6 | loss: 0.1413490\n",
      "\tspeed: 0.0663s/iter; left time: 296.5113s\n",
      "\titers: 400, epoch: 6 | loss: 0.0830060\n",
      "\tspeed: 0.0661s/iter; left time: 288.7979s\n",
      "\titers: 500, epoch: 6 | loss: 0.0527312\n",
      "\tspeed: 0.0673s/iter; left time: 287.6268s\n",
      "\titers: 600, epoch: 6 | loss: 0.0448766\n",
      "\tspeed: 0.0667s/iter; left time: 278.0051s\n",
      "\titers: 700, epoch: 6 | loss: 0.0632078\n",
      "\tspeed: 0.0658s/iter; left time: 267.7274s\n",
      "\titers: 800, epoch: 6 | loss: 0.0512046\n",
      "\tspeed: 0.0667s/iter; left time: 264.7237s\n",
      "\titers: 900, epoch: 6 | loss: 0.0468383\n",
      "\tspeed: 0.0701s/iter; left time: 271.4976s\n",
      "Epoch: 6 cost time: 64.59292674064636\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.0699862 Vali Loss: 0.0733904 Test Loss: 0.0978244\n",
      "Validation loss decreased (0.078689 --> 0.073390).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1026074\n",
      "\tspeed: 1.6926s/iter; left time: 6291.3887s\n",
      "\titers: 200, epoch: 7 | loss: 0.0830276\n",
      "\tspeed: 0.0688s/iter; left time: 249.0215s\n",
      "\titers: 300, epoch: 7 | loss: 0.0957270\n",
      "\tspeed: 0.0682s/iter; left time: 239.7062s\n",
      "\titers: 400, epoch: 7 | loss: 0.0532155\n",
      "\tspeed: 0.0683s/iter; left time: 233.5062s\n",
      "\titers: 500, epoch: 7 | loss: 0.0522668\n",
      "\tspeed: 0.0699s/iter; left time: 231.8216s\n",
      "\titers: 600, epoch: 7 | loss: 0.0424486\n",
      "\tspeed: 0.0698s/iter; left time: 224.5543s\n",
      "\titers: 700, epoch: 7 | loss: 0.0596162\n",
      "\tspeed: 0.0685s/iter; left time: 213.3828s\n",
      "\titers: 800, epoch: 7 | loss: 0.0927095\n",
      "\tspeed: 0.0706s/iter; left time: 212.9925s\n",
      "\titers: 900, epoch: 7 | loss: 0.0813328\n",
      "\tspeed: 0.0667s/iter; left time: 194.6761s\n",
      "Epoch: 7 cost time: 66.03270196914673\n",
      "Epoch: 7, Steps: 954 | Train Loss: 0.0688980 Vali Loss: 0.0777837 Test Loss: 0.1021453\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0592893\n",
      "\tspeed: 1.6837s/iter; left time: 4651.9492s\n",
      "\titers: 200, epoch: 8 | loss: 0.0842302\n",
      "\tspeed: 0.0687s/iter; left time: 182.8468s\n",
      "\titers: 300, epoch: 8 | loss: 0.0821714\n",
      "\tspeed: 0.0679s/iter; left time: 173.9431s\n",
      "\titers: 400, epoch: 8 | loss: 0.1414268\n",
      "\tspeed: 0.0679s/iter; left time: 167.2105s\n",
      "\titers: 500, epoch: 8 | loss: 0.0637861\n",
      "\tspeed: 0.0712s/iter; left time: 168.1656s\n",
      "\titers: 600, epoch: 8 | loss: 0.0490324\n",
      "\tspeed: 0.0688s/iter; left time: 155.7468s\n",
      "\titers: 700, epoch: 8 | loss: 0.0940057\n",
      "\tspeed: 0.0676s/iter; left time: 146.2532s\n",
      "\titers: 800, epoch: 8 | loss: 0.0685045\n",
      "\tspeed: 0.0710s/iter; left time: 146.4823s\n",
      "\titers: 900, epoch: 8 | loss: 0.0711851\n",
      "\tspeed: 0.0789s/iter; left time: 154.8769s\n",
      "Epoch: 8 cost time: 67.7874493598938\n",
      "Epoch: 8, Steps: 954 | Train Loss: 0.0681679 Vali Loss: 0.0758426 Test Loss: 0.0998705\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0794779\n",
      "\tspeed: 1.4553s/iter; left time: 2632.6189s\n",
      "\titers: 200, epoch: 9 | loss: 0.0419518\n",
      "\tspeed: 0.0681s/iter; left time: 116.3581s\n",
      "\titers: 300, epoch: 9 | loss: 0.0798752\n",
      "\tspeed: 0.0662s/iter; left time: 106.5716s\n",
      "\titers: 400, epoch: 9 | loss: 0.0488232\n",
      "\tspeed: 0.0663s/iter; left time: 100.1125s\n",
      "\titers: 500, epoch: 9 | loss: 0.0524303\n",
      "\tspeed: 0.0668s/iter; left time: 94.1404s\n",
      "\titers: 600, epoch: 9 | loss: 0.0787978\n",
      "\tspeed: 0.0668s/iter; left time: 87.4328s\n",
      "\titers: 700, epoch: 9 | loss: 0.0730984\n",
      "\tspeed: 0.0665s/iter; left time: 80.4456s\n",
      "\titers: 800, epoch: 9 | loss: 0.0565566\n",
      "\tspeed: 0.0663s/iter; left time: 73.5218s\n",
      "\titers: 900, epoch: 9 | loss: 0.0698863\n",
      "\tspeed: 0.0665s/iter; left time: 67.1190s\n",
      "Epoch: 9 cost time: 65.2650978565216\n",
      "Epoch: 9, Steps: 954 | Train Loss: 0.0677875 Vali Loss: 0.0762545 Test Loss: 0.0997035\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 1) (8735, 1, 24, 1)\n",
      "test shape: (8735, 24, 1) (8735, 24, 1)\n",
      "mse:0.09795290231704712, mae:0.16746366024017334\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.1903487\n",
      "\tspeed: 0.0781s/iter; left time: 736.9530s\n",
      "\titers: 200, epoch: 1 | loss: 0.1243003\n",
      "\tspeed: 0.0690s/iter; left time: 644.6827s\n",
      "\titers: 300, epoch: 1 | loss: 0.1137227\n",
      "\tspeed: 0.0686s/iter; left time: 633.6885s\n",
      "\titers: 400, epoch: 1 | loss: 0.1347989\n",
      "\tspeed: 0.0695s/iter; left time: 635.5597s\n",
      "\titers: 500, epoch: 1 | loss: 0.1070246\n",
      "\tspeed: 0.0709s/iter; left time: 641.0862s\n",
      "\titers: 600, epoch: 1 | loss: 0.1463566\n",
      "\tspeed: 0.0731s/iter; left time: 653.7496s\n",
      "\titers: 700, epoch: 1 | loss: 0.1555830\n",
      "\tspeed: 0.0735s/iter; left time: 650.0171s\n",
      "\titers: 800, epoch: 1 | loss: 0.1243898\n",
      "\tspeed: 0.0689s/iter; left time: 601.9934s\n",
      "\titers: 900, epoch: 1 | loss: 0.0767459\n",
      "\tspeed: 0.0690s/iter; left time: 596.1805s\n",
      "Epoch: 1 cost time: 67.86639952659607\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.1567666 Vali Loss: 0.1072990 Test Loss: 0.1353229\n",
      "Validation loss decreased (inf --> 0.107299).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0709763\n",
      "\tspeed: 1.6898s/iter; left time: 14341.6118s\n",
      "\titers: 200, epoch: 2 | loss: 0.1148428\n",
      "\tspeed: 0.0976s/iter; left time: 818.3139s\n",
      "\titers: 300, epoch: 2 | loss: 0.1124074\n",
      "\tspeed: 0.0823s/iter; left time: 681.9706s\n",
      "\titers: 400, epoch: 2 | loss: 0.0991662\n",
      "\tspeed: 0.0830s/iter; left time: 679.4589s\n",
      "\titers: 500, epoch: 2 | loss: 0.0866370\n",
      "\tspeed: 0.0816s/iter; left time: 659.6334s\n",
      "\titers: 600, epoch: 2 | loss: 0.0880995\n",
      "\tspeed: 0.0822s/iter; left time: 656.7672s\n",
      "\titers: 700, epoch: 2 | loss: 0.0633650\n",
      "\tspeed: 0.0824s/iter; left time: 650.1681s\n",
      "\titers: 800, epoch: 2 | loss: 0.1325227\n",
      "\tspeed: 0.0829s/iter; left time: 645.5064s\n",
      "\titers: 900, epoch: 2 | loss: 0.0865887\n",
      "\tspeed: 0.0818s/iter; left time: 628.9356s\n",
      "Epoch: 2 cost time: 80.66078233718872\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.0939421 Vali Loss: 0.0860836 Test Loss: 0.1166178\n",
      "Validation loss decreased (0.107299 --> 0.086084).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0637202\n",
      "\tspeed: 1.4803s/iter; left time: 11150.8705s\n",
      "\titers: 200, epoch: 3 | loss: 0.0867964\n",
      "\tspeed: 0.0814s/iter; left time: 604.7880s\n",
      "\titers: 300, epoch: 3 | loss: 0.0790244\n",
      "\tspeed: 0.0822s/iter; left time: 602.5462s\n",
      "\titers: 400, epoch: 3 | loss: 0.0871430\n",
      "\tspeed: 0.0822s/iter; left time: 594.8202s\n",
      "\titers: 500, epoch: 3 | loss: 0.0622036\n",
      "\tspeed: 0.0819s/iter; left time: 584.1220s\n",
      "\titers: 600, epoch: 3 | loss: 0.0789268\n",
      "\tspeed: 0.0811s/iter; left time: 570.1200s\n",
      "\titers: 700, epoch: 3 | loss: 0.0990159\n",
      "\tspeed: 0.0817s/iter; left time: 566.6836s\n",
      "\titers: 800, epoch: 3 | loss: 0.0663552\n",
      "\tspeed: 0.0815s/iter; left time: 557.0136s\n",
      "\titers: 900, epoch: 3 | loss: 0.1389276\n",
      "\tspeed: 0.0819s/iter; left time: 551.4280s\n",
      "Epoch: 3 cost time: 78.79868698120117\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.0811869 Vali Loss: 0.0891057 Test Loss: 0.1174031\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0756381\n",
      "\tspeed: 1.5237s/iter; left time: 10024.4110s\n",
      "\titers: 200, epoch: 4 | loss: 0.0814086\n",
      "\tspeed: 0.0710s/iter; left time: 460.3080s\n",
      "\titers: 300, epoch: 4 | loss: 0.0959219\n",
      "\tspeed: 0.0705s/iter; left time: 449.7121s\n",
      "\titers: 400, epoch: 4 | loss: 0.0870733\n",
      "\tspeed: 0.0714s/iter; left time: 448.0998s\n",
      "\titers: 500, epoch: 4 | loss: 0.0631724\n",
      "\tspeed: 0.0721s/iter; left time: 445.2392s\n",
      "\titers: 600, epoch: 4 | loss: 0.0779266\n",
      "\tspeed: 0.0691s/iter; left time: 420.3471s\n",
      "\titers: 700, epoch: 4 | loss: 0.1074261\n",
      "\tspeed: 0.0675s/iter; left time: 403.8052s\n",
      "\titers: 800, epoch: 4 | loss: 0.1245432\n",
      "\tspeed: 0.0694s/iter; left time: 407.8490s\n",
      "\titers: 900, epoch: 4 | loss: 0.0437508\n",
      "\tspeed: 0.0681s/iter; left time: 393.7148s\n",
      "Epoch: 4 cost time: 67.4559395313263\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.0756473 Vali Loss: 0.0755543 Test Loss: 0.1016519\n",
      "Validation loss decreased (0.086084 --> 0.075554).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0921911\n",
      "\tspeed: 1.7118s/iter; left time: 9629.0781s\n",
      "\titers: 200, epoch: 5 | loss: 0.0730598\n",
      "\tspeed: 0.0686s/iter; left time: 379.2301s\n",
      "\titers: 300, epoch: 5 | loss: 0.0743807\n",
      "\tspeed: 0.0733s/iter; left time: 397.4031s\n",
      "\titers: 400, epoch: 5 | loss: 0.0633250\n",
      "\tspeed: 0.0705s/iter; left time: 375.2720s\n",
      "\titers: 500, epoch: 5 | loss: 0.0731666\n",
      "\tspeed: 0.0715s/iter; left time: 373.5841s\n",
      "\titers: 600, epoch: 5 | loss: 0.0758846\n",
      "\tspeed: 0.0702s/iter; left time: 359.7589s\n",
      "\titers: 700, epoch: 5 | loss: 0.0545481\n",
      "\tspeed: 0.0719s/iter; left time: 361.4299s\n",
      "\titers: 800, epoch: 5 | loss: 0.0808640\n",
      "\tspeed: 0.0697s/iter; left time: 343.4729s\n",
      "\titers: 900, epoch: 5 | loss: 0.0742429\n",
      "\tspeed: 0.0701s/iter; left time: 338.4110s\n",
      "Epoch: 5 cost time: 68.34261202812195\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.0725384 Vali Loss: 0.0781822 Test Loss: 0.1025485\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0840440\n",
      "\tspeed: 1.7066s/iter; left time: 7971.7383s\n",
      "\titers: 200, epoch: 6 | loss: 0.0530801\n",
      "\tspeed: 0.0745s/iter; left time: 340.4096s\n",
      "\titers: 300, epoch: 6 | loss: 0.0727115\n",
      "\tspeed: 0.0701s/iter; left time: 313.4800s\n",
      "\titers: 400, epoch: 6 | loss: 0.0628198\n",
      "\tspeed: 0.0681s/iter; left time: 297.6797s\n",
      "\titers: 500, epoch: 6 | loss: 0.0505939\n",
      "\tspeed: 0.0672s/iter; left time: 287.1563s\n",
      "\titers: 600, epoch: 6 | loss: 0.0561436\n",
      "\tspeed: 0.0677s/iter; left time: 282.1753s\n",
      "\titers: 700, epoch: 6 | loss: 0.0694014\n",
      "\tspeed: 0.0684s/iter; left time: 278.5725s\n",
      "\titers: 800, epoch: 6 | loss: 0.0882710\n",
      "\tspeed: 0.0689s/iter; left time: 273.4342s\n",
      "\titers: 900, epoch: 6 | loss: 0.0691248\n",
      "\tspeed: 0.0690s/iter; left time: 266.9692s\n",
      "Epoch: 6 cost time: 66.97149634361267\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.0708630 Vali Loss: 0.0762609 Test Loss: 0.1030746\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0730369\n",
      "\tspeed: 1.7127s/iter; left time: 6365.9784s\n",
      "\titers: 200, epoch: 7 | loss: 0.0948013\n",
      "\tspeed: 0.0722s/iter; left time: 261.1910s\n",
      "\titers: 300, epoch: 7 | loss: 0.0638278\n",
      "\tspeed: 0.0695s/iter; left time: 244.5688s\n",
      "\titers: 400, epoch: 7 | loss: 0.0505906\n",
      "\tspeed: 0.0704s/iter; left time: 240.4863s\n",
      "\titers: 500, epoch: 7 | loss: 0.0503052\n",
      "\tspeed: 0.0711s/iter; left time: 235.9934s\n",
      "\titers: 600, epoch: 7 | loss: 0.0738723\n",
      "\tspeed: 0.0691s/iter; left time: 222.1502s\n",
      "\titers: 700, epoch: 7 | loss: 0.0732902\n",
      "\tspeed: 0.0705s/iter; left time: 219.8330s\n",
      "\titers: 800, epoch: 7 | loss: 0.0697946\n",
      "\tspeed: 0.0688s/iter; left time: 207.6668s\n",
      "\titers: 900, epoch: 7 | loss: 0.0989262\n",
      "\tspeed: 0.0693s/iter; left time: 202.0264s\n",
      "Epoch: 7 cost time: 68.21410584449768\n",
      "Epoch: 7, Steps: 954 | Train Loss: 0.0697504 Vali Loss: 0.0737700 Test Loss: 0.0993504\n",
      "Validation loss decreased (0.075554 --> 0.073770).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0431806\n",
      "\tspeed: 1.7178s/iter; left time: 4746.1588s\n",
      "\titers: 200, epoch: 8 | loss: 0.0924024\n",
      "\tspeed: 0.0709s/iter; left time: 188.6819s\n",
      "\titers: 300, epoch: 8 | loss: 0.0650581\n",
      "\tspeed: 0.0705s/iter; left time: 180.7123s\n",
      "\titers: 400, epoch: 8 | loss: 0.0929851\n",
      "\tspeed: 0.0709s/iter; left time: 174.7467s\n",
      "\titers: 500, epoch: 8 | loss: 0.0744507\n",
      "\tspeed: 0.0734s/iter; left time: 173.4641s\n",
      "\titers: 600, epoch: 8 | loss: 0.0654508\n",
      "\tspeed: 0.0707s/iter; left time: 159.9943s\n",
      "\titers: 700, epoch: 8 | loss: 0.0486053\n",
      "\tspeed: 0.0700s/iter; left time: 151.3450s\n",
      "\titers: 800, epoch: 8 | loss: 0.0533182\n",
      "\tspeed: 0.0760s/iter; left time: 156.7578s\n",
      "\titers: 900, epoch: 8 | loss: 0.0491673\n",
      "\tspeed: 0.0819s/iter; left time: 160.7666s\n",
      "Epoch: 8 cost time: 70.53950643539429\n",
      "Epoch: 8, Steps: 954 | Train Loss: 0.0688808 Vali Loss: 0.0759508 Test Loss: 0.1011773\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0568349\n",
      "\tspeed: 1.6876s/iter; left time: 3052.7926s\n",
      "\titers: 200, epoch: 9 | loss: 0.0886543\n",
      "\tspeed: 0.0686s/iter; left time: 117.2631s\n",
      "\titers: 300, epoch: 9 | loss: 0.0644496\n",
      "\tspeed: 0.0689s/iter; left time: 110.8564s\n",
      "\titers: 400, epoch: 9 | loss: 0.0598110\n",
      "\tspeed: 0.0694s/iter; left time: 104.7722s\n",
      "\titers: 500, epoch: 9 | loss: 0.0531583\n",
      "\tspeed: 0.0697s/iter; left time: 98.2389s\n",
      "\titers: 600, epoch: 9 | loss: 0.0517710\n",
      "\tspeed: 0.0685s/iter; left time: 89.6054s\n",
      "\titers: 700, epoch: 9 | loss: 0.0859085\n",
      "\tspeed: 0.0688s/iter; left time: 83.1338s\n",
      "\titers: 800, epoch: 9 | loss: 0.0756484\n",
      "\tspeed: 0.0686s/iter; left time: 76.0781s\n",
      "\titers: 900, epoch: 9 | loss: 0.0830211\n",
      "\tspeed: 0.0724s/iter; left time: 73.0598s\n",
      "Epoch: 9 cost time: 67.35744047164917\n",
      "Epoch: 9, Steps: 954 | Train Loss: 0.0685620 Vali Loss: 0.0747698 Test Loss: 0.0999986\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0722980\n",
      "\tspeed: 1.7182s/iter; left time: 1469.0281s\n",
      "\titers: 200, epoch: 10 | loss: 0.0758545\n",
      "\tspeed: 0.0706s/iter; left time: 53.2847s\n",
      "\titers: 300, epoch: 10 | loss: 0.1029776\n",
      "\tspeed: 0.0702s/iter; left time: 45.9675s\n",
      "\titers: 400, epoch: 10 | loss: 0.0893545\n",
      "\tspeed: 0.0715s/iter; left time: 39.6963s\n",
      "\titers: 500, epoch: 10 | loss: 0.0680228\n",
      "\tspeed: 0.0701s/iter; left time: 31.8794s\n",
      "\titers: 600, epoch: 10 | loss: 0.0610479\n",
      "\tspeed: 0.0708s/iter; left time: 25.1390s\n",
      "\titers: 700, epoch: 10 | loss: 0.1195635\n",
      "\tspeed: 0.0711s/iter; left time: 18.1385s\n",
      "\titers: 800, epoch: 10 | loss: 0.0738499\n",
      "\tspeed: 0.0721s/iter; left time: 11.1733s\n",
      "\titers: 900, epoch: 10 | loss: 0.0706217\n",
      "\tspeed: 0.0728s/iter; left time: 4.0026s\n",
      "Epoch: 10 cost time: 68.9905092716217\n",
      "Epoch: 10, Steps: 954 | Train Loss: 0.0682443 Vali Loss: 0.0738121 Test Loss: 0.0992322\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 1) (8735, 1, 24, 1)\n",
      "test shape: (8735, 24, 1) (8735, 24, 1)\n",
      "mse:0.09913162142038345, mae:0.16627638041973114\n",
      "\n",
      "Extracted Part: long_term_forecast__24_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__24_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=1, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=1, factor=5, features='S', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_48_DE_solar_generation_actual', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=48, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='DE_solar_generation_actual', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.1934608\n",
      "\tspeed: 0.0937s/iter; left time: 883.5542s\n",
      "\titers: 200, epoch: 1 | loss: 0.1357728\n",
      "\tspeed: 0.0810s/iter; left time: 756.1080s\n",
      "\titers: 300, epoch: 1 | loss: 0.1102787\n",
      "\tspeed: 0.0820s/iter; left time: 756.7944s\n",
      "\titers: 400, epoch: 1 | loss: 0.1485537\n",
      "\tspeed: 0.0835s/iter; left time: 762.1043s\n",
      "\titers: 500, epoch: 1 | loss: 0.1269380\n",
      "\tspeed: 0.0835s/iter; left time: 754.3346s\n",
      "\titers: 600, epoch: 1 | loss: 0.1018707\n",
      "\tspeed: 0.0832s/iter; left time: 743.1545s\n",
      "\titers: 700, epoch: 1 | loss: 0.1154705\n",
      "\tspeed: 0.0842s/iter; left time: 743.1785s\n",
      "\titers: 800, epoch: 1 | loss: 0.1259056\n",
      "\tspeed: 0.0835s/iter; left time: 729.1728s\n",
      "\titers: 900, epoch: 1 | loss: 0.1169200\n",
      "\tspeed: 0.0847s/iter; left time: 730.7267s\n",
      "Epoch: 1 cost time: 80.43740940093994\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.1693571 Vali Loss: 0.1122787 Test Loss: 0.1500806\n",
      "Validation loss decreased (inf --> 0.112279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1126414\n",
      "\tspeed: 1.5614s/iter; left time: 13237.7061s\n",
      "\titers: 200, epoch: 2 | loss: 0.0863106\n",
      "\tspeed: 0.0737s/iter; left time: 617.3059s\n",
      "\titers: 300, epoch: 2 | loss: 0.0829931\n",
      "\tspeed: 0.0748s/iter; left time: 619.0682s\n",
      "\titers: 400, epoch: 2 | loss: 0.1067402\n",
      "\tspeed: 0.0737s/iter; left time: 602.5272s\n",
      "\titers: 500, epoch: 2 | loss: 0.0838321\n",
      "\tspeed: 0.0759s/iter; left time: 612.9803s\n",
      "\titers: 600, epoch: 2 | loss: 0.0939466\n",
      "\tspeed: 0.0717s/iter; left time: 571.8209s\n",
      "\titers: 700, epoch: 2 | loss: 0.1260097\n",
      "\tspeed: 0.0723s/iter; left time: 569.8957s\n",
      "\titers: 800, epoch: 2 | loss: 0.0790051\n",
      "\tspeed: 0.0727s/iter; left time: 565.2145s\n",
      "\titers: 900, epoch: 2 | loss: 0.0670825\n",
      "\tspeed: 0.0716s/iter; left time: 549.8973s\n",
      "Epoch: 2 cost time: 70.48061108589172\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.1109388 Vali Loss: 0.1282181 Test Loss: 0.1637882\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0647052\n",
      "\tspeed: 1.7104s/iter; left time: 12870.7640s\n",
      "\titers: 200, epoch: 3 | loss: 0.0874846\n",
      "\tspeed: 0.0736s/iter; left time: 546.7400s\n",
      "\titers: 300, epoch: 3 | loss: 0.1003985\n",
      "\tspeed: 0.0731s/iter; left time: 535.1534s\n",
      "\titers: 400, epoch: 3 | loss: 0.0998901\n",
      "\tspeed: 0.0732s/iter; left time: 528.6857s\n",
      "\titers: 500, epoch: 3 | loss: 0.1010219\n",
      "\tspeed: 0.0733s/iter; left time: 522.4640s\n",
      "\titers: 600, epoch: 3 | loss: 0.0885388\n",
      "\tspeed: 0.0744s/iter; left time: 522.6873s\n",
      "\titers: 700, epoch: 3 | loss: 0.0828827\n",
      "\tspeed: 0.0730s/iter; left time: 505.4186s\n",
      "\titers: 800, epoch: 3 | loss: 0.0902887\n",
      "\tspeed: 0.0732s/iter; left time: 499.3729s\n",
      "\titers: 900, epoch: 3 | loss: 0.1096065\n",
      "\tspeed: 0.0741s/iter; left time: 498.4647s\n",
      "Epoch: 3 cost time: 70.48107075691223\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.0990859 Vali Loss: 0.0990270 Test Loss: 0.1298927\n",
      "Validation loss decreased (0.112279 --> 0.099027).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1499823\n",
      "\tspeed: 1.7065s/iter; left time: 11214.9744s\n",
      "\titers: 200, epoch: 4 | loss: 0.0684548\n",
      "\tspeed: 0.0754s/iter; left time: 487.7922s\n",
      "\titers: 300, epoch: 4 | loss: 0.0699284\n",
      "\tspeed: 0.0729s/iter; left time: 464.6944s\n",
      "\titers: 400, epoch: 4 | loss: 0.0808953\n",
      "\tspeed: 0.0721s/iter; left time: 451.9367s\n",
      "\titers: 500, epoch: 4 | loss: 0.0899018\n",
      "\tspeed: 0.0732s/iter; left time: 451.8388s\n",
      "\titers: 600, epoch: 4 | loss: 0.1030158\n",
      "\tspeed: 0.0732s/iter; left time: 444.2536s\n",
      "\titers: 700, epoch: 4 | loss: 0.0839314\n",
      "\tspeed: 0.0738s/iter; left time: 441.0213s\n",
      "\titers: 800, epoch: 4 | loss: 0.0584235\n",
      "\tspeed: 0.0737s/iter; left time: 432.6798s\n",
      "\titers: 900, epoch: 4 | loss: 0.1102461\n",
      "\tspeed: 0.0743s/iter; left time: 428.6729s\n",
      "Epoch: 4 cost time: 70.95565414428711\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.0936252 Vali Loss: 0.1006351 Test Loss: 0.1293904\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0776535\n",
      "\tspeed: 1.7048s/iter; left time: 9579.2547s\n",
      "\titers: 200, epoch: 5 | loss: 0.0711377\n",
      "\tspeed: 0.0812s/iter; left time: 448.3617s\n",
      "\titers: 300, epoch: 5 | loss: 0.0765321\n",
      "\tspeed: 0.0850s/iter; left time: 460.8172s\n",
      "\titers: 400, epoch: 5 | loss: 0.0963156\n",
      "\tspeed: 0.0842s/iter; left time: 447.6354s\n",
      "\titers: 500, epoch: 5 | loss: 0.0604929\n",
      "\tspeed: 0.0842s/iter; left time: 439.5391s\n",
      "\titers: 600, epoch: 5 | loss: 0.0998774\n",
      "\tspeed: 0.0839s/iter; left time: 429.6266s\n",
      "\titers: 700, epoch: 5 | loss: 0.1028932\n",
      "\tspeed: 0.0844s/iter; left time: 423.3573s\n",
      "\titers: 800, epoch: 5 | loss: 0.0957584\n",
      "\tspeed: 0.0851s/iter; left time: 418.6820s\n",
      "\titers: 900, epoch: 5 | loss: 0.0882849\n",
      "\tspeed: 0.0849s/iter; left time: 409.1394s\n",
      "Epoch: 5 cost time: 79.85797882080078\n",
      "Epoch: 5, Steps: 953 | Train Loss: 0.0903362 Vali Loss: 0.0994537 Test Loss: 0.1279648\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0745692\n",
      "\tspeed: 1.4497s/iter; left time: 6764.3681s\n",
      "\titers: 200, epoch: 6 | loss: 0.0773794\n",
      "\tspeed: 0.0728s/iter; left time: 332.5567s\n",
      "\titers: 300, epoch: 6 | loss: 0.1033536\n",
      "\tspeed: 0.0732s/iter; left time: 326.8299s\n",
      "\titers: 400, epoch: 6 | loss: 0.0901286\n",
      "\tspeed: 0.0740s/iter; left time: 323.1467s\n",
      "\titers: 500, epoch: 6 | loss: 0.0944872\n",
      "\tspeed: 0.0837s/iter; left time: 356.8668s\n",
      "\titers: 600, epoch: 6 | loss: 0.0777678\n",
      "\tspeed: 0.0836s/iter; left time: 348.1906s\n",
      "\titers: 700, epoch: 6 | loss: 0.0794905\n",
      "\tspeed: 0.0841s/iter; left time: 341.8672s\n",
      "\titers: 800, epoch: 6 | loss: 0.0840980\n",
      "\tspeed: 0.0853s/iter; left time: 338.3203s\n",
      "\titers: 900, epoch: 6 | loss: 0.0951085\n",
      "\tspeed: 0.0838s/iter; left time: 323.9827s\n",
      "Epoch: 6 cost time: 76.35620784759521\n",
      "Epoch: 6, Steps: 953 | Train Loss: 0.0886020 Vali Loss: 0.1027539 Test Loss: 0.1290588\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 1) (8711, 1, 48, 1)\n",
      "test shape: (8711, 48, 1) (8711, 48, 1)\n",
      "mse:0.12990029156208038, mae:0.1935780942440033\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.2895061\n",
      "\tspeed: 0.0818s/iter; left time: 771.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1886337\n",
      "\tspeed: 0.0758s/iter; left time: 706.9601s\n",
      "\titers: 300, epoch: 1 | loss: 0.1770206\n",
      "\tspeed: 0.0752s/iter; left time: 693.8881s\n",
      "\titers: 400, epoch: 1 | loss: 0.0743092\n",
      "\tspeed: 0.0732s/iter; left time: 668.2269s\n",
      "\titers: 500, epoch: 1 | loss: 0.0936490\n",
      "\tspeed: 0.0756s/iter; left time: 682.3754s\n",
      "\titers: 600, epoch: 1 | loss: 0.1198957\n",
      "\tspeed: 0.0754s/iter; left time: 673.0725s\n",
      "\titers: 700, epoch: 1 | loss: 0.1505799\n",
      "\tspeed: 0.0751s/iter; left time: 663.4827s\n",
      "\titers: 800, epoch: 1 | loss: 0.1693227\n",
      "\tspeed: 0.0755s/iter; left time: 659.3551s\n",
      "\titers: 900, epoch: 1 | loss: 0.0886214\n",
      "\tspeed: 0.0749s/iter; left time: 646.3832s\n",
      "Epoch: 1 cost time: 72.57148003578186\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.1764943 Vali Loss: 0.1128026 Test Loss: 0.1493310\n",
      "Validation loss decreased (inf --> 0.112803).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1238636\n",
      "\tspeed: 1.7244s/iter; left time: 14619.1671s\n",
      "\titers: 200, epoch: 2 | loss: 0.0876240\n",
      "\tspeed: 0.0864s/iter; left time: 723.9881s\n",
      "\titers: 300, epoch: 2 | loss: 0.1265195\n",
      "\tspeed: 0.0841s/iter; left time: 695.8541s\n",
      "\titers: 400, epoch: 2 | loss: 0.1193401\n",
      "\tspeed: 0.0849s/iter; left time: 694.5623s\n",
      "\titers: 500, epoch: 2 | loss: 0.1235006\n",
      "\tspeed: 0.0870s/iter; left time: 702.5043s\n",
      "\titers: 600, epoch: 2 | loss: 0.1345226\n",
      "\tspeed: 0.0836s/iter; left time: 667.1950s\n",
      "\titers: 700, epoch: 2 | loss: 0.1114141\n",
      "\tspeed: 0.0848s/iter; left time: 668.1230s\n",
      "\titers: 800, epoch: 2 | loss: 0.0707841\n",
      "\tspeed: 0.0847s/iter; left time: 658.6001s\n",
      "\titers: 900, epoch: 2 | loss: 0.0993292\n",
      "\tspeed: 0.0857s/iter; left time: 658.3574s\n",
      "Epoch: 2 cost time: 81.71231698989868\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.1122324 Vali Loss: 0.1041043 Test Loss: 0.1380922\n",
      "Validation loss decreased (0.112803 --> 0.104104).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1192093\n",
      "\tspeed: 1.7320s/iter; left time: 13033.6129s\n",
      "\titers: 200, epoch: 3 | loss: 0.1249468\n",
      "\tspeed: 0.0743s/iter; left time: 551.7034s\n",
      "\titers: 300, epoch: 3 | loss: 0.1018515\n",
      "\tspeed: 0.0740s/iter; left time: 542.2198s\n",
      "\titers: 400, epoch: 3 | loss: 0.0666959\n",
      "\tspeed: 0.0743s/iter; left time: 536.7564s\n",
      "\titers: 500, epoch: 3 | loss: 0.0999222\n",
      "\tspeed: 0.0749s/iter; left time: 533.9977s\n",
      "\titers: 600, epoch: 3 | loss: 0.0673240\n",
      "\tspeed: 0.0741s/iter; left time: 520.6847s\n",
      "\titers: 700, epoch: 3 | loss: 0.0736052\n",
      "\tspeed: 0.0752s/iter; left time: 520.6953s\n",
      "\titers: 800, epoch: 3 | loss: 0.1263746\n",
      "\tspeed: 0.0742s/iter; left time: 506.1735s\n",
      "\titers: 900, epoch: 3 | loss: 0.1202040\n",
      "\tspeed: 0.0745s/iter; left time: 500.7257s\n",
      "Epoch: 3 cost time: 72.06756281852722\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.0993336 Vali Loss: 0.1069156 Test Loss: 0.1371327\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0590973\n",
      "\tspeed: 1.7172s/iter; left time: 11285.2849s\n",
      "\titers: 200, epoch: 4 | loss: 0.0828800\n",
      "\tspeed: 0.0754s/iter; left time: 488.2234s\n",
      "\titers: 300, epoch: 4 | loss: 0.1287100\n",
      "\tspeed: 0.0750s/iter; left time: 478.1385s\n",
      "\titers: 400, epoch: 4 | loss: 0.1302465\n",
      "\tspeed: 0.0776s/iter; left time: 486.5487s\n",
      "\titers: 500, epoch: 4 | loss: 0.1037760\n",
      "\tspeed: 0.0755s/iter; left time: 465.8353s\n",
      "\titers: 600, epoch: 4 | loss: 0.0819830\n",
      "\tspeed: 0.0763s/iter; left time: 463.1425s\n",
      "\titers: 700, epoch: 4 | loss: 0.0962895\n",
      "\tspeed: 0.0766s/iter; left time: 457.7220s\n",
      "\titers: 800, epoch: 4 | loss: 0.0717953\n",
      "\tspeed: 0.0770s/iter; left time: 452.2726s\n",
      "\titers: 900, epoch: 4 | loss: 0.1345158\n",
      "\tspeed: 0.0766s/iter; left time: 442.2522s\n",
      "Epoch: 4 cost time: 73.610431432724\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.0940769 Vali Loss: 0.1072807 Test Loss: 0.1318391\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0962891\n",
      "\tspeed: 1.7316s/iter; left time: 9730.0724s\n",
      "\titers: 200, epoch: 5 | loss: 0.0963020\n",
      "\tspeed: 0.0760s/iter; left time: 419.6140s\n",
      "\titers: 300, epoch: 5 | loss: 0.1141718\n",
      "\tspeed: 0.0743s/iter; left time: 402.6830s\n",
      "\titers: 400, epoch: 5 | loss: 0.0748579\n",
      "\tspeed: 0.0761s/iter; left time: 404.8002s\n",
      "\titers: 500, epoch: 5 | loss: 0.0857522\n",
      "\tspeed: 0.0787s/iter; left time: 410.8725s\n",
      "\titers: 600, epoch: 5 | loss: 0.0889959\n",
      "\tspeed: 0.0752s/iter; left time: 384.9818s\n",
      "\titers: 700, epoch: 5 | loss: 0.0740965\n",
      "\tspeed: 0.0780s/iter; left time: 391.4195s\n",
      "\titers: 800, epoch: 5 | loss: 0.0970971\n",
      "\tspeed: 0.0744s/iter; left time: 365.8408s\n",
      "\titers: 900, epoch: 5 | loss: 0.1208087\n",
      "\tspeed: 0.0767s/iter; left time: 369.7492s\n",
      "Epoch: 5 cost time: 73.902508020401\n",
      "Epoch: 5, Steps: 953 | Train Loss: 0.0908968 Vali Loss: 0.0969929 Test Loss: 0.1259561\n",
      "Validation loss decreased (0.104104 --> 0.096993).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0868900\n",
      "\tspeed: 1.4941s/iter; left time: 6971.5181s\n",
      "\titers: 200, epoch: 6 | loss: 0.0770892\n",
      "\tspeed: 0.0742s/iter; left time: 338.7623s\n",
      "\titers: 300, epoch: 6 | loss: 0.1258942\n",
      "\tspeed: 0.0739s/iter; left time: 330.0578s\n",
      "\titers: 400, epoch: 6 | loss: 0.0743336\n",
      "\tspeed: 0.0788s/iter; left time: 343.9708s\n",
      "\titers: 500, epoch: 6 | loss: 0.0922476\n",
      "\tspeed: 0.0730s/iter; left time: 311.3437s\n",
      "\titers: 600, epoch: 6 | loss: 0.1199975\n",
      "\tspeed: 0.0749s/iter; left time: 311.8973s\n",
      "\titers: 700, epoch: 6 | loss: 0.0696449\n",
      "\tspeed: 0.0740s/iter; left time: 301.0422s\n",
      "\titers: 800, epoch: 6 | loss: 0.0635469\n",
      "\tspeed: 0.0733s/iter; left time: 290.8491s\n",
      "\titers: 900, epoch: 6 | loss: 0.1332060\n",
      "\tspeed: 0.0758s/iter; left time: 293.0495s\n",
      "Epoch: 6 cost time: 72.79874396324158\n",
      "Epoch: 6, Steps: 953 | Train Loss: 0.0892166 Vali Loss: 0.0977024 Test Loss: 0.1247544\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0635058\n",
      "\tspeed: 1.7251s/iter; left time: 6405.4715s\n",
      "\titers: 200, epoch: 7 | loss: 0.1015454\n",
      "\tspeed: 0.0757s/iter; left time: 273.4737s\n",
      "\titers: 300, epoch: 7 | loss: 0.0836972\n",
      "\tspeed: 0.0758s/iter; left time: 266.2492s\n",
      "\titers: 400, epoch: 7 | loss: 0.0727167\n",
      "\tspeed: 0.0765s/iter; left time: 261.2465s\n",
      "\titers: 500, epoch: 7 | loss: 0.0734254\n",
      "\tspeed: 0.0781s/iter; left time: 258.8705s\n",
      "\titers: 600, epoch: 7 | loss: 0.1066454\n",
      "\tspeed: 0.0751s/iter; left time: 241.2788s\n",
      "\titers: 700, epoch: 7 | loss: 0.0761470\n",
      "\tspeed: 0.0764s/iter; left time: 237.9474s\n",
      "\titers: 800, epoch: 7 | loss: 0.0770698\n",
      "\tspeed: 0.0753s/iter; left time: 226.9350s\n",
      "\titers: 900, epoch: 7 | loss: 0.0553315\n",
      "\tspeed: 0.0763s/iter; left time: 222.4070s\n",
      "Epoch: 7 cost time: 73.74003458023071\n",
      "Epoch: 7, Steps: 953 | Train Loss: 0.0879823 Vali Loss: 0.0990468 Test Loss: 0.1259219\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1307033\n",
      "\tspeed: 1.7094s/iter; left time: 4718.0247s\n",
      "\titers: 200, epoch: 8 | loss: 0.0969108\n",
      "\tspeed: 0.0747s/iter; left time: 198.8126s\n",
      "\titers: 300, epoch: 8 | loss: 0.0700001\n",
      "\tspeed: 0.0787s/iter; left time: 201.3721s\n",
      "\titers: 400, epoch: 8 | loss: 0.0608792\n",
      "\tspeed: 0.0753s/iter; left time: 185.1819s\n",
      "\titers: 500, epoch: 8 | loss: 0.1068817\n",
      "\tspeed: 0.0738s/iter; left time: 174.0886s\n",
      "\titers: 600, epoch: 8 | loss: 0.1136526\n",
      "\tspeed: 0.0743s/iter; left time: 167.9268s\n",
      "\titers: 700, epoch: 8 | loss: 0.0646930\n",
      "\tspeed: 0.0744s/iter; left time: 160.7478s\n",
      "\titers: 800, epoch: 8 | loss: 0.0648224\n",
      "\tspeed: 0.0743s/iter; left time: 153.0329s\n",
      "\titers: 900, epoch: 8 | loss: 0.0881835\n",
      "\tspeed: 0.0745s/iter; left time: 146.0174s\n",
      "Epoch: 8 cost time: 72.28053641319275\n",
      "Epoch: 8, Steps: 953 | Train Loss: 0.0874023 Vali Loss: 0.1027428 Test Loss: 0.1279328\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 1) (8711, 1, 48, 1)\n",
      "test shape: (8711, 48, 1) (8711, 48, 1)\n",
      "mse:0.12604592740535736, mae:0.2006378024816513\n",
      "\n",
      "Extracted Part: long_term_forecast__48_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__48_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=1, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=1, factor=5, features='S', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_96_DE_solar_generation_actual', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='DE_solar_generation_actual', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.2058430\n",
      "\tspeed: 0.1075s/iter; left time: 1013.1388s\n",
      "\titers: 200, epoch: 1 | loss: 0.1858350\n",
      "\tspeed: 0.0961s/iter; left time: 895.5842s\n",
      "\titers: 300, epoch: 1 | loss: 0.0995306\n",
      "\tspeed: 0.0957s/iter; left time: 882.6500s\n",
      "\titers: 400, epoch: 1 | loss: 0.1307174\n",
      "\tspeed: 0.0961s/iter; left time: 876.8987s\n",
      "\titers: 500, epoch: 1 | loss: 0.1428764\n",
      "\tspeed: 0.0961s/iter; left time: 867.1998s\n",
      "\titers: 600, epoch: 1 | loss: 0.1279767\n",
      "\tspeed: 0.0965s/iter; left time: 861.0358s\n",
      "\titers: 700, epoch: 1 | loss: 0.1712989\n",
      "\tspeed: 0.0973s/iter; left time: 858.4270s\n",
      "\titers: 800, epoch: 1 | loss: 0.1120761\n",
      "\tspeed: 0.0976s/iter; left time: 850.8829s\n",
      "\titers: 900, epoch: 1 | loss: 0.1045892\n",
      "\tspeed: 0.0996s/iter; left time: 858.7384s\n",
      "Epoch: 1 cost time: 93.51729393005371\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.1910020 Vali Loss: 0.1244926 Test Loss: 0.1675767\n",
      "Validation loss decreased (inf --> 0.124493).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1302615\n",
      "\tspeed: 1.7660s/iter; left time: 14956.1046s\n",
      "\titers: 200, epoch: 2 | loss: 0.1002000\n",
      "\tspeed: 0.0877s/iter; left time: 734.1581s\n",
      "\titers: 300, epoch: 2 | loss: 0.0993735\n",
      "\tspeed: 0.0855s/iter; left time: 706.6275s\n",
      "\titers: 400, epoch: 2 | loss: 0.0999412\n",
      "\tspeed: 0.0840s/iter; left time: 686.1946s\n",
      "\titers: 500, epoch: 2 | loss: 0.1148669\n",
      "\tspeed: 0.0850s/iter; left time: 685.6107s\n",
      "\titers: 600, epoch: 2 | loss: 0.1118585\n",
      "\tspeed: 0.0844s/iter; left time: 672.6710s\n",
      "\titers: 700, epoch: 2 | loss: 0.1121627\n",
      "\tspeed: 0.0841s/iter; left time: 661.4279s\n",
      "\titers: 800, epoch: 2 | loss: 0.1062777\n",
      "\tspeed: 0.0869s/iter; left time: 675.4323s\n",
      "\titers: 900, epoch: 2 | loss: 0.0906987\n",
      "\tspeed: 0.0864s/iter; left time: 662.6613s\n",
      "Epoch: 2 cost time: 82.06297326087952\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.1177337 Vali Loss: 0.1453606 Test Loss: 0.1782035\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1273013\n",
      "\tspeed: 1.7591s/iter; left time: 13222.9726s\n",
      "\titers: 200, epoch: 3 | loss: 0.1050505\n",
      "\tspeed: 0.0858s/iter; left time: 636.0663s\n",
      "\titers: 300, epoch: 3 | loss: 0.1158242\n",
      "\tspeed: 0.0847s/iter; left time: 619.4597s\n",
      "\titers: 400, epoch: 3 | loss: 0.1004114\n",
      "\tspeed: 0.0842s/iter; left time: 607.9346s\n",
      "\titers: 500, epoch: 3 | loss: 0.1034444\n",
      "\tspeed: 0.0861s/iter; left time: 612.4987s\n",
      "\titers: 600, epoch: 3 | loss: 0.1086587\n",
      "\tspeed: 0.0875s/iter; left time: 613.8965s\n",
      "\titers: 700, epoch: 3 | loss: 0.1050251\n",
      "\tspeed: 0.0904s/iter; left time: 625.0420s\n",
      "\titers: 800, epoch: 3 | loss: 0.0756155\n",
      "\tspeed: 0.0881s/iter; left time: 600.5048s\n",
      "\titers: 900, epoch: 3 | loss: 0.1082120\n",
      "\tspeed: 0.0884s/iter; left time: 593.7193s\n",
      "Epoch: 3 cost time: 83.15912556648254\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.1069882 Vali Loss: 0.1421415 Test Loss: 0.1652540\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1235988\n",
      "\tspeed: 1.7726s/iter; left time: 11636.8775s\n",
      "\titers: 200, epoch: 4 | loss: 0.0796843\n",
      "\tspeed: 0.0847s/iter; left time: 547.3928s\n",
      "\titers: 300, epoch: 4 | loss: 0.1093258\n",
      "\tspeed: 0.0866s/iter; left time: 551.2857s\n",
      "\titers: 400, epoch: 4 | loss: 0.0840812\n",
      "\tspeed: 0.0888s/iter; left time: 556.2654s\n",
      "\titers: 500, epoch: 4 | loss: 0.1303375\n",
      "\tspeed: 0.0854s/iter; left time: 526.5858s\n",
      "\titers: 600, epoch: 4 | loss: 0.1012842\n",
      "\tspeed: 0.0856s/iter; left time: 519.1625s\n",
      "\titers: 700, epoch: 4 | loss: 0.0986571\n",
      "\tspeed: 0.0865s/iter; left time: 515.9118s\n",
      "\titers: 800, epoch: 4 | loss: 0.0784874\n",
      "\tspeed: 0.0864s/iter; left time: 506.4619s\n",
      "\titers: 900, epoch: 4 | loss: 0.0846797\n",
      "\tspeed: 0.0860s/iter; left time: 495.8488s\n",
      "Epoch: 4 cost time: 82.56401348114014\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.1016928 Vali Loss: 0.1277334 Test Loss: 0.1552998\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 1) (8663, 1, 96, 1)\n",
      "test shape: (8663, 96, 1) (8663, 96, 1)\n",
      "mse:0.16751334071159363, mae:0.2536063492298126\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.2534936\n",
      "\tspeed: 0.0960s/iter; left time: 904.1686s\n",
      "\titers: 200, epoch: 1 | loss: 0.1742887\n",
      "\tspeed: 0.0886s/iter; left time: 826.2169s\n",
      "\titers: 300, epoch: 1 | loss: 0.1598877\n",
      "\tspeed: 0.0871s/iter; left time: 803.0518s\n",
      "\titers: 400, epoch: 1 | loss: 0.1456755\n",
      "\tspeed: 0.0908s/iter; left time: 828.4037s\n",
      "\titers: 500, epoch: 1 | loss: 0.1252326\n",
      "\tspeed: 0.0909s/iter; left time: 820.1368s\n",
      "\titers: 600, epoch: 1 | loss: 0.1072150\n",
      "\tspeed: 0.0901s/iter; left time: 803.5843s\n",
      "\titers: 700, epoch: 1 | loss: 0.1361414\n",
      "\tspeed: 0.0882s/iter; left time: 778.3456s\n",
      "\titers: 800, epoch: 1 | loss: 0.1469416\n",
      "\tspeed: 0.0889s/iter; left time: 774.9336s\n",
      "\titers: 900, epoch: 1 | loss: 0.1695048\n",
      "\tspeed: 0.0853s/iter; left time: 735.7809s\n",
      "Epoch: 1 cost time: 85.25697040557861\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.1910485 Vali Loss: 0.1202276 Test Loss: 0.1670720\n",
      "Validation loss decreased (inf --> 0.120228).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1079627\n",
      "\tspeed: 1.8250s/iter; left time: 15456.1221s\n",
      "\titers: 200, epoch: 2 | loss: 0.1067887\n",
      "\tspeed: 0.1000s/iter; left time: 836.8144s\n",
      "\titers: 300, epoch: 2 | loss: 0.1190840\n",
      "\tspeed: 0.0996s/iter; left time: 823.8945s\n",
      "\titers: 400, epoch: 2 | loss: 0.1473010\n",
      "\tspeed: 0.0997s/iter; left time: 814.5914s\n",
      "\titers: 500, epoch: 2 | loss: 0.1303439\n",
      "\tspeed: 0.0997s/iter; left time: 804.4150s\n",
      "\titers: 600, epoch: 2 | loss: 0.1326608\n",
      "\tspeed: 0.1002s/iter; left time: 798.3965s\n",
      "\titers: 700, epoch: 2 | loss: 0.0995354\n",
      "\tspeed: 0.1000s/iter; left time: 787.2770s\n",
      "\titers: 800, epoch: 2 | loss: 0.0953862\n",
      "\tspeed: 0.1003s/iter; left time: 778.8852s\n",
      "\titers: 900, epoch: 2 | loss: 0.1124942\n",
      "\tspeed: 0.1003s/iter; left time: 769.0181s\n",
      "Epoch: 2 cost time: 95.84958529472351\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.1200559 Vali Loss: 0.1592139 Test Loss: 0.1810189\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0958035\n",
      "\tspeed: 1.5242s/iter; left time: 11457.3808s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142738\n",
      "\tspeed: 0.1028s/iter; left time: 762.4390s\n",
      "\titers: 300, epoch: 3 | loss: 0.1045007\n",
      "\tspeed: 0.0913s/iter; left time: 667.7384s\n",
      "\titers: 400, epoch: 3 | loss: 0.1465833\n",
      "\tspeed: 0.0913s/iter; left time: 658.6270s\n",
      "\titers: 500, epoch: 3 | loss: 0.1119480\n",
      "\tspeed: 0.0875s/iter; left time: 622.7055s\n",
      "\titers: 600, epoch: 3 | loss: 0.1064399\n",
      "\tspeed: 0.0899s/iter; left time: 630.5803s\n",
      "\titers: 700, epoch: 3 | loss: 0.0851554\n",
      "\tspeed: 0.0888s/iter; left time: 614.3725s\n",
      "\titers: 800, epoch: 3 | loss: 0.1163112\n",
      "\tspeed: 0.0911s/iter; left time: 620.6885s\n",
      "\titers: 900, epoch: 3 | loss: 0.1216705\n",
      "\tspeed: 0.0884s/iter; left time: 593.7825s\n",
      "Epoch: 3 cost time: 88.01556706428528\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.1087557 Vali Loss: 0.1433149 Test Loss: 0.1762556\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1015105\n",
      "\tspeed: 1.8338s/iter; left time: 12038.6038s\n",
      "\titers: 200, epoch: 4 | loss: 0.0733514\n",
      "\tspeed: 0.0889s/iter; left time: 574.7203s\n",
      "\titers: 300, epoch: 4 | loss: 0.1085945\n",
      "\tspeed: 0.0883s/iter; left time: 561.9862s\n",
      "\titers: 400, epoch: 4 | loss: 0.1227592\n",
      "\tspeed: 0.0901s/iter; left time: 564.4258s\n",
      "\titers: 500, epoch: 4 | loss: 0.0913731\n",
      "\tspeed: 0.0882s/iter; left time: 543.8933s\n",
      "\titers: 600, epoch: 4 | loss: 0.0886349\n",
      "\tspeed: 0.0896s/iter; left time: 543.7163s\n",
      "\titers: 700, epoch: 4 | loss: 0.0858199\n",
      "\tspeed: 0.0889s/iter; left time: 530.2919s\n",
      "\titers: 800, epoch: 4 | loss: 0.1038520\n",
      "\tspeed: 0.0887s/iter; left time: 520.4663s\n",
      "\titers: 900, epoch: 4 | loss: 0.0977528\n",
      "\tspeed: 0.0893s/iter; left time: 514.8489s\n",
      "Epoch: 4 cost time: 85.33696150779724\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.1044227 Vali Loss: 0.1236775 Test Loss: 0.1557743\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 1) (8663, 1, 96, 1)\n",
      "test shape: (8663, 96, 1) (8663, 96, 1)\n",
      "mse:0.16703136265277863, mae:0.24031008780002594\n",
      "\n",
      "Extracted Part: long_term_forecast__96_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__96_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=1, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=1, factor=5, features='S', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_192_DE_solar_generation_actual', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='DE_solar_generation_actual', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.3216017\n",
      "\tspeed: 0.1373s/iter; left time: 1289.2167s\n",
      "\titers: 200, epoch: 1 | loss: 0.1363179\n",
      "\tspeed: 0.1225s/iter; left time: 1138.4196s\n",
      "\titers: 300, epoch: 1 | loss: 0.1858657\n",
      "\tspeed: 0.1208s/iter; left time: 1109.9056s\n",
      "\titers: 400, epoch: 1 | loss: 0.1645419\n",
      "\tspeed: 0.1202s/iter; left time: 1092.4515s\n",
      "\titers: 500, epoch: 1 | loss: 0.1233561\n",
      "\tspeed: 0.1206s/iter; left time: 1084.5274s\n",
      "\titers: 600, epoch: 1 | loss: 0.1418093\n",
      "\tspeed: 0.1207s/iter; left time: 1073.5452s\n",
      "\titers: 700, epoch: 1 | loss: 0.1268070\n",
      "\tspeed: 0.1251s/iter; left time: 1100.0183s\n",
      "\titers: 800, epoch: 1 | loss: 0.1113596\n",
      "\tspeed: 0.1349s/iter; left time: 1172.2264s\n",
      "\titers: 900, epoch: 1 | loss: 0.1333542\n",
      "\tspeed: 0.1465s/iter; left time: 1258.7479s\n",
      "Epoch: 1 cost time: 121.77108502388\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.2207736 Vali Loss: 0.1628055 Test Loss: 0.2066454\n",
      "Validation loss decreased (inf --> 0.162805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1340277\n",
      "\tspeed: 3.1082s/iter; left time: 26239.2293s\n",
      "\titers: 200, epoch: 2 | loss: 0.1108377\n",
      "\tspeed: 0.1435s/iter; left time: 1197.4458s\n",
      "\titers: 300, epoch: 2 | loss: 0.1191445\n",
      "\tspeed: 0.1389s/iter; left time: 1144.4785s\n",
      "\titers: 400, epoch: 2 | loss: 0.1084000\n",
      "\tspeed: 0.1413s/iter; left time: 1150.5698s\n",
      "\titers: 500, epoch: 2 | loss: 0.1294561\n",
      "\tspeed: 0.1434s/iter; left time: 1153.6035s\n",
      "\titers: 600, epoch: 2 | loss: 0.1361437\n",
      "\tspeed: 0.1385s/iter; left time: 1100.1053s\n",
      "\titers: 700, epoch: 2 | loss: 0.1058503\n",
      "\tspeed: 0.1462s/iter; left time: 1146.4109s\n",
      "\titers: 800, epoch: 2 | loss: 0.1145463\n",
      "\tspeed: 0.1535s/iter; left time: 1188.0446s\n",
      "\titers: 900, epoch: 2 | loss: 0.1092352\n",
      "\tspeed: 0.1439s/iter; left time: 1099.5149s\n",
      "Epoch: 2 cost time: 137.35154461860657\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.1219716 Vali Loss: 0.1275223 Test Loss: 0.1650543\n",
      "Validation loss decreased (0.162805 --> 0.127522).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0762820\n",
      "\tspeed: 2.1181s/iter; left time: 15871.2386s\n",
      "\titers: 200, epoch: 3 | loss: 0.1336645\n",
      "\tspeed: 0.1178s/iter; left time: 871.2389s\n",
      "\titers: 300, epoch: 3 | loss: 0.1097819\n",
      "\tspeed: 0.1238s/iter; left time: 902.5692s\n",
      "\titers: 400, epoch: 3 | loss: 0.1522210\n",
      "\tspeed: 0.1240s/iter; left time: 891.9983s\n",
      "\titers: 500, epoch: 3 | loss: 0.1155971\n",
      "\tspeed: 0.1211s/iter; left time: 858.6695s\n",
      "\titers: 600, epoch: 3 | loss: 0.1103802\n",
      "\tspeed: 0.1241s/iter; left time: 867.9609s\n",
      "\titers: 700, epoch: 3 | loss: 0.1011095\n",
      "\tspeed: 0.1247s/iter; left time: 859.3155s\n",
      "\titers: 800, epoch: 3 | loss: 0.1012477\n",
      "\tspeed: 0.1254s/iter; left time: 851.5328s\n",
      "\titers: 900, epoch: 3 | loss: 0.1243548\n",
      "\tspeed: 0.1225s/iter; left time: 819.7834s\n",
      "Epoch: 3 cost time: 116.92713379859924\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.1137487 Vali Loss: 0.1526710 Test Loss: 0.1784246\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1051009\n",
      "\tspeed: 2.4022s/iter; left time: 15720.0593s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826798\n",
      "\tspeed: 0.1483s/iter; left time: 955.7401s\n",
      "\titers: 300, epoch: 4 | loss: 0.1216753\n",
      "\tspeed: 0.1422s/iter; left time: 902.1776s\n",
      "\titers: 400, epoch: 4 | loss: 0.1012930\n",
      "\tspeed: 0.1373s/iter; left time: 857.3821s\n",
      "\titers: 500, epoch: 4 | loss: 0.1317167\n",
      "\tspeed: 0.1382s/iter; left time: 849.0089s\n",
      "\titers: 600, epoch: 4 | loss: 0.0999965\n",
      "\tspeed: 0.1408s/iter; left time: 850.7050s\n",
      "\titers: 700, epoch: 4 | loss: 0.1081559\n",
      "\tspeed: 0.1456s/iter; left time: 865.6433s\n",
      "\titers: 800, epoch: 4 | loss: 0.1114196\n",
      "\tspeed: 0.1495s/iter; left time: 873.9391s\n",
      "\titers: 900, epoch: 4 | loss: 0.1035274\n",
      "\tspeed: 0.1364s/iter; left time: 783.6481s\n",
      "Epoch: 4 cost time: 134.67494940757751\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.1101392 Vali Loss: 0.1522762 Test Loss: 0.1768062\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1300695\n",
      "\tspeed: 2.8924s/iter; left time: 16182.7976s\n",
      "\titers: 200, epoch: 5 | loss: 0.0908721\n",
      "\tspeed: 0.1427s/iter; left time: 783.8903s\n",
      "\titers: 300, epoch: 5 | loss: 0.1226206\n",
      "\tspeed: 0.1442s/iter; left time: 777.7468s\n",
      "\titers: 400, epoch: 5 | loss: 0.0965408\n",
      "\tspeed: 0.1422s/iter; left time: 752.9829s\n",
      "\titers: 500, epoch: 5 | loss: 0.1364177\n",
      "\tspeed: 0.1426s/iter; left time: 740.8012s\n",
      "\titers: 600, epoch: 5 | loss: 0.1284340\n",
      "\tspeed: 0.1486s/iter; left time: 757.1125s\n",
      "\titers: 700, epoch: 5 | loss: 0.1021258\n",
      "\tspeed: 0.1381s/iter; left time: 689.6357s\n",
      "\titers: 800, epoch: 5 | loss: 0.0966892\n",
      "\tspeed: 0.1391s/iter; left time: 680.9583s\n",
      "\titers: 900, epoch: 5 | loss: 0.1270067\n",
      "\tspeed: 0.1468s/iter; left time: 704.1308s\n",
      "Epoch: 5 cost time: 135.7723731994629\n",
      "Epoch: 5, Steps: 949 | Train Loss: 0.1079301 Vali Loss: 0.1425909 Test Loss: 0.1697117\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 1) (8567, 1, 192, 1)\n",
      "test shape: (8567, 192, 1) (8567, 192, 1)\n",
      "mse:0.16506774723529816, mae:0.2287590503692627\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.2700883\n",
      "\tspeed: 0.1468s/iter; left time: 1378.4789s\n",
      "\titers: 200, epoch: 1 | loss: 0.1561133\n",
      "\tspeed: 0.1376s/iter; left time: 1278.2582s\n",
      "\titers: 300, epoch: 1 | loss: 0.1470979\n",
      "\tspeed: 0.1409s/iter; left time: 1295.1527s\n",
      "\titers: 400, epoch: 1 | loss: 0.1441173\n",
      "\tspeed: 0.1296s/iter; left time: 1177.8850s\n",
      "\titers: 500, epoch: 1 | loss: 0.1696594\n",
      "\tspeed: 0.1217s/iter; left time: 1094.3687s\n",
      "\titers: 600, epoch: 1 | loss: 0.1706400\n",
      "\tspeed: 0.1086s/iter; left time: 965.1399s\n",
      "\titers: 700, epoch: 1 | loss: 0.1520520\n",
      "\tspeed: 0.1248s/iter; left time: 1097.1107s\n",
      "\titers: 800, epoch: 1 | loss: 0.1166205\n",
      "\tspeed: 0.1391s/iter; left time: 1209.1060s\n",
      "\titers: 900, epoch: 1 | loss: 0.1330544\n",
      "\tspeed: 0.1408s/iter; left time: 1209.4827s\n",
      "Epoch: 1 cost time: 126.15794515609741\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.2060230 Vali Loss: 0.1309320 Test Loss: 0.1761904\n",
      "Validation loss decreased (inf --> 0.130932).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1170979\n",
      "\tspeed: 2.5871s/iter; left time: 21840.1203s\n",
      "\titers: 200, epoch: 2 | loss: 0.1551921\n",
      "\tspeed: 0.1415s/iter; left time: 1180.7066s\n",
      "\titers: 300, epoch: 2 | loss: 0.1496941\n",
      "\tspeed: 0.1409s/iter; left time: 1161.3384s\n",
      "\titers: 400, epoch: 2 | loss: 0.0867709\n",
      "\tspeed: 0.1363s/iter; left time: 1109.9828s\n",
      "\titers: 500, epoch: 2 | loss: 0.1010501\n",
      "\tspeed: 0.1385s/iter; left time: 1113.6178s\n",
      "\titers: 600, epoch: 2 | loss: 0.1209113\n",
      "\tspeed: 0.1384s/iter; left time: 1099.4707s\n",
      "\titers: 700, epoch: 2 | loss: 0.1286608\n",
      "\tspeed: 0.1379s/iter; left time: 1081.5701s\n",
      "\titers: 800, epoch: 2 | loss: 0.1223057\n",
      "\tspeed: 0.1403s/iter; left time: 1086.0427s\n",
      "\titers: 900, epoch: 2 | loss: 0.1205456\n",
      "\tspeed: 0.1401s/iter; left time: 1070.6646s\n",
      "Epoch: 2 cost time: 132.91701698303223\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.1221754 Vali Loss: 0.1374187 Test Loss: 0.1725814\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1236959\n",
      "\tspeed: 2.6853s/iter; left time: 20121.1678s\n",
      "\titers: 200, epoch: 3 | loss: 0.1439191\n",
      "\tspeed: 0.1427s/iter; left time: 1055.1354s\n",
      "\titers: 300, epoch: 3 | loss: 0.1212281\n",
      "\tspeed: 0.1408s/iter; left time: 1026.6894s\n",
      "\titers: 400, epoch: 3 | loss: 0.1099152\n",
      "\tspeed: 0.1251s/iter; left time: 900.0460s\n",
      "\titers: 500, epoch: 3 | loss: 0.1080054\n",
      "\tspeed: 0.1229s/iter; left time: 871.6604s\n",
      "\titers: 600, epoch: 3 | loss: 0.1146089\n",
      "\tspeed: 0.1228s/iter; left time: 858.6735s\n",
      "\titers: 700, epoch: 3 | loss: 0.1207076\n",
      "\tspeed: 0.1220s/iter; left time: 841.1088s\n",
      "\titers: 800, epoch: 3 | loss: 0.1502322\n",
      "\tspeed: 0.1154s/iter; left time: 783.6229s\n",
      "\titers: 900, epoch: 3 | loss: 0.1176942\n",
      "\tspeed: 0.1168s/iter; left time: 781.4304s\n",
      "Epoch: 3 cost time: 121.2300500869751\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.1131997 Vali Loss: 0.1241353 Test Loss: 0.1602693\n",
      "Validation loss decreased (0.130932 --> 0.124135).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0951901\n",
      "\tspeed: 1.5833s/iter; left time: 10360.8627s\n",
      "\titers: 200, epoch: 4 | loss: 0.1160784\n",
      "\tspeed: 0.1213s/iter; left time: 781.5753s\n",
      "\titers: 300, epoch: 4 | loss: 0.0863028\n",
      "\tspeed: 0.1111s/iter; left time: 705.1043s\n",
      "\titers: 400, epoch: 4 | loss: 0.1061532\n",
      "\tspeed: 0.1126s/iter; left time: 702.7885s\n",
      "\titers: 500, epoch: 4 | loss: 0.1101004\n",
      "\tspeed: 0.1149s/iter; left time: 705.9762s\n",
      "\titers: 600, epoch: 4 | loss: 0.0986627\n",
      "\tspeed: 0.1146s/iter; left time: 692.8425s\n",
      "\titers: 700, epoch: 4 | loss: 0.1008343\n",
      "\tspeed: 0.1363s/iter; left time: 809.9734s\n",
      "\titers: 800, epoch: 4 | loss: 0.1076875\n",
      "\tspeed: 0.1407s/iter; left time: 822.4212s\n",
      "\titers: 900, epoch: 4 | loss: 0.0929652\n",
      "\tspeed: 0.1348s/iter; left time: 774.4506s\n",
      "Epoch: 4 cost time: 119.00131511688232\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.1086962 Vali Loss: 0.1472708 Test Loss: 0.1769447\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0911248\n",
      "\tspeed: 3.0415s/iter; left time: 17016.9991s\n",
      "\titers: 200, epoch: 5 | loss: 0.0942685\n",
      "\tspeed: 0.1418s/iter; left time: 779.0674s\n",
      "\titers: 300, epoch: 5 | loss: 0.1032712\n",
      "\tspeed: 0.1399s/iter; left time: 754.6059s\n",
      "\titers: 400, epoch: 5 | loss: 0.0968749\n",
      "\tspeed: 0.1464s/iter; left time: 774.9418s\n",
      "\titers: 500, epoch: 5 | loss: 0.0910326\n",
      "\tspeed: 0.1405s/iter; left time: 729.9451s\n",
      "\titers: 600, epoch: 5 | loss: 0.1060756\n",
      "\tspeed: 0.1423s/iter; left time: 725.1096s\n",
      "\titers: 700, epoch: 5 | loss: 0.1167327\n",
      "\tspeed: 0.1428s/iter; left time: 713.1552s\n",
      "\titers: 800, epoch: 5 | loss: 0.0917412\n",
      "\tspeed: 0.1392s/iter; left time: 681.2211s\n",
      "\titers: 900, epoch: 5 | loss: 0.1210441\n",
      "\tspeed: 0.1407s/iter; left time: 674.5848s\n",
      "Epoch: 5 cost time: 135.42900109291077\n",
      "Epoch: 5, Steps: 949 | Train Loss: 0.1059559 Vali Loss: 0.1456820 Test Loss: 0.1714012\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1114668\n",
      "\tspeed: 2.8638s/iter; left time: 13305.2979s\n",
      "\titers: 200, epoch: 6 | loss: 0.0985612\n",
      "\tspeed: 0.1357s/iter; left time: 616.7796s\n",
      "\titers: 300, epoch: 6 | loss: 0.1089530\n",
      "\tspeed: 0.1378s/iter; left time: 612.7462s\n",
      "\titers: 400, epoch: 6 | loss: 0.1115271\n",
      "\tspeed: 0.1387s/iter; left time: 602.5908s\n",
      "\titers: 500, epoch: 6 | loss: 0.1028463\n",
      "\tspeed: 0.1367s/iter; left time: 580.5864s\n",
      "\titers: 600, epoch: 6 | loss: 0.1031839\n",
      "\tspeed: 0.1384s/iter; left time: 573.8375s\n",
      "\titers: 700, epoch: 6 | loss: 0.1164617\n",
      "\tspeed: 0.1447s/iter; left time: 585.6109s\n",
      "\titers: 800, epoch: 6 | loss: 0.0928602\n",
      "\tspeed: 0.1432s/iter; left time: 565.0093s\n",
      "\titers: 900, epoch: 6 | loss: 0.0793763\n",
      "\tspeed: 0.1402s/iter; left time: 539.2892s\n",
      "Epoch: 6 cost time: 132.72748112678528\n",
      "Epoch: 6, Steps: 949 | Train Loss: 0.1039751 Vali Loss: 0.1464853 Test Loss: 0.1705980\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 1) (8567, 1, 192, 1)\n",
      "test shape: (8567, 192, 1) (8567, 192, 1)\n",
      "mse:0.1602500081062317, mae:0.2232259064912796\n",
      "\n",
      "Extracted Part: long_term_forecast__192_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__192_DE_solar_generation_actual_Informer_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=1, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=1, factor=5, features='S', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_24_DE_wind_generation_actual', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=24, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='DE_wind_generation_actual', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.5572323\n",
      "\tspeed: 0.0819s/iter; left time: 773.3166s\n",
      "\titers: 200, epoch: 1 | loss: 0.4448757\n",
      "\tspeed: 0.0673s/iter; left time: 628.2102s\n",
      "\titers: 300, epoch: 1 | loss: 0.3694775\n",
      "\tspeed: 0.0675s/iter; left time: 623.8433s\n",
      "\titers: 400, epoch: 1 | loss: 0.3178607\n",
      "\tspeed: 0.0665s/iter; left time: 607.4601s\n",
      "\titers: 500, epoch: 1 | loss: 0.3314666\n",
      "\tspeed: 0.0656s/iter; left time: 593.1436s\n",
      "\titers: 600, epoch: 1 | loss: 0.3253468\n",
      "\tspeed: 0.0663s/iter; left time: 593.1881s\n",
      "\titers: 700, epoch: 1 | loss: 0.3323730\n",
      "\tspeed: 0.0693s/iter; left time: 612.6116s\n",
      "\titers: 800, epoch: 1 | loss: 0.3473037\n",
      "\tspeed: 0.0673s/iter; left time: 588.4396s\n",
      "\titers: 900, epoch: 1 | loss: 0.3356878\n",
      "\tspeed: 0.0690s/iter; left time: 596.2016s\n",
      "Epoch: 1 cost time: 65.92292380332947\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.4550349 Vali Loss: 0.5582978 Test Loss: 0.6950771\n",
      "Validation loss decreased (inf --> 0.558298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5005322\n",
      "\tspeed: 1.9622s/iter; left time: 16653.1556s\n",
      "\titers: 200, epoch: 2 | loss: 0.3799969\n",
      "\tspeed: 0.0677s/iter; left time: 567.7145s\n",
      "\titers: 300, epoch: 2 | loss: 0.3587454\n",
      "\tspeed: 0.0696s/iter; left time: 576.4335s\n",
      "\titers: 400, epoch: 2 | loss: 0.3169991\n",
      "\tspeed: 0.0687s/iter; left time: 562.8298s\n",
      "\titers: 500, epoch: 2 | loss: 0.4031389\n",
      "\tspeed: 0.0682s/iter; left time: 551.5317s\n",
      "\titers: 600, epoch: 2 | loss: 0.4228994\n",
      "\tspeed: 0.0682s/iter; left time: 544.9278s\n",
      "\titers: 700, epoch: 2 | loss: 0.4199405\n",
      "\tspeed: 0.0720s/iter; left time: 568.2238s\n",
      "\titers: 800, epoch: 2 | loss: 0.3724045\n",
      "\tspeed: 0.0675s/iter; left time: 525.5386s\n",
      "\titers: 900, epoch: 2 | loss: 0.4019499\n",
      "\tspeed: 0.0681s/iter; left time: 523.2434s\n",
      "Epoch: 2 cost time: 65.91968607902527\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.3827275 Vali Loss: 0.5487197 Test Loss: 0.6541445\n",
      "Validation loss decreased (0.558298 --> 0.548720).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2815190\n",
      "\tspeed: 1.6464s/iter; left time: 12402.3580s\n",
      "\titers: 200, epoch: 3 | loss: 0.3209378\n",
      "\tspeed: 0.0794s/iter; left time: 590.5452s\n",
      "\titers: 300, epoch: 3 | loss: 0.3505766\n",
      "\tspeed: 0.0802s/iter; left time: 588.1379s\n",
      "\titers: 400, epoch: 3 | loss: 0.4340388\n",
      "\tspeed: 0.0784s/iter; left time: 567.3509s\n",
      "\titers: 500, epoch: 3 | loss: 0.4021564\n",
      "\tspeed: 0.0792s/iter; left time: 564.7967s\n",
      "\titers: 600, epoch: 3 | loss: 0.2745571\n",
      "\tspeed: 0.0813s/iter; left time: 572.1292s\n",
      "\titers: 700, epoch: 3 | loss: 0.3331263\n",
      "\tspeed: 0.0793s/iter; left time: 549.4980s\n",
      "\titers: 800, epoch: 3 | loss: 0.3307028\n",
      "\tspeed: 0.0797s/iter; left time: 544.7823s\n",
      "\titers: 900, epoch: 3 | loss: 0.2774228\n",
      "\tspeed: 0.0795s/iter; left time: 535.4691s\n",
      "Epoch: 3 cost time: 76.41514468193054\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.3485792 Vali Loss: 0.5801538 Test Loss: 0.7393644\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2272018\n",
      "\tspeed: 1.6129s/iter; left time: 10611.1309s\n",
      "\titers: 200, epoch: 4 | loss: 0.2502836\n",
      "\tspeed: 0.0679s/iter; left time: 439.6789s\n",
      "\titers: 300, epoch: 4 | loss: 0.1639560\n",
      "\tspeed: 0.0665s/iter; left time: 424.3183s\n",
      "\titers: 400, epoch: 4 | loss: 0.3048301\n",
      "\tspeed: 0.0676s/iter; left time: 424.5149s\n",
      "\titers: 500, epoch: 4 | loss: 0.3557013\n",
      "\tspeed: 0.0678s/iter; left time: 418.8238s\n",
      "\titers: 600, epoch: 4 | loss: 0.3569252\n",
      "\tspeed: 0.0660s/iter; left time: 401.0218s\n",
      "\titers: 700, epoch: 4 | loss: 0.3238820\n",
      "\tspeed: 0.0660s/iter; left time: 394.3720s\n",
      "\titers: 800, epoch: 4 | loss: 0.4184113\n",
      "\tspeed: 0.0664s/iter; left time: 390.4353s\n",
      "\titers: 900, epoch: 4 | loss: 0.3643007\n",
      "\tspeed: 0.0660s/iter; left time: 381.6722s\n",
      "Epoch: 4 cost time: 64.1615788936615\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.3148047 Vali Loss: 0.5566549 Test Loss: 0.6598099\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3250803\n",
      "\tspeed: 1.6764s/iter; left time: 9429.7936s\n",
      "\titers: 200, epoch: 5 | loss: 0.1954526\n",
      "\tspeed: 0.0674s/iter; left time: 372.3235s\n",
      "\titers: 300, epoch: 5 | loss: 0.2441027\n",
      "\tspeed: 0.0701s/iter; left time: 380.0578s\n",
      "\titers: 400, epoch: 5 | loss: 0.3114851\n",
      "\tspeed: 0.0683s/iter; left time: 363.9176s\n",
      "\titers: 500, epoch: 5 | loss: 0.3751462\n",
      "\tspeed: 0.0676s/iter; left time: 353.4583s\n",
      "\titers: 600, epoch: 5 | loss: 0.3390769\n",
      "\tspeed: 0.0690s/iter; left time: 353.7040s\n",
      "\titers: 700, epoch: 5 | loss: 0.1951835\n",
      "\tspeed: 0.0679s/iter; left time: 341.3330s\n",
      "\titers: 800, epoch: 5 | loss: 0.2741965\n",
      "\tspeed: 0.0678s/iter; left time: 333.9145s\n",
      "\titers: 900, epoch: 5 | loss: 0.2622778\n",
      "\tspeed: 0.0677s/iter; left time: 326.8688s\n",
      "Epoch: 5 cost time: 65.72421455383301\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.2927286 Vali Loss: 0.5729383 Test Loss: 0.6496488\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 1) (8735, 1, 24, 1)\n",
      "test shape: (8735, 24, 1) (8735, 24, 1)\n",
      "mse:0.6545013785362244, mae:0.5839739441871643\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.6551771\n",
      "\tspeed: 0.0763s/iter; left time: 720.3490s\n",
      "\titers: 200, epoch: 1 | loss: 0.5374793\n",
      "\tspeed: 0.0714s/iter; left time: 666.7615s\n",
      "\titers: 300, epoch: 1 | loss: 0.4287822\n",
      "\tspeed: 0.0700s/iter; left time: 646.7833s\n",
      "\titers: 400, epoch: 1 | loss: 0.4570041\n",
      "\tspeed: 0.0703s/iter; left time: 642.7449s\n",
      "\titers: 500, epoch: 1 | loss: 0.2900365\n",
      "\tspeed: 0.0705s/iter; left time: 637.1351s\n",
      "\titers: 600, epoch: 1 | loss: 0.3967379\n",
      "\tspeed: 0.0688s/iter; left time: 615.2591s\n",
      "\titers: 700, epoch: 1 | loss: 0.3599232\n",
      "\tspeed: 0.0680s/iter; left time: 601.1202s\n",
      "\titers: 800, epoch: 1 | loss: 0.3800548\n",
      "\tspeed: 0.0674s/iter; left time: 589.1389s\n",
      "\titers: 900, epoch: 1 | loss: 0.2360621\n",
      "\tspeed: 0.0680s/iter; left time: 587.6266s\n",
      "Epoch: 1 cost time: 66.91111707687378\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.4719446 Vali Loss: 0.6237425 Test Loss: 0.7844881\n",
      "Validation loss decreased (inf --> 0.623743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2612551\n",
      "\tspeed: 1.7225s/iter; left time: 14618.7262s\n",
      "\titers: 200, epoch: 2 | loss: 0.4090391\n",
      "\tspeed: 0.0716s/iter; left time: 600.2479s\n",
      "\titers: 300, epoch: 2 | loss: 0.3142110\n",
      "\tspeed: 0.0697s/iter; left time: 578.0126s\n",
      "\titers: 400, epoch: 2 | loss: 0.4040985\n",
      "\tspeed: 0.0698s/iter; left time: 571.8591s\n",
      "\titers: 500, epoch: 2 | loss: 0.2802789\n",
      "\tspeed: 0.0691s/iter; left time: 558.5376s\n",
      "\titers: 600, epoch: 2 | loss: 0.4498811\n",
      "\tspeed: 0.0692s/iter; left time: 552.9896s\n",
      "\titers: 700, epoch: 2 | loss: 0.6055081\n",
      "\tspeed: 0.0693s/iter; left time: 546.3155s\n",
      "\titers: 800, epoch: 2 | loss: 0.4449690\n",
      "\tspeed: 0.0701s/iter; left time: 545.5609s\n",
      "\titers: 900, epoch: 2 | loss: 0.2641930\n",
      "\tspeed: 0.0695s/iter; left time: 533.8692s\n",
      "Epoch: 2 cost time: 67.42311000823975\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.3819962 Vali Loss: 0.5354876 Test Loss: 0.6327021\n",
      "Validation loss decreased (0.623743 --> 0.535488).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4057409\n",
      "\tspeed: 1.7101s/iter; left time: 12881.8427s\n",
      "\titers: 200, epoch: 3 | loss: 0.5766126\n",
      "\tspeed: 0.0715s/iter; left time: 531.2770s\n",
      "\titers: 300, epoch: 3 | loss: 0.1921342\n",
      "\tspeed: 0.0700s/iter; left time: 513.2374s\n",
      "\titers: 400, epoch: 3 | loss: 0.3550608\n",
      "\tspeed: 0.0709s/iter; left time: 512.5460s\n",
      "\titers: 500, epoch: 3 | loss: 0.3124747\n",
      "\tspeed: 0.0709s/iter; left time: 506.0359s\n",
      "\titers: 600, epoch: 3 | loss: 0.3631157\n",
      "\tspeed: 0.0688s/iter; left time: 483.5832s\n",
      "\titers: 700, epoch: 3 | loss: 0.3337310\n",
      "\tspeed: 0.0706s/iter; left time: 489.6729s\n",
      "\titers: 800, epoch: 3 | loss: 0.3566642\n",
      "\tspeed: 0.0708s/iter; left time: 483.7727s\n",
      "\titers: 900, epoch: 3 | loss: 0.2837871\n",
      "\tspeed: 0.0706s/iter; left time: 475.3462s\n",
      "Epoch: 3 cost time: 68.22279787063599\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.3468584 Vali Loss: 0.5208558 Test Loss: 0.6247236\n",
      "Validation loss decreased (0.535488 --> 0.520856).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3083104\n",
      "\tspeed: 1.7254s/iter; left time: 11351.2839s\n",
      "\titers: 200, epoch: 4 | loss: 0.2593141\n",
      "\tspeed: 0.0771s/iter; left time: 499.6162s\n",
      "\titers: 300, epoch: 4 | loss: 0.2579650\n",
      "\tspeed: 0.0828s/iter; left time: 528.3643s\n",
      "\titers: 400, epoch: 4 | loss: 0.2781546\n",
      "\tspeed: 0.0819s/iter; left time: 513.9488s\n",
      "\titers: 500, epoch: 4 | loss: 0.2287960\n",
      "\tspeed: 0.0804s/iter; left time: 496.5360s\n",
      "\titers: 600, epoch: 4 | loss: 0.2259487\n",
      "\tspeed: 0.0811s/iter; left time: 493.1775s\n",
      "\titers: 700, epoch: 4 | loss: 0.4396087\n",
      "\tspeed: 0.0810s/iter; left time: 484.5882s\n",
      "\titers: 800, epoch: 4 | loss: 0.4405689\n",
      "\tspeed: 0.0822s/iter; left time: 483.0665s\n",
      "\titers: 900, epoch: 4 | loss: 0.2630619\n",
      "\tspeed: 0.0816s/iter; left time: 471.6079s\n",
      "Epoch: 4 cost time: 77.27128005027771\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.3201338 Vali Loss: 0.5586113 Test Loss: 0.6576839\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2605606\n",
      "\tspeed: 1.5256s/iter; left time: 8581.6946s\n",
      "\titers: 200, epoch: 5 | loss: 0.1577328\n",
      "\tspeed: 0.0724s/iter; left time: 399.7577s\n",
      "\titers: 300, epoch: 5 | loss: 0.1837601\n",
      "\tspeed: 0.0707s/iter; left time: 383.6021s\n",
      "\titers: 400, epoch: 5 | loss: 0.2531990\n",
      "\tspeed: 0.0726s/iter; left time: 386.5117s\n",
      "\titers: 500, epoch: 5 | loss: 0.3046651\n",
      "\tspeed: 0.0685s/iter; left time: 357.8699s\n",
      "\titers: 600, epoch: 5 | loss: 0.3146862\n",
      "\tspeed: 0.0672s/iter; left time: 344.6051s\n",
      "\titers: 700, epoch: 5 | loss: 0.3275302\n",
      "\tspeed: 0.0681s/iter; left time: 342.1259s\n",
      "\titers: 800, epoch: 5 | loss: 0.2997349\n",
      "\tspeed: 0.0681s/iter; left time: 335.4054s\n",
      "\titers: 900, epoch: 5 | loss: 0.3808646\n",
      "\tspeed: 0.0698s/iter; left time: 336.8881s\n",
      "Epoch: 5 cost time: 67.31013107299805\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.3039923 Vali Loss: 0.5923899 Test Loss: 0.6954013\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2192200\n",
      "\tspeed: 1.7015s/iter; left time: 7947.8940s\n",
      "\titers: 200, epoch: 6 | loss: 0.2843288\n",
      "\tspeed: 0.0697s/iter; left time: 318.7274s\n",
      "\titers: 300, epoch: 6 | loss: 0.4425208\n",
      "\tspeed: 0.0687s/iter; left time: 307.3367s\n",
      "\titers: 400, epoch: 6 | loss: 0.5224752\n",
      "\tspeed: 0.0722s/iter; left time: 315.6235s\n",
      "\titers: 500, epoch: 6 | loss: 0.3007174\n",
      "\tspeed: 0.0710s/iter; left time: 303.0438s\n",
      "\titers: 600, epoch: 6 | loss: 0.2969752\n",
      "\tspeed: 0.0688s/iter; left time: 287.1560s\n",
      "\titers: 700, epoch: 6 | loss: 0.2737163\n",
      "\tspeed: 0.0677s/iter; left time: 275.7515s\n",
      "\titers: 800, epoch: 6 | loss: 0.2005433\n",
      "\tspeed: 0.0690s/iter; left time: 273.9521s\n",
      "\titers: 900, epoch: 6 | loss: 0.2836852\n",
      "\tspeed: 0.0676s/iter; left time: 261.6871s\n",
      "Epoch: 6 cost time: 66.8708188533783\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.2905545 Vali Loss: 0.5854358 Test Loss: 0.6629839\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 1) (8735, 1, 24, 1)\n",
      "test shape: (8735, 24, 1) (8735, 24, 1)\n",
      "mse:0.6241730451583862, mae:0.5690067410469055\n",
      "\n",
      "Extracted Part: long_term_forecast__24_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__24_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=1, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=1, factor=5, features='S', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_48_DE_wind_generation_actual', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=48, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='DE_wind_generation_actual', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.6887225\n",
      "\tspeed: 0.0940s/iter; left time: 886.8738s\n",
      "\titers: 200, epoch: 1 | loss: 0.5107099\n",
      "\tspeed: 0.0833s/iter; left time: 777.2787s\n",
      "\titers: 300, epoch: 1 | loss: 0.7689399\n",
      "\tspeed: 0.0819s/iter; left time: 756.3700s\n",
      "\titers: 400, epoch: 1 | loss: 0.6798980\n",
      "\tspeed: 0.0824s/iter; left time: 752.0817s\n",
      "\titers: 500, epoch: 1 | loss: 0.6041614\n",
      "\tspeed: 0.0777s/iter; left time: 702.1170s\n",
      "\titers: 600, epoch: 1 | loss: 0.6950924\n",
      "\tspeed: 0.0675s/iter; left time: 603.1219s\n",
      "\titers: 700, epoch: 1 | loss: 0.4993938\n",
      "\tspeed: 0.0677s/iter; left time: 597.8399s\n",
      "\titers: 800, epoch: 1 | loss: 0.7296857\n",
      "\tspeed: 0.0677s/iter; left time: 591.2232s\n",
      "\titers: 900, epoch: 1 | loss: 0.4919892\n",
      "\tspeed: 0.0717s/iter; left time: 619.0147s\n",
      "Epoch: 1 cost time: 73.84863567352295\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.6412159 Vali Loss: 0.7946241 Test Loss: 1.0692393\n",
      "Validation loss decreased (inf --> 0.794624).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7596664\n",
      "\tspeed: 1.6396s/iter; left time: 13900.9525s\n",
      "\titers: 200, epoch: 2 | loss: 0.5300848\n",
      "\tspeed: 0.0727s/iter; left time: 609.0887s\n",
      "\titers: 300, epoch: 2 | loss: 0.3818451\n",
      "\tspeed: 0.0717s/iter; left time: 593.5011s\n",
      "\titers: 400, epoch: 2 | loss: 0.5674471\n",
      "\tspeed: 0.0722s/iter; left time: 590.6073s\n",
      "\titers: 500, epoch: 2 | loss: 0.7497802\n",
      "\tspeed: 0.0734s/iter; left time: 593.1216s\n",
      "\titers: 600, epoch: 2 | loss: 0.7989782\n",
      "\tspeed: 0.0729s/iter; left time: 581.9901s\n",
      "\titers: 700, epoch: 2 | loss: 0.7906040\n",
      "\tspeed: 0.0726s/iter; left time: 571.7660s\n",
      "\titers: 800, epoch: 2 | loss: 0.4833606\n",
      "\tspeed: 0.0743s/iter; left time: 577.7562s\n",
      "\titers: 900, epoch: 2 | loss: 0.5473029\n",
      "\tspeed: 0.0763s/iter; left time: 585.5829s\n",
      "Epoch: 2 cost time: 70.36905932426453\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.5597803 Vali Loss: 0.8979846 Test Loss: 1.0965381\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6364750\n",
      "\tspeed: 1.6990s/iter; left time: 12785.1477s\n",
      "\titers: 200, epoch: 3 | loss: 0.6122440\n",
      "\tspeed: 0.0727s/iter; left time: 539.5909s\n",
      "\titers: 300, epoch: 3 | loss: 0.2786388\n",
      "\tspeed: 0.0753s/iter; left time: 551.4214s\n",
      "\titers: 400, epoch: 3 | loss: 0.5755386\n",
      "\tspeed: 0.0754s/iter; left time: 544.7642s\n",
      "\titers: 500, epoch: 3 | loss: 0.5431096\n",
      "\tspeed: 0.0745s/iter; left time: 530.6519s\n",
      "\titers: 600, epoch: 3 | loss: 0.5693508\n",
      "\tspeed: 0.0730s/iter; left time: 512.6746s\n",
      "\titers: 700, epoch: 3 | loss: 0.6560224\n",
      "\tspeed: 0.0731s/iter; left time: 506.5355s\n",
      "\titers: 800, epoch: 3 | loss: 0.4110553\n",
      "\tspeed: 0.0745s/iter; left time: 508.1871s\n",
      "\titers: 900, epoch: 3 | loss: 0.4015586\n",
      "\tspeed: 0.0738s/iter; left time: 496.3711s\n",
      "Epoch: 3 cost time: 70.92757749557495\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.5158076 Vali Loss: 0.7932831 Test Loss: 1.0034566\n",
      "Validation loss decreased (0.794624 --> 0.793283).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4659845\n",
      "\tspeed: 1.4994s/iter; left time: 9854.0202s\n",
      "\titers: 200, epoch: 4 | loss: 0.4796256\n",
      "\tspeed: 0.0842s/iter; left time: 545.2491s\n",
      "\titers: 300, epoch: 4 | loss: 0.6297247\n",
      "\tspeed: 0.0759s/iter; left time: 483.7412s\n",
      "\titers: 400, epoch: 4 | loss: 0.5005044\n",
      "\tspeed: 0.0839s/iter; left time: 526.3399s\n",
      "\titers: 500, epoch: 4 | loss: 0.4268821\n",
      "\tspeed: 0.0842s/iter; left time: 519.5822s\n",
      "\titers: 600, epoch: 4 | loss: 0.3942715\n",
      "\tspeed: 0.0855s/iter; left time: 519.2124s\n",
      "\titers: 700, epoch: 4 | loss: 0.6444985\n",
      "\tspeed: 0.0852s/iter; left time: 509.0854s\n",
      "\titers: 800, epoch: 4 | loss: 0.4819245\n",
      "\tspeed: 0.0848s/iter; left time: 497.7556s\n",
      "\titers: 900, epoch: 4 | loss: 0.5084320\n",
      "\tspeed: 0.0838s/iter; left time: 483.5684s\n",
      "Epoch: 4 cost time: 79.9093747138977\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.4754031 Vali Loss: 0.8280530 Test Loss: 1.0278261\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3888615\n",
      "\tspeed: 1.5116s/iter; left time: 8493.9312s\n",
      "\titers: 200, epoch: 5 | loss: 0.5273632\n",
      "\tspeed: 0.0751s/iter; left time: 414.6445s\n",
      "\titers: 300, epoch: 5 | loss: 0.3486099\n",
      "\tspeed: 0.0731s/iter; left time: 396.3861s\n",
      "\titers: 400, epoch: 5 | loss: 0.4704781\n",
      "\tspeed: 0.0735s/iter; left time: 390.6967s\n",
      "\titers: 500, epoch: 5 | loss: 0.4590688\n",
      "\tspeed: 0.0756s/iter; left time: 394.3301s\n",
      "\titers: 600, epoch: 5 | loss: 0.5083677\n",
      "\tspeed: 0.0715s/iter; left time: 366.0699s\n",
      "\titers: 700, epoch: 5 | loss: 0.4127379\n",
      "\tspeed: 0.0756s/iter; left time: 379.3467s\n",
      "\titers: 800, epoch: 5 | loss: 0.3219487\n",
      "\tspeed: 0.0721s/iter; left time: 354.5480s\n",
      "\titers: 900, epoch: 5 | loss: 0.3949207\n",
      "\tspeed: 0.0717s/iter; left time: 345.2819s\n",
      "Epoch: 5 cost time: 70.78306674957275\n",
      "Epoch: 5, Steps: 953 | Train Loss: 0.4395108 Vali Loss: 0.8691450 Test Loss: 1.0896305\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3309757\n",
      "\tspeed: 1.7002s/iter; left time: 7933.0938s\n",
      "\titers: 200, epoch: 6 | loss: 0.2353657\n",
      "\tspeed: 0.0762s/iter; left time: 348.1390s\n",
      "\titers: 300, epoch: 6 | loss: 0.4139326\n",
      "\tspeed: 0.0754s/iter; left time: 336.5200s\n",
      "\titers: 400, epoch: 6 | loss: 0.3570453\n",
      "\tspeed: 0.0754s/iter; left time: 329.0815s\n",
      "\titers: 500, epoch: 6 | loss: 0.4392410\n",
      "\tspeed: 0.0749s/iter; left time: 319.3354s\n",
      "\titers: 600, epoch: 6 | loss: 0.3381782\n",
      "\tspeed: 0.0744s/iter; left time: 309.8435s\n",
      "\titers: 700, epoch: 6 | loss: 0.3688589\n",
      "\tspeed: 0.0774s/iter; left time: 314.7942s\n",
      "\titers: 800, epoch: 6 | loss: 0.3723699\n",
      "\tspeed: 0.0759s/iter; left time: 300.9719s\n",
      "\titers: 900, epoch: 6 | loss: 0.4749608\n",
      "\tspeed: 0.0741s/iter; left time: 286.6180s\n",
      "Epoch: 6 cost time: 72.50860977172852\n",
      "Epoch: 6, Steps: 953 | Train Loss: 0.4137730 Vali Loss: 0.8403117 Test Loss: 1.0450757\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 1) (8711, 1, 48, 1)\n",
      "test shape: (8711, 48, 1) (8711, 48, 1)\n",
      "mse:1.0031168460845947, mae:0.7264240384101868\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.6226380\n",
      "\tspeed: 0.0907s/iter; left time: 855.0865s\n",
      "\titers: 200, epoch: 1 | loss: 0.5812739\n",
      "\tspeed: 0.0853s/iter; left time: 796.1917s\n",
      "\titers: 300, epoch: 1 | loss: 0.6505254\n",
      "\tspeed: 0.0881s/iter; left time: 813.1067s\n",
      "\titers: 400, epoch: 1 | loss: 0.5527072\n",
      "\tspeed: 0.0855s/iter; left time: 780.7794s\n",
      "\titers: 500, epoch: 1 | loss: 0.6906402\n",
      "\tspeed: 0.0848s/iter; left time: 765.8037s\n",
      "\titers: 600, epoch: 1 | loss: 0.5812013\n",
      "\tspeed: 0.0847s/iter; left time: 756.4864s\n",
      "\titers: 700, epoch: 1 | loss: 0.7013516\n",
      "\tspeed: 0.0839s/iter; left time: 740.9242s\n",
      "\titers: 800, epoch: 1 | loss: 0.4902179\n",
      "\tspeed: 0.0839s/iter; left time: 732.5948s\n",
      "\titers: 900, epoch: 1 | loss: 0.5996997\n",
      "\tspeed: 0.0843s/iter; left time: 727.7180s\n",
      "Epoch: 1 cost time: 81.75799942016602\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.6476542 Vali Loss: 0.8003632 Test Loss: 0.9942293\n",
      "Validation loss decreased (inf --> 0.800363).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6245935\n",
      "\tspeed: 1.6196s/iter; left time: 13731.3622s\n",
      "\titers: 200, epoch: 2 | loss: 0.6845542\n",
      "\tspeed: 0.1039s/iter; left time: 870.6422s\n",
      "\titers: 300, epoch: 2 | loss: 0.6728422\n",
      "\tspeed: 0.0985s/iter; left time: 815.2810s\n",
      "\titers: 400, epoch: 2 | loss: 0.7220057\n",
      "\tspeed: 0.0986s/iter; left time: 805.9647s\n",
      "\titers: 500, epoch: 2 | loss: 0.5150800\n",
      "\tspeed: 0.0978s/iter; left time: 789.6913s\n",
      "\titers: 600, epoch: 2 | loss: 0.6902844\n",
      "\tspeed: 0.0972s/iter; left time: 775.6892s\n",
      "\titers: 700, epoch: 2 | loss: 0.5925654\n",
      "\tspeed: 0.0965s/iter; left time: 760.6010s\n",
      "\titers: 800, epoch: 2 | loss: 1.0740807\n",
      "\tspeed: 0.0974s/iter; left time: 757.4619s\n",
      "\titers: 900, epoch: 2 | loss: 0.5426063\n",
      "\tspeed: 0.0764s/iter; left time: 586.4519s\n",
      "Epoch: 2 cost time: 91.70814180374146\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.5600295 Vali Loss: 0.8199589 Test Loss: 1.0801632\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3457080\n",
      "\tspeed: 1.8657s/iter; left time: 14039.5903s\n",
      "\titers: 200, epoch: 3 | loss: 0.4300551\n",
      "\tspeed: 0.0754s/iter; left time: 560.0046s\n",
      "\titers: 300, epoch: 3 | loss: 0.7098575\n",
      "\tspeed: 0.0754s/iter; left time: 552.1256s\n",
      "\titers: 400, epoch: 3 | loss: 0.6252586\n",
      "\tspeed: 0.0746s/iter; left time: 539.0628s\n",
      "\titers: 500, epoch: 3 | loss: 0.3614294\n",
      "\tspeed: 0.0751s/iter; left time: 535.2731s\n",
      "\titers: 600, epoch: 3 | loss: 0.5464662\n",
      "\tspeed: 0.0762s/iter; left time: 535.5716s\n",
      "\titers: 700, epoch: 3 | loss: 0.5104918\n",
      "\tspeed: 0.0760s/iter; left time: 526.3751s\n",
      "\titers: 800, epoch: 3 | loss: 0.4880412\n",
      "\tspeed: 0.0770s/iter; left time: 525.3380s\n",
      "\titers: 900, epoch: 3 | loss: 0.4150617\n",
      "\tspeed: 0.0765s/iter; left time: 514.2825s\n",
      "Epoch: 3 cost time: 73.53142976760864\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.5099302 Vali Loss: 0.8042153 Test Loss: 1.0722474\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5537373\n",
      "\tspeed: 1.8500s/iter; left time: 12158.4308s\n",
      "\titers: 200, epoch: 4 | loss: 0.5430377\n",
      "\tspeed: 0.0757s/iter; left time: 489.9685s\n",
      "\titers: 300, epoch: 4 | loss: 0.5788991\n",
      "\tspeed: 0.0818s/iter; left time: 521.4402s\n",
      "\titers: 400, epoch: 4 | loss: 0.4121108\n",
      "\tspeed: 0.0846s/iter; left time: 530.4178s\n",
      "\titers: 500, epoch: 4 | loss: 0.3663344\n",
      "\tspeed: 0.0843s/iter; left time: 520.5848s\n",
      "\titers: 600, epoch: 4 | loss: 0.3942500\n",
      "\tspeed: 0.0865s/iter; left time: 525.4031s\n",
      "\titers: 700, epoch: 4 | loss: 0.5498053\n",
      "\tspeed: 0.0855s/iter; left time: 510.6434s\n",
      "\titers: 800, epoch: 4 | loss: 0.5628061\n",
      "\tspeed: 0.0870s/iter; left time: 510.6580s\n",
      "\titers: 900, epoch: 4 | loss: 0.3796799\n",
      "\tspeed: 0.0883s/iter; left time: 509.4192s\n",
      "Epoch: 4 cost time: 80.64217042922974\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.4638272 Vali Loss: 0.8627461 Test Loss: 1.1404152\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 1) (8711, 1, 48, 1)\n",
      "test shape: (8711, 48, 1) (8711, 48, 1)\n",
      "mse:0.9941468834877014, mae:0.7426179647445679\n",
      "\n",
      "Extracted Part: long_term_forecast__48_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__48_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=1, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=1, factor=5, features='S', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_96_DE_wind_generation_actual', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='DE_wind_generation_actual', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.6771030\n",
      "\tspeed: 0.1196s/iter; left time: 1126.8866s\n",
      "\titers: 200, epoch: 1 | loss: 0.7759134\n",
      "\tspeed: 0.0844s/iter; left time: 786.3262s\n",
      "\titers: 300, epoch: 1 | loss: 0.6369838\n",
      "\tspeed: 0.0841s/iter; left time: 775.6126s\n",
      "\titers: 400, epoch: 1 | loss: 0.5363414\n",
      "\tspeed: 0.0856s/iter; left time: 781.0220s\n",
      "\titers: 500, epoch: 1 | loss: 0.8152033\n",
      "\tspeed: 0.0857s/iter; left time: 772.7603s\n",
      "\titers: 600, epoch: 1 | loss: 0.5792909\n",
      "\tspeed: 0.0854s/iter; left time: 761.6578s\n",
      "\titers: 700, epoch: 1 | loss: 0.7998774\n",
      "\tspeed: 0.0841s/iter; left time: 742.1216s\n",
      "\titers: 800, epoch: 1 | loss: 0.7984141\n",
      "\tspeed: 0.0871s/iter; left time: 759.9208s\n",
      "\titers: 900, epoch: 1 | loss: 0.5384763\n",
      "\tspeed: 0.0970s/iter; left time: 836.0985s\n",
      "Epoch: 1 cost time: 86.80209922790527\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.7847397 Vali Loss: 0.9646093 Test Loss: 1.3214501\n",
      "Validation loss decreased (inf --> 0.964609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7032005\n",
      "\tspeed: 1.6920s/iter; left time: 14329.9224s\n",
      "\titers: 200, epoch: 2 | loss: 0.9773167\n",
      "\tspeed: 0.0978s/iter; left time: 818.6493s\n",
      "\titers: 300, epoch: 2 | loss: 0.6509828\n",
      "\tspeed: 0.1198s/iter; left time: 990.7530s\n",
      "\titers: 400, epoch: 2 | loss: 0.9303762\n",
      "\tspeed: 0.1200s/iter; left time: 980.4672s\n",
      "\titers: 500, epoch: 2 | loss: 0.5531433\n",
      "\tspeed: 0.1232s/iter; left time: 993.7089s\n",
      "\titers: 600, epoch: 2 | loss: 0.5609571\n",
      "\tspeed: 0.1354s/iter; left time: 1078.8688s\n",
      "\titers: 700, epoch: 2 | loss: 0.5461251\n",
      "\tspeed: 0.1225s/iter; left time: 964.2090s\n",
      "\titers: 800, epoch: 2 | loss: 0.8632907\n",
      "\tspeed: 0.1302s/iter; left time: 1011.4183s\n",
      "\titers: 900, epoch: 2 | loss: 0.8894216\n",
      "\tspeed: 0.1299s/iter; left time: 995.9469s\n",
      "Epoch: 2 cost time: 115.13680219650269\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.7014439 Vali Loss: 0.9489898 Test Loss: 1.2786655\n",
      "Validation loss decreased (0.964609 --> 0.948990).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6724458\n",
      "\tspeed: 2.0996s/iter; left time: 15782.9738s\n",
      "\titers: 200, epoch: 3 | loss: 0.6799847\n",
      "\tspeed: 0.0848s/iter; left time: 628.6379s\n",
      "\titers: 300, epoch: 3 | loss: 0.5661384\n",
      "\tspeed: 0.0870s/iter; left time: 636.7502s\n",
      "\titers: 400, epoch: 3 | loss: 0.9718671\n",
      "\tspeed: 0.0859s/iter; left time: 619.9464s\n",
      "\titers: 500, epoch: 3 | loss: 0.6119372\n",
      "\tspeed: 0.0851s/iter; left time: 605.5329s\n",
      "\titers: 600, epoch: 3 | loss: 0.6717500\n",
      "\tspeed: 0.0875s/iter; left time: 613.7285s\n",
      "\titers: 700, epoch: 3 | loss: 0.9071016\n",
      "\tspeed: 0.0876s/iter; left time: 606.0644s\n",
      "\titers: 800, epoch: 3 | loss: 0.6052699\n",
      "\tspeed: 0.0877s/iter; left time: 597.7692s\n",
      "\titers: 900, epoch: 3 | loss: 0.6667517\n",
      "\tspeed: 0.1090s/iter; left time: 732.3090s\n",
      "Epoch: 3 cost time: 85.33480191230774\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.6487369 Vali Loss: 0.9507244 Test Loss: 1.3234044\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5960284\n",
      "\tspeed: 1.8101s/iter; left time: 11883.3045s\n",
      "\titers: 200, epoch: 4 | loss: 0.7656448\n",
      "\tspeed: 0.0881s/iter; left time: 569.6400s\n",
      "\titers: 300, epoch: 4 | loss: 0.5837189\n",
      "\tspeed: 0.0875s/iter; left time: 557.1499s\n",
      "\titers: 400, epoch: 4 | loss: 0.5914105\n",
      "\tspeed: 0.0850s/iter; left time: 532.6348s\n",
      "\titers: 500, epoch: 4 | loss: 0.4553558\n",
      "\tspeed: 0.0846s/iter; left time: 521.4962s\n",
      "\titers: 600, epoch: 4 | loss: 0.3680499\n",
      "\tspeed: 0.1026s/iter; left time: 622.3415s\n",
      "\titers: 700, epoch: 4 | loss: 0.6948869\n",
      "\tspeed: 0.1379s/iter; left time: 822.5298s\n",
      "\titers: 800, epoch: 4 | loss: 0.5041977\n",
      "\tspeed: 0.0882s/iter; left time: 517.5104s\n",
      "\titers: 900, epoch: 4 | loss: 0.5842611\n",
      "\tspeed: 0.0861s/iter; left time: 496.2617s\n",
      "Epoch: 4 cost time: 89.75405621528625\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.6039466 Vali Loss: 1.0170405 Test Loss: 1.3713225\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.8642439\n",
      "\tspeed: 1.6605s/iter; left time: 9320.4026s\n",
      "\titers: 200, epoch: 5 | loss: 0.6105061\n",
      "\tspeed: 0.0969s/iter; left time: 533.9679s\n",
      "\titers: 300, epoch: 5 | loss: 0.6239032\n",
      "\tspeed: 0.0968s/iter; left time: 524.2023s\n",
      "\titers: 400, epoch: 5 | loss: 0.5545884\n",
      "\tspeed: 0.0968s/iter; left time: 514.2778s\n",
      "\titers: 500, epoch: 5 | loss: 0.5861741\n",
      "\tspeed: 0.0962s/iter; left time: 501.3773s\n",
      "\titers: 600, epoch: 5 | loss: 0.6784672\n",
      "\tspeed: 0.0977s/iter; left time: 499.3651s\n",
      "\titers: 700, epoch: 5 | loss: 0.6697319\n",
      "\tspeed: 0.0982s/iter; left time: 492.1955s\n",
      "\titers: 800, epoch: 5 | loss: 0.5834202\n",
      "\tspeed: 0.0979s/iter; left time: 480.7643s\n",
      "\titers: 900, epoch: 5 | loss: 0.5202563\n",
      "\tspeed: 0.0977s/iter; left time: 470.0767s\n",
      "Epoch: 5 cost time: 94.16193962097168\n",
      "Epoch: 5, Steps: 952 | Train Loss: 0.5671006 Vali Loss: 1.0691521 Test Loss: 1.4014159\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 1) (8663, 1, 96, 1)\n",
      "test shape: (8663, 96, 1) (8663, 96, 1)\n",
      "mse:1.2782334089279175, mae:0.8355177640914917\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 1.0701822\n",
      "\tspeed: 0.0970s/iter; left time: 913.5808s\n",
      "\titers: 200, epoch: 1 | loss: 0.6813685\n",
      "\tspeed: 0.0890s/iter; left time: 829.9274s\n",
      "\titers: 300, epoch: 1 | loss: 0.6223149\n",
      "\tspeed: 0.0874s/iter; left time: 805.7244s\n",
      "\titers: 400, epoch: 1 | loss: 0.6401813\n",
      "\tspeed: 0.0866s/iter; left time: 789.7347s\n",
      "\titers: 500, epoch: 1 | loss: 1.3772590\n",
      "\tspeed: 0.0864s/iter; left time: 779.1872s\n",
      "\titers: 600, epoch: 1 | loss: 0.5923274\n",
      "\tspeed: 0.0862s/iter; left time: 769.4037s\n",
      "\titers: 700, epoch: 1 | loss: 1.0385302\n",
      "\tspeed: 0.1006s/iter; left time: 887.2770s\n",
      "\titers: 800, epoch: 1 | loss: 0.7321184\n",
      "\tspeed: 0.1257s/iter; left time: 1095.9876s\n",
      "\titers: 900, epoch: 1 | loss: 0.9088561\n",
      "\tspeed: 0.1442s/iter; left time: 1242.8528s\n",
      "Epoch: 1 cost time: 96.93550443649292\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.7759416 Vali Loss: 0.8775318 Test Loss: 1.2616996\n",
      "Validation loss decreased (inf --> 0.877532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7091193\n",
      "\tspeed: 2.5994s/iter; left time: 22014.6651s\n",
      "\titers: 200, epoch: 2 | loss: 0.5631580\n",
      "\tspeed: 0.1311s/iter; left time: 1097.4995s\n",
      "\titers: 300, epoch: 2 | loss: 0.7910326\n",
      "\tspeed: 0.1440s/iter; left time: 1190.3610s\n",
      "\titers: 400, epoch: 2 | loss: 0.7894663\n",
      "\tspeed: 0.1347s/iter; left time: 1100.0288s\n",
      "\titers: 500, epoch: 2 | loss: 0.7432073\n",
      "\tspeed: 0.1446s/iter; left time: 1167.0338s\n",
      "\titers: 600, epoch: 2 | loss: 0.5241051\n",
      "\tspeed: 0.1584s/iter; left time: 1262.5673s\n",
      "\titers: 700, epoch: 2 | loss: 0.8520340\n",
      "\tspeed: 0.1654s/iter; left time: 1301.1545s\n",
      "\titers: 800, epoch: 2 | loss: 0.7765261\n",
      "\tspeed: 0.1447s/iter; left time: 1124.0800s\n",
      "\titers: 900, epoch: 2 | loss: 0.4642495\n",
      "\tspeed: 0.1352s/iter; left time: 1037.1250s\n",
      "Epoch: 2 cost time: 139.13273167610168\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.6897750 Vali Loss: 0.9812528 Test Loss: 1.3048177\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6680884\n",
      "\tspeed: 2.0436s/iter; left time: 15361.3839s\n",
      "\titers: 200, epoch: 3 | loss: 0.6535168\n",
      "\tspeed: 0.1076s/iter; left time: 798.2440s\n",
      "\titers: 300, epoch: 3 | loss: 0.7407446\n",
      "\tspeed: 0.0871s/iter; left time: 637.3467s\n",
      "\titers: 400, epoch: 3 | loss: 0.5440657\n",
      "\tspeed: 0.0861s/iter; left time: 621.5061s\n",
      "\titers: 500, epoch: 3 | loss: 0.5942291\n",
      "\tspeed: 0.0907s/iter; left time: 645.8521s\n",
      "\titers: 600, epoch: 3 | loss: 0.5859637\n",
      "\tspeed: 0.0987s/iter; left time: 692.3152s\n",
      "\titers: 700, epoch: 3 | loss: 0.7604043\n",
      "\tspeed: 0.0992s/iter; left time: 686.0297s\n",
      "\titers: 800, epoch: 3 | loss: 0.5776753\n",
      "\tspeed: 0.0992s/iter; left time: 676.5391s\n",
      "\titers: 900, epoch: 3 | loss: 0.4801705\n",
      "\tspeed: 0.0988s/iter; left time: 663.3376s\n",
      "Epoch: 3 cost time: 91.89818930625916\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.6315432 Vali Loss: 0.9717851 Test Loss: 1.3049892\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5452120\n",
      "\tspeed: 1.5071s/iter; left time: 9894.1269s\n",
      "\titers: 200, epoch: 4 | loss: 0.5421452\n",
      "\tspeed: 0.0864s/iter; left time: 558.5910s\n",
      "\titers: 300, epoch: 4 | loss: 0.4497911\n",
      "\tspeed: 0.0854s/iter; left time: 543.6267s\n",
      "\titers: 400, epoch: 4 | loss: 0.6012692\n",
      "\tspeed: 0.0852s/iter; left time: 533.9499s\n",
      "\titers: 500, epoch: 4 | loss: 0.6027790\n",
      "\tspeed: 0.0850s/iter; left time: 524.1831s\n",
      "\titers: 600, epoch: 4 | loss: 0.5476236\n",
      "\tspeed: 0.0887s/iter; left time: 538.2043s\n",
      "\titers: 700, epoch: 4 | loss: 0.5977480\n",
      "\tspeed: 0.1052s/iter; left time: 627.4801s\n",
      "\titers: 800, epoch: 4 | loss: 0.7933677\n",
      "\tspeed: 0.0885s/iter; left time: 519.1418s\n",
      "\titers: 900, epoch: 4 | loss: 0.6781211\n",
      "\tspeed: 0.0869s/iter; left time: 500.8725s\n",
      "Epoch: 4 cost time: 85.20819616317749\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.5703190 Vali Loss: 1.0172863 Test Loss: 1.3269694\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 1) (8663, 1, 96, 1)\n",
      "test shape: (8663, 96, 1) (8663, 96, 1)\n",
      "mse:1.2613147497177124, mae:0.8368407487869263\n",
      "\n",
      "Extracted Part: long_term_forecast__96_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__96_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=1, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=1, factor=5, features='S', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='Informer', model_id='_192_DE_wind_generation_actual', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='DE_wind_generation_actual', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 1.0508147\n",
      "\tspeed: 0.1937s/iter; left time: 1819.1895s\n",
      "\titers: 200, epoch: 1 | loss: 1.0305539\n",
      "\tspeed: 0.2037s/iter; left time: 1892.2457s\n",
      "\titers: 300, epoch: 1 | loss: 0.8209612\n",
      "\tspeed: 0.1924s/iter; left time: 1768.6741s\n",
      "\titers: 400, epoch: 1 | loss: 0.7947590\n",
      "\tspeed: 0.1398s/iter; left time: 1271.2663s\n",
      "\titers: 500, epoch: 1 | loss: 0.8223672\n",
      "\tspeed: 0.1216s/iter; left time: 1093.5994s\n",
      "\titers: 600, epoch: 1 | loss: 0.7850008\n",
      "\tspeed: 0.1230s/iter; left time: 1093.7362s\n",
      "\titers: 700, epoch: 1 | loss: 0.7934039\n",
      "\tspeed: 0.1226s/iter; left time: 1077.6645s\n",
      "\titers: 800, epoch: 1 | loss: 0.7909865\n",
      "\tspeed: 0.1244s/iter; left time: 1081.4841s\n",
      "\titers: 900, epoch: 1 | loss: 0.9182602\n",
      "\tspeed: 0.1212s/iter; left time: 1041.2601s\n",
      "Epoch: 1 cost time: 140.30911493301392\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.8573602 Vali Loss: 1.1059597 Test Loss: 1.4772754\n",
      "Validation loss decreased (inf --> 1.105960).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9680007\n",
      "\tspeed: 1.9181s/iter; left time: 16192.6329s\n",
      "\titers: 200, epoch: 2 | loss: 0.7571619\n",
      "\tspeed: 0.1949s/iter; left time: 1626.0067s\n",
      "\titers: 300, epoch: 2 | loss: 0.7733989\n",
      "\tspeed: 0.1982s/iter; left time: 1633.8440s\n",
      "\titers: 400, epoch: 2 | loss: 0.6615418\n",
      "\tspeed: 0.1979s/iter; left time: 1611.5559s\n",
      "\titers: 500, epoch: 2 | loss: 0.8290841\n",
      "\tspeed: 0.1892s/iter; left time: 1521.3329s\n",
      "\titers: 600, epoch: 2 | loss: 0.8878521\n",
      "\tspeed: 0.1402s/iter; left time: 1113.5632s\n",
      "\titers: 700, epoch: 2 | loss: 0.7533436\n",
      "\tspeed: 0.1437s/iter; left time: 1127.1804s\n",
      "\titers: 800, epoch: 2 | loss: 0.8558709\n",
      "\tspeed: 0.1414s/iter; left time: 1094.5901s\n",
      "\titers: 900, epoch: 2 | loss: 0.6608174\n",
      "\tspeed: 0.1403s/iter; left time: 1071.8117s\n",
      "Epoch: 2 cost time: 159.33506035804749\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.7636674 Vali Loss: 1.0682793 Test Loss: 1.4656929\n",
      "Validation loss decreased (1.105960 --> 1.068279).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.7953112\n",
      "\tspeed: 3.0798s/iter; left time: 23076.6170s\n",
      "\titers: 200, epoch: 3 | loss: 0.7043127\n",
      "\tspeed: 0.1380s/iter; left time: 1020.3852s\n",
      "\titers: 300, epoch: 3 | loss: 0.6438127\n",
      "\tspeed: 0.1450s/iter; left time: 1057.5955s\n",
      "\titers: 400, epoch: 3 | loss: 0.6355046\n",
      "\tspeed: 0.1449s/iter; left time: 1042.5807s\n",
      "\titers: 500, epoch: 3 | loss: 1.0531399\n",
      "\tspeed: 0.1872s/iter; left time: 1327.6554s\n",
      "\titers: 600, epoch: 3 | loss: 0.7108998\n",
      "\tspeed: 0.1932s/iter; left time: 1350.9783s\n",
      "\titers: 700, epoch: 3 | loss: 0.6936641\n",
      "\tspeed: 0.2078s/iter; left time: 1432.4114s\n",
      "\titers: 800, epoch: 3 | loss: 0.7378897\n",
      "\tspeed: 0.2052s/iter; left time: 1394.0495s\n",
      "\titers: 900, epoch: 3 | loss: 0.6949693\n",
      "\tspeed: 0.1578s/iter; left time: 1056.0834s\n",
      "Epoch: 3 cost time: 159.26816964149475\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.6952819 Vali Loss: 1.1014808 Test Loss: 1.4983519\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.6907536\n",
      "\tspeed: 2.3869s/iter; left time: 15619.8674s\n",
      "\titers: 200, epoch: 4 | loss: 0.8944556\n",
      "\tspeed: 0.1190s/iter; left time: 767.0353s\n",
      "\titers: 300, epoch: 4 | loss: 0.5191684\n",
      "\tspeed: 0.1195s/iter; left time: 757.8133s\n",
      "\titers: 400, epoch: 4 | loss: 0.5895669\n",
      "\tspeed: 0.1883s/iter; left time: 1175.6303s\n",
      "\titers: 500, epoch: 4 | loss: 0.7630682\n",
      "\tspeed: 0.1780s/iter; left time: 1093.3347s\n",
      "\titers: 600, epoch: 4 | loss: 0.6257862\n",
      "\tspeed: 0.2029s/iter; left time: 1226.2750s\n",
      "\titers: 700, epoch: 4 | loss: 0.5053778\n",
      "\tspeed: 0.2044s/iter; left time: 1215.0244s\n",
      "\titers: 800, epoch: 4 | loss: 0.7452601\n",
      "\tspeed: 0.1400s/iter; left time: 818.3199s\n",
      "\titers: 900, epoch: 4 | loss: 0.6839814\n",
      "\tspeed: 0.1460s/iter; left time: 838.6932s\n",
      "Epoch: 4 cost time: 149.33364129066467\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.6269140 Vali Loss: 1.1579553 Test Loss: 1.5701483\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6042789\n",
      "\tspeed: 3.4124s/iter; left time: 19092.3806s\n",
      "\titers: 200, epoch: 5 | loss: 0.5382022\n",
      "\tspeed: 0.1399s/iter; left time: 768.8062s\n",
      "\titers: 300, epoch: 5 | loss: 0.4911638\n",
      "\tspeed: 0.1444s/iter; left time: 778.9414s\n",
      "\titers: 400, epoch: 5 | loss: 0.5921096\n",
      "\tspeed: 0.1418s/iter; left time: 750.7007s\n",
      "\titers: 500, epoch: 5 | loss: 0.7636571\n",
      "\tspeed: 0.1406s/iter; left time: 730.3079s\n",
      "\titers: 600, epoch: 5 | loss: 0.6133704\n",
      "\tspeed: 0.1397s/iter; left time: 711.5563s\n",
      "\titers: 700, epoch: 5 | loss: 0.6952666\n",
      "\tspeed: 0.1464s/iter; left time: 731.3009s\n",
      "\titers: 800, epoch: 5 | loss: 0.6000866\n",
      "\tspeed: 0.1340s/iter; left time: 656.1167s\n",
      "\titers: 900, epoch: 5 | loss: 0.5650258\n",
      "\tspeed: 0.1865s/iter; left time: 894.2604s\n",
      "Epoch: 5 cost time: 143.18394923210144\n",
      "Epoch: 5, Steps: 949 | Train Loss: 0.5789620 Vali Loss: 1.1941942 Test Loss: 1.6065124\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 1) (8567, 1, 192, 1)\n",
      "test shape: (8567, 192, 1) (8567, 192, 1)\n",
      "mse:1.4658856391906738, mae:0.8987047076225281\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.9578940\n",
      "\tspeed: 0.1265s/iter; left time: 1188.2414s\n",
      "\titers: 200, epoch: 1 | loss: 0.9515758\n",
      "\tspeed: 0.1073s/iter; left time: 997.2781s\n",
      "\titers: 300, epoch: 1 | loss: 0.8186919\n",
      "\tspeed: 0.1212s/iter; left time: 1113.8326s\n",
      "\titers: 400, epoch: 1 | loss: 1.0377171\n",
      "\tspeed: 0.1200s/iter; left time: 1090.8970s\n",
      "\titers: 500, epoch: 1 | loss: 0.6463565\n",
      "\tspeed: 0.1154s/iter; left time: 1037.1520s\n",
      "\titers: 600, epoch: 1 | loss: 0.7421216\n",
      "\tspeed: 0.1236s/iter; left time: 1098.8209s\n",
      "\titers: 700, epoch: 1 | loss: 0.7250158\n",
      "\tspeed: 0.1413s/iter; left time: 1242.2953s\n",
      "\titers: 800, epoch: 1 | loss: 0.7955941\n",
      "\tspeed: 0.1910s/iter; left time: 1660.3112s\n",
      "\titers: 900, epoch: 1 | loss: 0.7928143\n",
      "\tspeed: 0.1985s/iter; left time: 1705.0992s\n",
      "Epoch: 1 cost time: 135.08163785934448\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.8540136 Vali Loss: 1.1443655 Test Loss: 1.4960570\n",
      "Validation loss decreased (inf --> 1.144366).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9787437\n",
      "\tspeed: 3.2583s/iter; left time: 27506.9272s\n",
      "\titers: 200, epoch: 2 | loss: 0.6311604\n",
      "\tspeed: 0.1845s/iter; left time: 1538.7098s\n",
      "\titers: 300, epoch: 2 | loss: 0.6660070\n",
      "\tspeed: 0.1914s/iter; left time: 1577.8003s\n",
      "\titers: 400, epoch: 2 | loss: 1.1008627\n",
      "\tspeed: 0.1888s/iter; left time: 1537.5753s\n",
      "\titers: 500, epoch: 2 | loss: 0.7808213\n",
      "\tspeed: 0.1894s/iter; left time: 1523.4006s\n",
      "\titers: 600, epoch: 2 | loss: 0.5584326\n",
      "\tspeed: 0.1984s/iter; left time: 1575.8212s\n",
      "\titers: 700, epoch: 2 | loss: 0.7680799\n",
      "\tspeed: 0.2020s/iter; left time: 1584.3004s\n",
      "\titers: 800, epoch: 2 | loss: 0.7259725\n",
      "\tspeed: 0.1603s/iter; left time: 1241.2611s\n",
      "\titers: 900, epoch: 2 | loss: 0.8409052\n",
      "\tspeed: 0.1863s/iter; left time: 1423.9154s\n",
      "Epoch: 2 cost time: 176.54473519325256\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.7632873 Vali Loss: 1.0811225 Test Loss: 1.3683218\n",
      "Validation loss decreased (1.144366 --> 1.081123).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6478815\n",
      "\tspeed: 2.6527s/iter; left time: 19876.9283s\n",
      "\titers: 200, epoch: 3 | loss: 0.6015131\n",
      "\tspeed: 0.1694s/iter; left time: 1252.0768s\n",
      "\titers: 300, epoch: 3 | loss: 0.6434649\n",
      "\tspeed: 0.1866s/iter; left time: 1361.0915s\n",
      "\titers: 400, epoch: 3 | loss: 0.7279412\n",
      "\tspeed: 0.1872s/iter; left time: 1346.5587s\n",
      "\titers: 500, epoch: 3 | loss: 0.6966461\n",
      "\tspeed: 0.1713s/iter; left time: 1214.9970s\n",
      "\titers: 600, epoch: 3 | loss: 0.5696543\n",
      "\tspeed: 0.1396s/iter; left time: 976.3681s\n",
      "\titers: 700, epoch: 3 | loss: 0.6667780\n",
      "\tspeed: 0.1229s/iter; left time: 847.0471s\n",
      "\titers: 800, epoch: 3 | loss: 0.6594956\n",
      "\tspeed: 0.1230s/iter; left time: 835.5370s\n",
      "\titers: 900, epoch: 3 | loss: 0.6491444\n",
      "\tspeed: 0.1178s/iter; left time: 788.3179s\n",
      "Epoch: 3 cost time: 140.53032326698303\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.6960007 Vali Loss: 1.1533679 Test Loss: 1.4501135\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.7257190\n",
      "\tspeed: 2.8750s/iter; left time: 18813.8479s\n",
      "\titers: 200, epoch: 4 | loss: 0.5947288\n",
      "\tspeed: 0.2013s/iter; left time: 1296.9437s\n",
      "\titers: 300, epoch: 4 | loss: 0.6576075\n",
      "\tspeed: 0.2052s/iter; left time: 1301.6225s\n",
      "\titers: 400, epoch: 4 | loss: 0.5795388\n",
      "\tspeed: 0.1397s/iter; left time: 872.3423s\n",
      "\titers: 500, epoch: 4 | loss: 0.6631225\n",
      "\tspeed: 0.1372s/iter; left time: 842.7019s\n",
      "\titers: 600, epoch: 4 | loss: 0.8875684\n",
      "\tspeed: 0.1414s/iter; left time: 854.3680s\n",
      "\titers: 700, epoch: 4 | loss: 0.5723618\n",
      "\tspeed: 0.1389s/iter; left time: 825.8091s\n",
      "\titers: 800, epoch: 4 | loss: 0.7274537\n",
      "\tspeed: 0.1383s/iter; left time: 808.4957s\n",
      "\titers: 900, epoch: 4 | loss: 0.4633636\n",
      "\tspeed: 0.1395s/iter; left time: 801.2131s\n",
      "Epoch: 4 cost time: 150.43965029716492\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.6321477 Vali Loss: 1.2062523 Test Loss: 1.5404514\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6547750\n",
      "\tspeed: 2.0969s/iter; left time: 11732.3302s\n",
      "\titers: 200, epoch: 5 | loss: 0.6233870\n",
      "\tspeed: 0.2058s/iter; left time: 1131.0893s\n",
      "\titers: 300, epoch: 5 | loss: 0.6553636\n",
      "\tspeed: 0.1736s/iter; left time: 936.7233s\n",
      "\titers: 400, epoch: 5 | loss: 0.6800188\n",
      "\tspeed: 0.1922s/iter; left time: 1017.7516s\n",
      "\titers: 500, epoch: 5 | loss: 0.4960464\n",
      "\tspeed: 0.2039s/iter; left time: 1059.4567s\n",
      "\titers: 600, epoch: 5 | loss: 0.7286615\n",
      "\tspeed: 0.1449s/iter; left time: 738.3187s\n",
      "\titers: 700, epoch: 5 | loss: 0.5395927\n",
      "\tspeed: 0.1426s/iter; left time: 712.5310s\n",
      "\titers: 800, epoch: 5 | loss: 0.5995808\n",
      "\tspeed: 0.1482s/iter; left time: 725.6209s\n",
      "\titers: 900, epoch: 5 | loss: 0.5619575\n",
      "\tspeed: 0.1390s/iter; left time: 666.6201s\n",
      "Epoch: 5 cost time: 154.78967142105103\n",
      "Epoch: 5, Steps: 949 | Train Loss: 0.5879046 Vali Loss: 1.2025170 Test Loss: 1.5970477\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 1) (8567, 1, 192, 1)\n",
      "test shape: (8567, 192, 1) (8567, 192, 1)\n",
      "mse:1.368574857711792, mae:0.8822953104972839\n",
      "\n",
      "Extracted Part: long_term_forecast__192_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__192_DE_wind_generation_actual_Informer_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n"
     ]
    }
   ],
   "source": [
    "# List of columns and prediction lengths for the grid search\n",
    "columns = [\"DE_load_actual_entsoe_transparency\", \"DE_solar_generation_actual\", \"DE_wind_generation_actual\"]\n",
    "prediction_lengths = [\"24\", \"48\", \"96\", \"192\"]\n",
    "for column in columns:\n",
    "    for pred_len in prediction_lengths:\n",
    "        # Define the script arguments as a list\n",
    "        model_id = f\"_{pred_len}_{column}\"  # Create the model_id\n",
    "        script_arguments = [\n",
    "            \"--task_name\", \"long_term_forecast\",\n",
    "            \"--is_training\", \"1\",\n",
    "            \"--root_path\", \"../../../01_datasets/\",\n",
    "            \"--data_path\", \"df_most_important_columns.csv\",\n",
    "            \"--model_id\", model_id,\n",
    "            \"--model\", \"Informer\",\n",
    "            \"--data\", \"custom\",\n",
    "            \"--features\", \"S\",\n",
    "            \"--target\", str(column),\n",
    "            \"--seq_len\", \"96\",\n",
    "            \"--label_len\", \"48\",\n",
    "            \"--pred_len\", pred_len,\n",
    "            \"--e_layers\", \"2\",\n",
    "            \"--d_layers\", \"5\",\n",
    "            \"--factor\", \"5\",\n",
    "            \"--enc_in\", \"1\",\n",
    "            \"--dec_in\", \"1\",\n",
    "            \"--c_out\", \"1\",\n",
    "            \"--des\", \"Exp\",\n",
    "            \"--itr\", \"2\"\n",
    "        ]\n",
    "\n",
    "        script_output = run_and_capture_script_output(script_path, script_arguments)\n",
    "\n",
    "        print(\"Captured Output:\")\n",
    "        print(script_output)\n",
    "\n",
    "        # Extract and save the prints related to the settings variable\n",
    "        settings_prints = extract_settings_prints(script_output.splitlines())\n",
    "\n",
    "        matched_patterns = pattern_matching(settings_prints)\n",
    "\n",
    "        summarize_results(matched_patterns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350bf88e-c0bf-4b16-967c-8ce032e8852b",
   "metadata": {},
   "source": [
    "## 6. DLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2ea106d-153b-4302-bfa6-288b03a6b42a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=29, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_all_columns.csv', dec_in=29, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=29, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_24_df_all_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=24, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.5421631\n",
      "\tspeed: 0.0167s/iter; left time: 157.8049s\n",
      "\titers: 200, epoch: 1 | loss: 0.4520778\n",
      "\tspeed: 0.0064s/iter; left time: 59.6568s\n",
      "\titers: 300, epoch: 1 | loss: 0.3625733\n",
      "\tspeed: 0.0063s/iter; left time: 58.5066s\n",
      "\titers: 400, epoch: 1 | loss: 0.3819025\n",
      "\tspeed: 0.0081s/iter; left time: 74.4074s\n",
      "\titers: 500, epoch: 1 | loss: 0.4025869\n",
      "\tspeed: 0.0063s/iter; left time: 56.8843s\n",
      "\titers: 600, epoch: 1 | loss: 0.4568376\n",
      "\tspeed: 0.0063s/iter; left time: 56.5345s\n",
      "\titers: 700, epoch: 1 | loss: 0.3601250\n",
      "\tspeed: 0.0066s/iter; left time: 58.0166s\n",
      "\titers: 800, epoch: 1 | loss: 0.3735189\n",
      "\tspeed: 0.0062s/iter; left time: 54.3104s\n",
      "\titers: 900, epoch: 1 | loss: 0.3347552\n",
      "\tspeed: 0.0068s/iter; left time: 58.3498s\n",
      "Epoch: 1 cost time: 7.394834518432617\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.4141758 Vali Loss: 0.5068188 Test Loss: 0.7281235\n",
      "Validation loss decreased (inf --> 0.506819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3748479\n",
      "\tspeed: 0.2285s/iter; left time: 1939.5645s\n",
      "\titers: 200, epoch: 2 | loss: 0.2991004\n",
      "\tspeed: 0.0078s/iter; left time: 65.0402s\n",
      "\titers: 300, epoch: 2 | loss: 0.3515681\n",
      "\tspeed: 0.0058s/iter; left time: 47.7596s\n",
      "\titers: 400, epoch: 2 | loss: 0.3319286\n",
      "\tspeed: 0.0061s/iter; left time: 50.0694s\n",
      "\titers: 500, epoch: 2 | loss: 0.3880650\n",
      "\tspeed: 0.0055s/iter; left time: 44.3941s\n",
      "\titers: 600, epoch: 2 | loss: 0.4190436\n",
      "\tspeed: 0.0066s/iter; left time: 52.6514s\n",
      "\titers: 700, epoch: 2 | loss: 0.3848827\n",
      "\tspeed: 0.0064s/iter; left time: 50.1215s\n",
      "\titers: 800, epoch: 2 | loss: 0.2710210\n",
      "\tspeed: 0.0070s/iter; left time: 54.2049s\n",
      "\titers: 900, epoch: 2 | loss: 0.3382883\n",
      "\tspeed: 0.0089s/iter; left time: 68.5158s\n",
      "Epoch: 2 cost time: 6.818856239318848\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.3361082 Vali Loss: 0.4799070 Test Loss: 0.6934749\n",
      "Validation loss decreased (0.506819 --> 0.479907).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3802623\n",
      "\tspeed: 0.2391s/iter; left time: 1801.4932s\n",
      "\titers: 200, epoch: 3 | loss: 0.3235737\n",
      "\tspeed: 0.0106s/iter; left time: 78.5822s\n",
      "\titers: 300, epoch: 3 | loss: 0.3002176\n",
      "\tspeed: 0.0111s/iter; left time: 81.5644s\n",
      "\titers: 400, epoch: 3 | loss: 0.3792438\n",
      "\tspeed: 0.0091s/iter; left time: 65.5536s\n",
      "\titers: 500, epoch: 3 | loss: 0.3471519\n",
      "\tspeed: 0.0106s/iter; left time: 75.3638s\n",
      "\titers: 600, epoch: 3 | loss: 0.3504935\n",
      "\tspeed: 0.0116s/iter; left time: 81.4819s\n",
      "\titers: 700, epoch: 3 | loss: 0.3596065\n",
      "\tspeed: 0.0094s/iter; left time: 64.8614s\n",
      "\titers: 800, epoch: 3 | loss: 0.2812025\n",
      "\tspeed: 0.0109s/iter; left time: 74.2621s\n",
      "\titers: 900, epoch: 3 | loss: 0.2980841\n",
      "\tspeed: 0.0113s/iter; left time: 76.1159s\n",
      "Epoch: 3 cost time: 10.395143032073975\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.3254245 Vali Loss: 0.4703546 Test Loss: 0.6786611\n",
      "Validation loss decreased (0.479907 --> 0.470355).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3625722\n",
      "\tspeed: 0.3237s/iter; left time: 2129.4444s\n",
      "\titers: 200, epoch: 4 | loss: 0.2784903\n",
      "\tspeed: 0.0139s/iter; left time: 90.0417s\n",
      "\titers: 300, epoch: 4 | loss: 0.3018099\n",
      "\tspeed: 0.0093s/iter; left time: 59.1843s\n",
      "\titers: 400, epoch: 4 | loss: 0.2761784\n",
      "\tspeed: 0.0114s/iter; left time: 71.6158s\n",
      "\titers: 500, epoch: 4 | loss: 0.2834699\n",
      "\tspeed: 0.0140s/iter; left time: 86.2342s\n",
      "\titers: 600, epoch: 4 | loss: 0.3210257\n",
      "\tspeed: 0.0146s/iter; left time: 88.5416s\n",
      "\titers: 700, epoch: 4 | loss: 0.3560238\n",
      "\tspeed: 0.0146s/iter; left time: 87.0300s\n",
      "\titers: 800, epoch: 4 | loss: 0.3469231\n",
      "\tspeed: 0.0133s/iter; left time: 78.2878s\n",
      "\titers: 900, epoch: 4 | loss: 0.3355588\n",
      "\tspeed: 0.0129s/iter; left time: 74.7024s\n",
      "Epoch: 4 cost time: 13.138086795806885\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.3225704 Vali Loss: 0.4660676 Test Loss: 0.6698217\n",
      "Validation loss decreased (0.470355 --> 0.466068).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3437563\n",
      "\tspeed: 0.2739s/iter; left time: 1540.9243s\n",
      "\titers: 200, epoch: 5 | loss: 0.2679048\n",
      "\tspeed: 0.0107s/iter; left time: 59.0373s\n",
      "\titers: 300, epoch: 5 | loss: 0.2836208\n",
      "\tspeed: 0.0101s/iter; left time: 54.9894s\n",
      "\titers: 400, epoch: 5 | loss: 0.2461845\n",
      "\tspeed: 0.0134s/iter; left time: 71.3481s\n",
      "\titers: 500, epoch: 5 | loss: 0.3092716\n",
      "\tspeed: 0.0109s/iter; left time: 57.0273s\n",
      "\titers: 600, epoch: 5 | loss: 0.3683695\n",
      "\tspeed: 0.0102s/iter; left time: 52.0727s\n",
      "\titers: 700, epoch: 5 | loss: 0.3348386\n",
      "\tspeed: 0.0103s/iter; left time: 51.6943s\n",
      "\titers: 800, epoch: 5 | loss: 0.3147963\n",
      "\tspeed: 0.0135s/iter; left time: 66.5092s\n",
      "\titers: 900, epoch: 5 | loss: 0.4320584\n",
      "\tspeed: 0.0091s/iter; left time: 44.0123s\n",
      "Epoch: 5 cost time: 10.813664197921753\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.3215084 Vali Loss: 0.4645353 Test Loss: 0.6692734\n",
      "Validation loss decreased (0.466068 --> 0.464535).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3509212\n",
      "\tspeed: 0.2673s/iter; left time: 1248.6218s\n",
      "\titers: 200, epoch: 6 | loss: 0.3003101\n",
      "\tspeed: 0.0181s/iter; left time: 82.9485s\n",
      "\titers: 300, epoch: 6 | loss: 0.3400850\n",
      "\tspeed: 0.0078s/iter; left time: 34.9387s\n",
      "\titers: 400, epoch: 6 | loss: 0.2624064\n",
      "\tspeed: 0.0069s/iter; left time: 30.2878s\n",
      "\titers: 500, epoch: 6 | loss: 0.2839436\n",
      "\tspeed: 0.0071s/iter; left time: 30.4055s\n",
      "\titers: 600, epoch: 6 | loss: 0.3411654\n",
      "\tspeed: 0.0071s/iter; left time: 29.5917s\n",
      "\titers: 700, epoch: 6 | loss: 0.3570345\n",
      "\tspeed: 0.0078s/iter; left time: 31.5636s\n",
      "\titers: 800, epoch: 6 | loss: 0.3311916\n",
      "\tspeed: 0.0081s/iter; left time: 32.2459s\n",
      "\titers: 900, epoch: 6 | loss: 0.2912089\n",
      "\tspeed: 0.0082s/iter; left time: 31.6436s\n",
      "Epoch: 6 cost time: 9.218327522277832\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.3210007 Vali Loss: 0.4668085 Test Loss: 0.6729031\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4424106\n",
      "\tspeed: 0.2092s/iter; left time: 777.5745s\n",
      "\titers: 200, epoch: 7 | loss: 0.2442357\n",
      "\tspeed: 0.0087s/iter; left time: 31.4221s\n",
      "\titers: 300, epoch: 7 | loss: 0.2976051\n",
      "\tspeed: 0.0072s/iter; left time: 25.3167s\n",
      "\titers: 400, epoch: 7 | loss: 0.2815739\n",
      "\tspeed: 0.0064s/iter; left time: 21.7063s\n",
      "\titers: 500, epoch: 7 | loss: 0.2835294\n",
      "\tspeed: 0.0096s/iter; left time: 31.9914s\n",
      "\titers: 600, epoch: 7 | loss: 0.2941781\n",
      "\tspeed: 0.0151s/iter; left time: 48.7146s\n",
      "\titers: 700, epoch: 7 | loss: 0.2874697\n",
      "\tspeed: 0.0157s/iter; left time: 49.0621s\n",
      "\titers: 800, epoch: 7 | loss: 0.2849416\n",
      "\tspeed: 0.0184s/iter; left time: 55.3987s\n",
      "\titers: 900, epoch: 7 | loss: 0.2883394\n",
      "\tspeed: 0.0163s/iter; left time: 47.5246s\n",
      "Epoch: 7 cost time: 11.716209650039673\n",
      "Epoch: 7, Steps: 954 | Train Loss: 0.3207470 Vali Loss: 0.4659464 Test Loss: 0.6720403\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2744377\n",
      "\tspeed: 0.2451s/iter; left time: 677.1970s\n",
      "\titers: 200, epoch: 8 | loss: 0.3714235\n",
      "\tspeed: 0.0119s/iter; left time: 31.8073s\n",
      "\titers: 300, epoch: 8 | loss: 0.3159831\n",
      "\tspeed: 0.0179s/iter; left time: 45.7597s\n",
      "\titers: 400, epoch: 8 | loss: 0.3155674\n",
      "\tspeed: 0.0138s/iter; left time: 33.9122s\n",
      "\titers: 500, epoch: 8 | loss: 0.2554454\n",
      "\tspeed: 0.0083s/iter; left time: 19.5608s\n",
      "\titers: 600, epoch: 8 | loss: 0.3430921\n",
      "\tspeed: 0.0054s/iter; left time: 12.2870s\n",
      "\titers: 700, epoch: 8 | loss: 0.3166977\n",
      "\tspeed: 0.0081s/iter; left time: 17.5816s\n",
      "\titers: 800, epoch: 8 | loss: 0.2936083\n",
      "\tspeed: 0.0099s/iter; left time: 20.4265s\n",
      "\titers: 900, epoch: 8 | loss: 0.3394349\n",
      "\tspeed: 0.0089s/iter; left time: 17.4655s\n",
      "Epoch: 8 cost time: 10.62855577468872\n",
      "Epoch: 8, Steps: 954 | Train Loss: 0.3206548 Vali Loss: 0.4657460 Test Loss: 0.6714311\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 29) (8735, 1, 24, 29)\n",
      "test shape: (8735, 24, 29) (8735, 24, 29)\n",
      "mse:0.6692736148834229, mae:0.5501456260681152\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.5773740\n",
      "\tspeed: 0.0158s/iter; left time: 149.4120s\n",
      "\titers: 200, epoch: 1 | loss: 0.4490194\n",
      "\tspeed: 0.0119s/iter; left time: 111.2531s\n",
      "\titers: 300, epoch: 1 | loss: 0.5002804\n",
      "\tspeed: 0.0114s/iter; left time: 105.7899s\n",
      "\titers: 400, epoch: 1 | loss: 0.4374205\n",
      "\tspeed: 0.0129s/iter; left time: 117.9352s\n",
      "\titers: 500, epoch: 1 | loss: 0.3431564\n",
      "\tspeed: 0.0118s/iter; left time: 106.5721s\n",
      "\titers: 600, epoch: 1 | loss: 0.4093103\n",
      "\tspeed: 0.0133s/iter; left time: 118.8669s\n",
      "\titers: 700, epoch: 1 | loss: 0.3625019\n",
      "\tspeed: 0.0122s/iter; left time: 107.7270s\n",
      "\titers: 800, epoch: 1 | loss: 0.4043191\n",
      "\tspeed: 0.0158s/iter; left time: 138.1158s\n",
      "\titers: 900, epoch: 1 | loss: 0.3566909\n",
      "\tspeed: 0.0134s/iter; left time: 116.0948s\n",
      "Epoch: 1 cost time: 12.775843858718872\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.4122241 Vali Loss: 0.5062371 Test Loss: 0.7261165\n",
      "Validation loss decreased (inf --> 0.506237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2679296\n",
      "\tspeed: 0.3236s/iter; left time: 2746.3791s\n",
      "\titers: 200, epoch: 2 | loss: 0.3521173\n",
      "\tspeed: 0.0217s/iter; left time: 182.3029s\n",
      "\titers: 300, epoch: 2 | loss: 0.4037635\n",
      "\tspeed: 0.0231s/iter; left time: 191.6364s\n",
      "\titers: 400, epoch: 2 | loss: 0.2829464\n",
      "\tspeed: 0.0171s/iter; left time: 140.3024s\n",
      "\titers: 500, epoch: 2 | loss: 0.2950730\n",
      "\tspeed: 0.0230s/iter; left time: 185.9424s\n",
      "\titers: 600, epoch: 2 | loss: 0.3309591\n",
      "\tspeed: 0.0173s/iter; left time: 137.8078s\n",
      "\titers: 700, epoch: 2 | loss: 0.3276134\n",
      "\tspeed: 0.0155s/iter; left time: 122.4897s\n",
      "\titers: 800, epoch: 2 | loss: 0.3422542\n",
      "\tspeed: 0.0134s/iter; left time: 104.3660s\n",
      "\titers: 900, epoch: 2 | loss: 0.2943245\n",
      "\tspeed: 0.0157s/iter; left time: 120.6040s\n",
      "Epoch: 2 cost time: 18.079367876052856\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.3358987 Vali Loss: 0.4746832 Test Loss: 0.6828604\n",
      "Validation loss decreased (0.506237 --> 0.474683).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3370696\n",
      "\tspeed: 0.3202s/iter; left time: 2411.8327s\n",
      "\titers: 200, epoch: 3 | loss: 0.3456594\n",
      "\tspeed: 0.0107s/iter; left time: 79.7516s\n",
      "\titers: 300, epoch: 3 | loss: 0.3685032\n",
      "\tspeed: 0.0106s/iter; left time: 77.6402s\n",
      "\titers: 400, epoch: 3 | loss: 0.3169399\n",
      "\tspeed: 0.0124s/iter; left time: 89.8644s\n",
      "\titers: 500, epoch: 3 | loss: 0.3364578\n",
      "\tspeed: 0.0124s/iter; left time: 88.5758s\n",
      "\titers: 600, epoch: 3 | loss: 0.2785912\n",
      "\tspeed: 0.0133s/iter; left time: 93.6259s\n",
      "\titers: 700, epoch: 3 | loss: 0.3672883\n",
      "\tspeed: 0.0139s/iter; left time: 96.3896s\n",
      "\titers: 800, epoch: 3 | loss: 0.2777706\n",
      "\tspeed: 0.0120s/iter; left time: 81.7359s\n",
      "\titers: 900, epoch: 3 | loss: 0.3295929\n",
      "\tspeed: 0.0122s/iter; left time: 82.4012s\n",
      "Epoch: 3 cost time: 12.026380062103271\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.3254069 Vali Loss: 0.4661159 Test Loss: 0.6680897\n",
      "Validation loss decreased (0.474683 --> 0.466116).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3473035\n",
      "\tspeed: 0.2655s/iter; left time: 1746.7777s\n",
      "\titers: 200, epoch: 4 | loss: 0.3741408\n",
      "\tspeed: 0.0120s/iter; left time: 77.4245s\n",
      "\titers: 300, epoch: 4 | loss: 0.3034441\n",
      "\tspeed: 0.0133s/iter; left time: 85.0632s\n",
      "\titers: 400, epoch: 4 | loss: 0.2813929\n",
      "\tspeed: 0.0088s/iter; left time: 54.9944s\n",
      "\titers: 500, epoch: 4 | loss: 0.2454191\n",
      "\tspeed: 0.0095s/iter; left time: 58.5791s\n",
      "\titers: 600, epoch: 4 | loss: 0.3278161\n",
      "\tspeed: 0.0093s/iter; left time: 56.4649s\n",
      "\titers: 700, epoch: 4 | loss: 0.3724749\n",
      "\tspeed: 0.0086s/iter; left time: 51.1745s\n",
      "\titers: 800, epoch: 4 | loss: 0.2957323\n",
      "\tspeed: 0.0087s/iter; left time: 51.1574s\n",
      "\titers: 900, epoch: 4 | loss: 0.3303140\n",
      "\tspeed: 0.0099s/iter; left time: 57.1011s\n",
      "Epoch: 4 cost time: 10.213894128799438\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.3225363 Vali Loss: 0.4669138 Test Loss: 0.6735995\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2918230\n",
      "\tspeed: 0.2409s/iter; left time: 1355.1207s\n",
      "\titers: 200, epoch: 5 | loss: 0.3292795\n",
      "\tspeed: 0.0136s/iter; left time: 74.9423s\n",
      "\titers: 300, epoch: 5 | loss: 0.2997526\n",
      "\tspeed: 0.0114s/iter; left time: 61.9512s\n",
      "\titers: 400, epoch: 5 | loss: 0.3714638\n",
      "\tspeed: 0.0129s/iter; left time: 68.6067s\n",
      "\titers: 500, epoch: 5 | loss: 0.2840622\n",
      "\tspeed: 0.0159s/iter; left time: 83.3377s\n",
      "\titers: 600, epoch: 5 | loss: 0.4598394\n",
      "\tspeed: 0.0094s/iter; left time: 48.0079s\n",
      "\titers: 700, epoch: 5 | loss: 0.3425991\n",
      "\tspeed: 0.0077s/iter; left time: 38.8479s\n",
      "\titers: 800, epoch: 5 | loss: 0.3212500\n",
      "\tspeed: 0.0095s/iter; left time: 46.5437s\n",
      "\titers: 900, epoch: 5 | loss: 0.4561026\n",
      "\tspeed: 0.0112s/iter; left time: 54.2288s\n",
      "Epoch: 5 cost time: 11.45793867111206\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.3214346 Vali Loss: 0.4688626 Test Loss: 0.6776734\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3984587\n",
      "\tspeed: 0.2724s/iter; left time: 1272.1804s\n",
      "\titers: 200, epoch: 6 | loss: 0.3391969\n",
      "\tspeed: 0.0100s/iter; left time: 45.8918s\n",
      "\titers: 300, epoch: 6 | loss: 0.3917398\n",
      "\tspeed: 0.0144s/iter; left time: 64.2722s\n",
      "\titers: 400, epoch: 6 | loss: 0.2558066\n",
      "\tspeed: 0.0167s/iter; left time: 73.1827s\n",
      "\titers: 500, epoch: 6 | loss: 0.3119452\n",
      "\tspeed: 0.0118s/iter; left time: 50.2140s\n",
      "\titers: 600, epoch: 6 | loss: 0.3179979\n",
      "\tspeed: 0.0088s/iter; left time: 36.8916s\n",
      "\titers: 700, epoch: 6 | loss: 0.3257717\n",
      "\tspeed: 0.0151s/iter; left time: 61.4959s\n",
      "\titers: 800, epoch: 6 | loss: 0.2847517\n",
      "\tspeed: 0.0119s/iter; left time: 47.3631s\n",
      "\titers: 900, epoch: 6 | loss: 0.3697807\n",
      "\tspeed: 0.0133s/iter; left time: 51.6713s\n",
      "Epoch: 6 cost time: 12.698856830596924\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.3209216 Vali Loss: 0.4653527 Test Loss: 0.6703548\n",
      "Validation loss decreased (0.466116 --> 0.465353).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4474272\n",
      "\tspeed: 0.3432s/iter; left time: 1275.8309s\n",
      "\titers: 200, epoch: 7 | loss: 0.2845558\n",
      "\tspeed: 0.0147s/iter; left time: 53.1567s\n",
      "\titers: 300, epoch: 7 | loss: 0.3221335\n",
      "\tspeed: 0.0204s/iter; left time: 71.7366s\n",
      "\titers: 400, epoch: 7 | loss: 0.2959565\n",
      "\tspeed: 0.0180s/iter; left time: 61.4646s\n",
      "\titers: 500, epoch: 7 | loss: 0.3416485\n",
      "\tspeed: 0.0107s/iter; left time: 35.4696s\n",
      "\titers: 600, epoch: 7 | loss: 0.3369100\n",
      "\tspeed: 0.0136s/iter; left time: 43.8518s\n",
      "\titers: 700, epoch: 7 | loss: 0.4082767\n",
      "\tspeed: 0.0114s/iter; left time: 35.5152s\n",
      "\titers: 800, epoch: 7 | loss: 0.3732599\n",
      "\tspeed: 0.0143s/iter; left time: 43.1868s\n",
      "\titers: 900, epoch: 7 | loss: 0.3563049\n",
      "\tspeed: 0.0123s/iter; left time: 35.9794s\n",
      "Epoch: 7 cost time: 14.492751836776733\n",
      "Epoch: 7, Steps: 954 | Train Loss: 0.3206803 Vali Loss: 0.4649031 Test Loss: 0.6699410\n",
      "Validation loss decreased (0.465353 --> 0.464903).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3654885\n",
      "\tspeed: 0.3016s/iter; left time: 833.2589s\n",
      "\titers: 200, epoch: 8 | loss: 0.3395914\n",
      "\tspeed: 0.0141s/iter; left time: 37.5614s\n",
      "\titers: 300, epoch: 8 | loss: 0.3200466\n",
      "\tspeed: 0.0095s/iter; left time: 24.2527s\n",
      "\titers: 400, epoch: 8 | loss: 0.2984875\n",
      "\tspeed: 0.0123s/iter; left time: 30.3018s\n",
      "\titers: 500, epoch: 8 | loss: 0.2908190\n",
      "\tspeed: 0.0104s/iter; left time: 24.5806s\n",
      "\titers: 600, epoch: 8 | loss: 0.3719956\n",
      "\tspeed: 0.0120s/iter; left time: 27.1996s\n",
      "\titers: 700, epoch: 8 | loss: 0.2824999\n",
      "\tspeed: 0.0149s/iter; left time: 32.3361s\n",
      "\titers: 800, epoch: 8 | loss: 0.3484518\n",
      "\tspeed: 0.0093s/iter; left time: 19.2108s\n",
      "\titers: 900, epoch: 8 | loss: 0.2861110\n",
      "\tspeed: 0.0132s/iter; left time: 25.8498s\n",
      "Epoch: 8 cost time: 12.221676349639893\n",
      "Epoch: 8, Steps: 954 | Train Loss: 0.3205709 Vali Loss: 0.4652357 Test Loss: 0.6702151\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2773571\n",
      "\tspeed: 0.2779s/iter; left time: 502.7675s\n",
      "\titers: 200, epoch: 9 | loss: 0.3221130\n",
      "\tspeed: 0.0134s/iter; left time: 22.8386s\n",
      "\titers: 300, epoch: 9 | loss: 0.2383395\n",
      "\tspeed: 0.0080s/iter; left time: 12.9323s\n",
      "\titers: 400, epoch: 9 | loss: 0.3565283\n",
      "\tspeed: 0.0112s/iter; left time: 16.8722s\n",
      "\titers: 500, epoch: 9 | loss: 0.3218915\n",
      "\tspeed: 0.0099s/iter; left time: 13.9273s\n",
      "\titers: 600, epoch: 9 | loss: 0.3284203\n",
      "\tspeed: 0.0113s/iter; left time: 14.7676s\n",
      "\titers: 700, epoch: 9 | loss: 0.2614634\n",
      "\tspeed: 0.0118s/iter; left time: 14.2365s\n",
      "\titers: 800, epoch: 9 | loss: 0.3076674\n",
      "\tspeed: 0.0104s/iter; left time: 11.5685s\n",
      "\titers: 900, epoch: 9 | loss: 0.3765902\n",
      "\tspeed: 0.0089s/iter; left time: 9.0295s\n",
      "Epoch: 9 cost time: 11.144419193267822\n",
      "Epoch: 9, Steps: 954 | Train Loss: 0.3204983 Vali Loss: 0.4651110 Test Loss: 0.6705350\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2804342\n",
      "\tspeed: 0.2767s/iter; left time: 236.5603s\n",
      "\titers: 200, epoch: 10 | loss: 0.3389263\n",
      "\tspeed: 0.0215s/iter; left time: 16.2156s\n",
      "\titers: 300, epoch: 10 | loss: 0.4267631\n",
      "\tspeed: 0.0226s/iter; left time: 14.8166s\n",
      "\titers: 400, epoch: 10 | loss: 0.2557402\n",
      "\tspeed: 0.0178s/iter; left time: 9.8795s\n",
      "\titers: 500, epoch: 10 | loss: 0.2615328\n",
      "\tspeed: 0.0259s/iter; left time: 11.7641s\n",
      "\titers: 600, epoch: 10 | loss: 0.3424541\n",
      "\tspeed: 0.0225s/iter; left time: 7.9848s\n",
      "\titers: 700, epoch: 10 | loss: 0.3117596\n",
      "\tspeed: 0.0188s/iter; left time: 4.7930s\n",
      "\titers: 800, epoch: 10 | loss: 0.2491298\n",
      "\tspeed: 0.0189s/iter; left time: 2.9287s\n",
      "\titers: 900, epoch: 10 | loss: 0.3105919\n",
      "\tspeed: 0.0280s/iter; left time: 1.5378s\n",
      "Epoch: 10 cost time: 21.037919759750366\n",
      "Epoch: 10, Steps: 954 | Train Loss: 0.3204802 Vali Loss: 0.4650140 Test Loss: 0.6706307\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 29) (8735, 1, 24, 29)\n",
      "test shape: (8735, 24, 29) (8735, 24, 29)\n",
      "mse:0.6699410676956177, mae:0.5495629906654358\n",
      "\n",
      "Extracted Part: long_term_forecast__24_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__24_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=29, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_all_columns.csv', dec_in=29, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=29, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_48_df_all_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=48, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.6430352\n",
      "\tspeed: 0.0193s/iter; left time: 182.2366s\n",
      "\titers: 200, epoch: 1 | loss: 0.5368741\n",
      "\tspeed: 0.0133s/iter; left time: 123.7546s\n",
      "\titers: 300, epoch: 1 | loss: 0.5477026\n",
      "\tspeed: 0.0120s/iter; left time: 110.9263s\n",
      "\titers: 400, epoch: 1 | loss: 0.4691350\n",
      "\tspeed: 0.0104s/iter; left time: 95.0480s\n",
      "\titers: 500, epoch: 1 | loss: 0.4035235\n",
      "\tspeed: 0.0133s/iter; left time: 120.1150s\n",
      "\titers: 600, epoch: 1 | loss: 0.4899686\n",
      "\tspeed: 0.0134s/iter; left time: 119.5414s\n",
      "\titers: 700, epoch: 1 | loss: 0.4419934\n",
      "\tspeed: 0.0120s/iter; left time: 105.8281s\n",
      "\titers: 800, epoch: 1 | loss: 0.3995644\n",
      "\tspeed: 0.0152s/iter; left time: 132.6382s\n",
      "\titers: 900, epoch: 1 | loss: 0.4078711\n",
      "\tspeed: 0.0142s/iter; left time: 122.6327s\n",
      "Epoch: 1 cost time: 12.972403526306152\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.5040992 Vali Loss: 0.6584525 Test Loss: 0.9480980\n",
      "Validation loss decreased (inf --> 0.658452).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4885999\n",
      "\tspeed: 0.2529s/iter; left time: 2143.8926s\n",
      "\titers: 200, epoch: 2 | loss: 0.4077531\n",
      "\tspeed: 0.0125s/iter; left time: 104.4717s\n",
      "\titers: 300, epoch: 2 | loss: 0.3383836\n",
      "\tspeed: 0.0226s/iter; left time: 187.0977s\n",
      "\titers: 400, epoch: 2 | loss: 0.4747927\n",
      "\tspeed: 0.0262s/iter; left time: 214.2801s\n",
      "\titers: 500, epoch: 2 | loss: 0.4919825\n",
      "\tspeed: 0.0227s/iter; left time: 183.6445s\n",
      "\titers: 600, epoch: 2 | loss: 0.3726679\n",
      "\tspeed: 0.0172s/iter; left time: 136.9894s\n",
      "\titers: 700, epoch: 2 | loss: 0.4181012\n",
      "\tspeed: 0.0192s/iter; left time: 151.4424s\n",
      "\titers: 800, epoch: 2 | loss: 0.4309824\n",
      "\tspeed: 0.0311s/iter; left time: 241.7890s\n",
      "\titers: 900, epoch: 2 | loss: 0.4525957\n",
      "\tspeed: 0.0284s/iter; left time: 217.7101s\n",
      "Epoch: 2 cost time: 20.766038417816162\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.4462952 Vali Loss: 0.6368040 Test Loss: 0.9159565\n",
      "Validation loss decreased (0.658452 --> 0.636804).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4903690\n",
      "\tspeed: 0.3597s/iter; left time: 2706.6401s\n",
      "\titers: 200, epoch: 3 | loss: 0.3808117\n",
      "\tspeed: 0.0271s/iter; left time: 201.0033s\n",
      "\titers: 300, epoch: 3 | loss: 0.3986650\n",
      "\tspeed: 0.0208s/iter; left time: 152.0194s\n",
      "\titers: 400, epoch: 3 | loss: 0.4891813\n",
      "\tspeed: 0.0223s/iter; left time: 161.3687s\n",
      "\titers: 500, epoch: 3 | loss: 0.4419177\n",
      "\tspeed: 0.0206s/iter; left time: 146.9083s\n",
      "\titers: 600, epoch: 3 | loss: 0.4142224\n",
      "\tspeed: 0.0207s/iter; left time: 145.0979s\n",
      "\titers: 700, epoch: 3 | loss: 0.4434655\n",
      "\tspeed: 0.0108s/iter; left time: 74.6495s\n",
      "\titers: 800, epoch: 3 | loss: 0.3632301\n",
      "\tspeed: 0.0240s/iter; left time: 163.9414s\n",
      "\titers: 900, epoch: 3 | loss: 0.4365088\n",
      "\tspeed: 0.0087s/iter; left time: 58.7521s\n",
      "Epoch: 3 cost time: 19.37137007713318\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.4395275 Vali Loss: 0.6408319 Test Loss: 0.9271324\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4371752\n",
      "\tspeed: 0.3549s/iter; left time: 2332.4407s\n",
      "\titers: 200, epoch: 4 | loss: 0.3770969\n",
      "\tspeed: 0.0245s/iter; left time: 158.8287s\n",
      "\titers: 300, epoch: 4 | loss: 0.3827460\n",
      "\tspeed: 0.0191s/iter; left time: 121.9111s\n",
      "\titers: 400, epoch: 4 | loss: 0.4013865\n",
      "\tspeed: 0.0229s/iter; left time: 143.5646s\n",
      "\titers: 500, epoch: 4 | loss: 0.5120748\n",
      "\tspeed: 0.0170s/iter; left time: 104.7710s\n",
      "\titers: 600, epoch: 4 | loss: 0.4256176\n",
      "\tspeed: 0.0307s/iter; left time: 186.4045s\n",
      "\titers: 700, epoch: 4 | loss: 0.4091959\n",
      "\tspeed: 0.0080s/iter; left time: 47.7717s\n",
      "\titers: 800, epoch: 4 | loss: 0.4183429\n",
      "\tspeed: 0.0196s/iter; left time: 115.3714s\n",
      "\titers: 900, epoch: 4 | loss: 0.4268900\n",
      "\tspeed: 0.0302s/iter; left time: 174.2495s\n",
      "Epoch: 4 cost time: 21.05081534385681\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.4375762 Vali Loss: 0.6351122 Test Loss: 0.9175265\n",
      "Validation loss decreased (0.636804 --> 0.635112).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3859166\n",
      "\tspeed: 0.3689s/iter; left time: 2072.6285s\n",
      "\titers: 200, epoch: 5 | loss: 0.4285497\n",
      "\tspeed: 0.0156s/iter; left time: 85.8456s\n",
      "\titers: 300, epoch: 5 | loss: 0.5107666\n",
      "\tspeed: 0.0247s/iter; left time: 134.1040s\n",
      "\titers: 400, epoch: 5 | loss: 0.4575418\n",
      "\tspeed: 0.0204s/iter; left time: 108.3277s\n",
      "\titers: 500, epoch: 5 | loss: 0.3300714\n",
      "\tspeed: 0.0158s/iter; left time: 82.5304s\n",
      "\titers: 600, epoch: 5 | loss: 0.4533824\n",
      "\tspeed: 0.0040s/iter; left time: 20.4055s\n",
      "\titers: 700, epoch: 5 | loss: 0.4460967\n",
      "\tspeed: 0.0339s/iter; left time: 170.3910s\n",
      "\titers: 800, epoch: 5 | loss: 0.4122525\n",
      "\tspeed: 0.0032s/iter; left time: 15.9623s\n",
      "\titers: 900, epoch: 5 | loss: 0.4821319\n",
      "\tspeed: 0.0210s/iter; left time: 100.9712s\n",
      "Epoch: 5 cost time: 16.572245597839355\n",
      "Epoch: 5, Steps: 953 | Train Loss: 0.4368616 Vali Loss: 0.6313244 Test Loss: 0.9099304\n",
      "Validation loss decreased (0.635112 --> 0.631324).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3655619\n",
      "\tspeed: 0.2984s/iter; left time: 1392.5262s\n",
      "\titers: 200, epoch: 6 | loss: 0.4206948\n",
      "\tspeed: 0.0248s/iter; left time: 113.3798s\n",
      "\titers: 300, epoch: 6 | loss: 0.3762677\n",
      "\tspeed: 0.0263s/iter; left time: 117.5464s\n",
      "\titers: 400, epoch: 6 | loss: 0.5003132\n",
      "\tspeed: 0.0204s/iter; left time: 88.9951s\n",
      "\titers: 500, epoch: 6 | loss: 0.3820066\n",
      "\tspeed: 0.0058s/iter; left time: 24.9407s\n",
      "\titers: 600, epoch: 6 | loss: 0.4269322\n",
      "\tspeed: 0.0251s/iter; left time: 104.4842s\n",
      "\titers: 700, epoch: 6 | loss: 0.3984955\n",
      "\tspeed: 0.0099s/iter; left time: 40.1705s\n",
      "\titers: 800, epoch: 6 | loss: 0.5249900\n",
      "\tspeed: 0.0106s/iter; left time: 41.9184s\n",
      "\titers: 900, epoch: 6 | loss: 0.4714347\n",
      "\tspeed: 0.0247s/iter; left time: 95.6129s\n",
      "Epoch: 6 cost time: 18.56109881401062\n",
      "Epoch: 6, Steps: 953 | Train Loss: 0.4365735 Vali Loss: 0.6339076 Test Loss: 0.9148927\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3975473\n",
      "\tspeed: 0.2770s/iter; left time: 1028.6320s\n",
      "\titers: 200, epoch: 7 | loss: 0.3956367\n",
      "\tspeed: 0.0159s/iter; left time: 57.4591s\n",
      "\titers: 300, epoch: 7 | loss: 0.4385774\n",
      "\tspeed: 0.0268s/iter; left time: 94.2937s\n",
      "\titers: 400, epoch: 7 | loss: 0.4225829\n",
      "\tspeed: 0.0076s/iter; left time: 25.8992s\n",
      "\titers: 500, epoch: 7 | loss: 0.4046276\n",
      "\tspeed: 0.0158s/iter; left time: 52.2748s\n",
      "\titers: 600, epoch: 7 | loss: 0.4315104\n",
      "\tspeed: 0.0215s/iter; left time: 68.9725s\n",
      "\titers: 700, epoch: 7 | loss: 0.4088434\n",
      "\tspeed: 0.0102s/iter; left time: 31.8236s\n",
      "\titers: 800, epoch: 7 | loss: 0.3288055\n",
      "\tspeed: 0.0137s/iter; left time: 41.2761s\n",
      "\titers: 900, epoch: 7 | loss: 0.4927737\n",
      "\tspeed: 0.0280s/iter; left time: 81.6414s\n",
      "Epoch: 7 cost time: 16.829569578170776\n",
      "Epoch: 7, Steps: 953 | Train Loss: 0.4363018 Vali Loss: 0.6337702 Test Loss: 0.9143142\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4772983\n",
      "\tspeed: 0.3275s/iter; left time: 903.9768s\n",
      "\titers: 200, epoch: 8 | loss: 0.4488514\n",
      "\tspeed: 0.0311s/iter; left time: 82.8038s\n",
      "\titers: 300, epoch: 8 | loss: 0.4258700\n",
      "\tspeed: 0.0032s/iter; left time: 8.1110s\n",
      "\titers: 400, epoch: 8 | loss: 0.3740515\n",
      "\tspeed: 0.0201s/iter; left time: 49.5175s\n",
      "\titers: 500, epoch: 8 | loss: 0.4348693\n",
      "\tspeed: 0.0177s/iter; left time: 41.6867s\n",
      "\titers: 600, epoch: 8 | loss: 0.4486671\n",
      "\tspeed: 0.0095s/iter; left time: 21.4491s\n",
      "\titers: 700, epoch: 8 | loss: 0.4407851\n",
      "\tspeed: 0.0289s/iter; left time: 62.4147s\n",
      "\titers: 800, epoch: 8 | loss: 0.4460466\n",
      "\tspeed: 0.0135s/iter; left time: 27.7734s\n",
      "\titers: 900, epoch: 8 | loss: 0.4713811\n",
      "\tspeed: 0.0094s/iter; left time: 18.4758s\n",
      "Epoch: 8 cost time: 15.672342538833618\n",
      "Epoch: 8, Steps: 953 | Train Loss: 0.4362992 Vali Loss: 0.6334877 Test Loss: 0.9142668\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 29) (8711, 1, 48, 29)\n",
      "test shape: (8711, 48, 29) (8711, 48, 29)\n",
      "mse:0.9099300503730774, mae:0.6673800349235535\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.5357712\n",
      "\tspeed: 0.0396s/iter; left time: 373.4057s\n",
      "\titers: 200, epoch: 1 | loss: 0.4444734\n",
      "\tspeed: 0.0326s/iter; left time: 303.7462s\n",
      "\titers: 300, epoch: 1 | loss: 0.4724023\n",
      "\tspeed: 0.0302s/iter; left time: 278.9970s\n",
      "\titers: 400, epoch: 1 | loss: 0.4844629\n",
      "\tspeed: 0.0271s/iter; left time: 247.8929s\n",
      "\titers: 500, epoch: 1 | loss: 0.5026370\n",
      "\tspeed: 0.0172s/iter; left time: 155.2520s\n",
      "\titers: 600, epoch: 1 | loss: 0.3864936\n",
      "\tspeed: 0.0364s/iter; left time: 325.4001s\n",
      "\titers: 700, epoch: 1 | loss: 0.4974551\n",
      "\tspeed: 0.0238s/iter; left time: 210.5600s\n",
      "\titers: 800, epoch: 1 | loss: 0.4223273\n",
      "\tspeed: 0.0159s/iter; left time: 138.8832s\n",
      "\titers: 900, epoch: 1 | loss: 0.4236113\n",
      "\tspeed: 0.0309s/iter; left time: 266.5999s\n",
      "Epoch: 1 cost time: 27.439437866210938\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.5039265 Vali Loss: 0.6622708 Test Loss: 0.9559073\n",
      "Validation loss decreased (inf --> 0.662271).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3939587\n",
      "\tspeed: 0.3609s/iter; left time: 3059.4539s\n",
      "\titers: 200, epoch: 2 | loss: 0.4501188\n",
      "\tspeed: 0.0263s/iter; left time: 220.3004s\n",
      "\titers: 300, epoch: 2 | loss: 0.4740724\n",
      "\tspeed: 0.0393s/iter; left time: 325.5228s\n",
      "\titers: 400, epoch: 2 | loss: 0.4011506\n",
      "\tspeed: 0.0343s/iter; left time: 280.6449s\n",
      "\titers: 500, epoch: 2 | loss: 0.4444767\n",
      "\tspeed: 0.0572s/iter; left time: 462.1227s\n",
      "\titers: 600, epoch: 2 | loss: 0.4898717\n",
      "\tspeed: 0.0135s/iter; left time: 107.4587s\n",
      "\titers: 700, epoch: 2 | loss: 0.4953011\n",
      "\tspeed: 0.0243s/iter; left time: 191.4708s\n",
      "\titers: 800, epoch: 2 | loss: 0.4454725\n",
      "\tspeed: 0.0260s/iter; left time: 202.3365s\n",
      "\titers: 900, epoch: 2 | loss: 0.4155242\n",
      "\tspeed: 0.0031s/iter; left time: 23.4192s\n",
      "Epoch: 2 cost time: 24.335673093795776\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.4463635 Vali Loss: 0.6346767 Test Loss: 0.9096325\n",
      "Validation loss decreased (0.662271 --> 0.634677).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4494371\n",
      "\tspeed: 0.3154s/iter; left time: 2373.4325s\n",
      "\titers: 200, epoch: 3 | loss: 0.4505060\n",
      "\tspeed: 0.0397s/iter; left time: 294.5549s\n",
      "\titers: 300, epoch: 3 | loss: 0.3535379\n",
      "\tspeed: 0.0270s/iter; left time: 197.6433s\n",
      "\titers: 400, epoch: 3 | loss: 0.4766021\n",
      "\tspeed: 0.0272s/iter; left time: 196.2293s\n",
      "\titers: 500, epoch: 3 | loss: 0.4381023\n",
      "\tspeed: 0.0384s/iter; left time: 273.8170s\n",
      "\titers: 600, epoch: 3 | loss: 0.4078365\n",
      "\tspeed: 0.0171s/iter; left time: 119.9994s\n",
      "\titers: 700, epoch: 3 | loss: 0.4524460\n",
      "\tspeed: 0.0123s/iter; left time: 85.3777s\n",
      "\titers: 800, epoch: 3 | loss: 0.4487939\n",
      "\tspeed: 0.0464s/iter; left time: 316.8428s\n",
      "\titers: 900, epoch: 3 | loss: 0.4753297\n",
      "\tspeed: 0.0316s/iter; left time: 212.4055s\n",
      "Epoch: 3 cost time: 27.343788146972656\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.4395145 Vali Loss: 0.6433349 Test Loss: 0.9322371\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4074008\n",
      "\tspeed: 0.4478s/iter; left time: 2942.8345s\n",
      "\titers: 200, epoch: 4 | loss: 0.4427268\n",
      "\tspeed: 0.0098s/iter; left time: 63.2472s\n",
      "\titers: 300, epoch: 4 | loss: 0.4039291\n",
      "\tspeed: 0.0151s/iter; left time: 96.1307s\n",
      "\titers: 400, epoch: 4 | loss: 0.4885094\n",
      "\tspeed: 0.0474s/iter; left time: 297.3163s\n",
      "\titers: 500, epoch: 4 | loss: 0.3736653\n",
      "\tspeed: 0.0225s/iter; left time: 138.9249s\n",
      "\titers: 600, epoch: 4 | loss: 0.4022359\n",
      "\tspeed: 0.0565s/iter; left time: 343.2482s\n",
      "\titers: 700, epoch: 4 | loss: 0.4433856\n",
      "\tspeed: 0.0094s/iter; left time: 55.9195s\n",
      "\titers: 800, epoch: 4 | loss: 0.4019572\n",
      "\tspeed: 0.0219s/iter; left time: 128.6906s\n",
      "\titers: 900, epoch: 4 | loss: 0.4062604\n",
      "\tspeed: 0.0442s/iter; left time: 254.9905s\n",
      "Epoch: 4 cost time: 29.898417472839355\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.4376894 Vali Loss: 0.6376219 Test Loss: 0.9218499\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5232362\n",
      "\tspeed: 0.4319s/iter; left time: 2426.9768s\n",
      "\titers: 200, epoch: 5 | loss: 0.4573276\n",
      "\tspeed: 0.0305s/iter; left time: 168.6023s\n",
      "\titers: 300, epoch: 5 | loss: 0.3851887\n",
      "\tspeed: 0.0422s/iter; left time: 228.7412s\n",
      "\titers: 400, epoch: 5 | loss: 0.4402090\n",
      "\tspeed: 0.0156s/iter; left time: 83.0115s\n",
      "\titers: 500, epoch: 5 | loss: 0.3950483\n",
      "\tspeed: 0.0514s/iter; left time: 268.0152s\n",
      "\titers: 600, epoch: 5 | loss: 0.3844500\n",
      "\tspeed: 0.0220s/iter; left time: 112.5743s\n",
      "\titers: 700, epoch: 5 | loss: 0.5291409\n",
      "\tspeed: 0.0229s/iter; left time: 114.9858s\n",
      "\titers: 800, epoch: 5 | loss: 0.4898561\n",
      "\tspeed: 0.0351s/iter; left time: 172.7301s\n",
      "\titers: 900, epoch: 5 | loss: 0.4713517\n",
      "\tspeed: 0.0140s/iter; left time: 67.3818s\n",
      "Epoch: 5 cost time: 26.954771757125854\n",
      "Epoch: 5, Steps: 953 | Train Loss: 0.4369579 Vali Loss: 0.6370977 Test Loss: 0.9216005\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 29) (8711, 1, 48, 29)\n",
      "test shape: (8711, 48, 29) (8711, 48, 29)\n",
      "mse:0.9096322655677795, mae:0.6694639921188354\n",
      "\n",
      "Extracted Part: long_term_forecast__48_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__48_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=29, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_all_columns.csv', dec_in=29, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=29, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_96_df_all_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.7013574\n",
      "\tspeed: 0.0533s/iter; left time: 501.9452s\n",
      "\titers: 200, epoch: 1 | loss: 0.5878045\n",
      "\tspeed: 0.0181s/iter; left time: 169.0395s\n",
      "\titers: 300, epoch: 1 | loss: 0.5487080\n",
      "\tspeed: 0.0482s/iter; left time: 444.9094s\n",
      "\titers: 400, epoch: 1 | loss: 0.4955180\n",
      "\tspeed: 0.0220s/iter; left time: 200.3093s\n",
      "\titers: 500, epoch: 1 | loss: 0.4842401\n",
      "\tspeed: 0.0298s/iter; left time: 268.9646s\n",
      "\titers: 600, epoch: 1 | loss: 0.5492756\n",
      "\tspeed: 0.0272s/iter; left time: 242.4951s\n",
      "\titers: 700, epoch: 1 | loss: 0.4514607\n",
      "\tspeed: 0.0511s/iter; left time: 451.1861s\n",
      "\titers: 800, epoch: 1 | loss: 0.5707030\n",
      "\tspeed: 0.0530s/iter; left time: 462.1649s\n",
      "\titers: 900, epoch: 1 | loss: 0.4535215\n",
      "\tspeed: 0.0110s/iter; left time: 95.1793s\n",
      "Epoch: 1 cost time: 33.136303663253784\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.5695519 Vali Loss: 0.7845390 Test Loss: 1.1233877\n",
      "Validation loss decreased (inf --> 0.784539).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4732433\n",
      "\tspeed: 0.3296s/iter; left time: 2791.7204s\n",
      "\titers: 200, epoch: 2 | loss: 0.4966302\n",
      "\tspeed: 0.0518s/iter; left time: 433.4380s\n",
      "\titers: 300, epoch: 2 | loss: 0.5571529\n",
      "\tspeed: 0.0190s/iter; left time: 157.4172s\n",
      "\titers: 400, epoch: 2 | loss: 0.5020965\n",
      "\tspeed: 0.0419s/iter; left time: 342.1419s\n",
      "\titers: 500, epoch: 2 | loss: 0.5997694\n",
      "\tspeed: 0.0197s/iter; left time: 158.7554s\n",
      "\titers: 600, epoch: 2 | loss: 0.5066665\n",
      "\tspeed: 0.0361s/iter; left time: 287.7015s\n",
      "\titers: 700, epoch: 2 | loss: 0.5110217\n",
      "\tspeed: 0.0279s/iter; left time: 219.2211s\n",
      "\titers: 800, epoch: 2 | loss: 0.4718327\n",
      "\tspeed: 0.0203s/iter; left time: 157.3878s\n",
      "\titers: 900, epoch: 2 | loss: 0.5786946\n",
      "\tspeed: 0.0258s/iter; left time: 198.0195s\n",
      "Epoch: 2 cost time: 27.810463905334473\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.5257102 Vali Loss: 0.7718642 Test Loss: 1.1094432\n",
      "Validation loss decreased (0.784539 --> 0.771864).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4814379\n",
      "\tspeed: 0.4450s/iter; left time: 3344.8665s\n",
      "\titers: 200, epoch: 3 | loss: 0.5230183\n",
      "\tspeed: 0.0504s/iter; left time: 373.7492s\n",
      "\titers: 300, epoch: 3 | loss: 0.5850930\n",
      "\tspeed: 0.0178s/iter; left time: 130.2026s\n",
      "\titers: 400, epoch: 3 | loss: 0.6620468\n",
      "\tspeed: 0.0391s/iter; left time: 281.9150s\n",
      "\titers: 500, epoch: 3 | loss: 0.4577120\n",
      "\tspeed: 0.0247s/iter; left time: 175.7806s\n",
      "\titers: 600, epoch: 3 | loss: 0.4749392\n",
      "\tspeed: 0.0220s/iter; left time: 154.1884s\n",
      "\titers: 700, epoch: 3 | loss: 0.5851589\n",
      "\tspeed: 0.0325s/iter; left time: 225.0921s\n",
      "\titers: 800, epoch: 3 | loss: 0.5572463\n",
      "\tspeed: 0.0213s/iter; left time: 145.2356s\n",
      "\titers: 900, epoch: 3 | loss: 0.5206154\n",
      "\tspeed: 0.0481s/iter; left time: 323.0286s\n",
      "Epoch: 3 cost time: 29.77833867073059\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.5216113 Vali Loss: 0.7700465 Test Loss: 1.1084169\n",
      "Validation loss decreased (0.771864 --> 0.770047).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4961879\n",
      "\tspeed: 0.3400s/iter; left time: 2231.9985s\n",
      "\titers: 200, epoch: 4 | loss: 0.5819280\n",
      "\tspeed: 0.0402s/iter; left time: 260.0558s\n",
      "\titers: 300, epoch: 4 | loss: 0.4603938\n",
      "\tspeed: 0.0133s/iter; left time: 84.8909s\n",
      "\titers: 400, epoch: 4 | loss: 0.4984903\n",
      "\tspeed: 0.0410s/iter; left time: 257.0933s\n",
      "\titers: 500, epoch: 4 | loss: 0.4455124\n",
      "\tspeed: 0.0079s/iter; left time: 48.9089s\n",
      "\titers: 600, epoch: 4 | loss: 0.5291024\n",
      "\tspeed: 0.0469s/iter; left time: 284.4951s\n",
      "\titers: 700, epoch: 4 | loss: 0.5274696\n",
      "\tspeed: 0.0103s/iter; left time: 61.4625s\n",
      "\titers: 800, epoch: 4 | loss: 0.5388995\n",
      "\tspeed: 0.0457s/iter; left time: 267.9107s\n",
      "\titers: 900, epoch: 4 | loss: 0.4688331\n",
      "\tspeed: 0.0272s/iter; left time: 156.5974s\n",
      "Epoch: 4 cost time: 28.93023920059204\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.5203851 Vali Loss: 0.7658269 Test Loss: 1.1025891\n",
      "Validation loss decreased (0.770047 --> 0.765827).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5089071\n",
      "\tspeed: 0.3554s/iter; left time: 1995.0098s\n",
      "\titers: 200, epoch: 5 | loss: 0.5676893\n",
      "\tspeed: 0.0033s/iter; left time: 18.3953s\n",
      "\titers: 300, epoch: 5 | loss: 0.5632151\n",
      "\tspeed: 0.0126s/iter; left time: 68.0343s\n",
      "\titers: 400, epoch: 5 | loss: 0.5524287\n",
      "\tspeed: 0.0291s/iter; left time: 154.6796s\n",
      "\titers: 500, epoch: 5 | loss: 0.4795516\n",
      "\tspeed: 0.0031s/iter; left time: 16.3236s\n",
      "\titers: 600, epoch: 5 | loss: 0.4611592\n",
      "\tspeed: 0.0194s/iter; left time: 98.9723s\n",
      "\titers: 700, epoch: 5 | loss: 0.5473090\n",
      "\tspeed: 0.0350s/iter; left time: 175.5572s\n",
      "\titers: 800, epoch: 5 | loss: 0.5206653\n",
      "\tspeed: 0.0036s/iter; left time: 17.8150s\n",
      "\titers: 900, epoch: 5 | loss: 0.5855504\n",
      "\tspeed: 0.0242s/iter; left time: 116.4799s\n",
      "Epoch: 5 cost time: 21.128654956817627\n",
      "Epoch: 5, Steps: 952 | Train Loss: 0.5199238 Vali Loss: 0.7695212 Test Loss: 1.1096343\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.5132271\n",
      "\tspeed: 0.3333s/iter; left time: 1553.3097s\n",
      "\titers: 200, epoch: 6 | loss: 0.4936326\n",
      "\tspeed: 0.0119s/iter; left time: 54.2609s\n",
      "\titers: 300, epoch: 6 | loss: 0.4527277\n",
      "\tspeed: 0.0304s/iter; left time: 135.8006s\n",
      "\titers: 400, epoch: 6 | loss: 0.5443829\n",
      "\tspeed: 0.0372s/iter; left time: 162.4362s\n",
      "\titers: 500, epoch: 6 | loss: 0.6208467\n",
      "\tspeed: 0.0050s/iter; left time: 21.1504s\n",
      "\titers: 600, epoch: 6 | loss: 0.4932531\n",
      "\tspeed: 0.0413s/iter; left time: 172.0184s\n",
      "\titers: 700, epoch: 6 | loss: 0.5218767\n",
      "\tspeed: 0.0150s/iter; left time: 60.8019s\n",
      "\titers: 800, epoch: 6 | loss: 0.4615943\n",
      "\tspeed: 0.0201s/iter; left time: 79.7652s\n",
      "\titers: 900, epoch: 6 | loss: 0.4768701\n",
      "\tspeed: 0.0356s/iter; left time: 137.4562s\n",
      "Epoch: 6 cost time: 23.81227135658264\n",
      "Epoch: 6, Steps: 952 | Train Loss: 0.5196788 Vali Loss: 0.7704942 Test Loss: 1.1099048\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.5566017\n",
      "\tspeed: 0.2799s/iter; left time: 1038.2238s\n",
      "\titers: 200, epoch: 7 | loss: 0.4897730\n",
      "\tspeed: 0.0518s/iter; left time: 186.9053s\n",
      "\titers: 300, epoch: 7 | loss: 0.5231029\n",
      "\tspeed: 0.0063s/iter; left time: 22.1573s\n",
      "\titers: 400, epoch: 7 | loss: 0.6046622\n",
      "\tspeed: 0.0527s/iter; left time: 179.6370s\n",
      "\titers: 500, epoch: 7 | loss: 0.5509413\n",
      "\tspeed: 0.0310s/iter; left time: 102.5380s\n",
      "\titers: 600, epoch: 7 | loss: 0.5591111\n",
      "\tspeed: 0.0056s/iter; left time: 18.0518s\n",
      "\titers: 700, epoch: 7 | loss: 0.6154180\n",
      "\tspeed: 0.0307s/iter; left time: 95.5912s\n",
      "\titers: 800, epoch: 7 | loss: 0.5700971\n",
      "\tspeed: 0.0041s/iter; left time: 12.3041s\n",
      "\titers: 900, epoch: 7 | loss: 0.5778615\n",
      "\tspeed: 0.0082s/iter; left time: 23.7248s\n",
      "Epoch: 7 cost time: 23.239251613616943\n",
      "Epoch: 7, Steps: 952 | Train Loss: 0.5195674 Vali Loss: 0.7697489 Test Loss: 1.1095479\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 29) (8663, 1, 96, 29)\n",
      "test shape: (8663, 96, 29) (8663, 96, 29)\n",
      "mse:1.1025893688201904, mae:0.7486240267753601\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.6552199\n",
      "\tspeed: 0.0319s/iter; left time: 300.8785s\n",
      "\titers: 200, epoch: 1 | loss: 0.5634387\n",
      "\tspeed: 0.0035s/iter; left time: 32.4409s\n",
      "\titers: 300, epoch: 1 | loss: 0.5069177\n",
      "\tspeed: 0.0186s/iter; left time: 171.7330s\n",
      "\titers: 400, epoch: 1 | loss: 0.5101775\n",
      "\tspeed: 0.0223s/iter; left time: 203.2221s\n",
      "\titers: 500, epoch: 1 | loss: 0.5302448\n",
      "\tspeed: 0.0040s/iter; left time: 36.0680s\n",
      "\titers: 600, epoch: 1 | loss: 0.4723275\n",
      "\tspeed: 0.0372s/iter; left time: 331.8890s\n",
      "\titers: 700, epoch: 1 | loss: 0.4220249\n",
      "\tspeed: 0.0248s/iter; left time: 218.6561s\n",
      "\titers: 800, epoch: 1 | loss: 0.5147039\n",
      "\tspeed: 0.0118s/iter; left time: 102.7690s\n",
      "\titers: 900, epoch: 1 | loss: 0.5241773\n",
      "\tspeed: 0.0440s/iter; left time: 379.3846s\n",
      "Epoch: 1 cost time: 20.106850624084473\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.5701862 Vali Loss: 0.7986774 Test Loss: 1.1619188\n",
      "Validation loss decreased (inf --> 0.798677).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5082786\n",
      "\tspeed: 0.2829s/iter; left time: 2396.3029s\n",
      "\titers: 200, epoch: 2 | loss: 0.6811507\n",
      "\tspeed: 0.0049s/iter; left time: 41.1193s\n",
      "\titers: 300, epoch: 2 | loss: 0.6507064\n",
      "\tspeed: 0.0385s/iter; left time: 318.0727s\n",
      "\titers: 400, epoch: 2 | loss: 0.5797721\n",
      "\tspeed: 0.0165s/iter; left time: 135.1124s\n",
      "\titers: 500, epoch: 2 | loss: 0.6225839\n",
      "\tspeed: 0.0032s/iter; left time: 26.1431s\n",
      "\titers: 600, epoch: 2 | loss: 0.4699896\n",
      "\tspeed: 0.0149s/iter; left time: 118.9072s\n",
      "\titers: 700, epoch: 2 | loss: 0.5217916\n",
      "\tspeed: 0.0271s/iter; left time: 213.0257s\n",
      "\titers: 800, epoch: 2 | loss: 0.5765536\n",
      "\tspeed: 0.0041s/iter; left time: 32.1137s\n",
      "\titers: 900, epoch: 2 | loss: 0.4092681\n",
      "\tspeed: 0.0255s/iter; left time: 195.8902s\n",
      "Epoch: 2 cost time: 18.80894184112549\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.5256643 Vali Loss: 0.7582584 Test Loss: 1.0794108\n",
      "Validation loss decreased (0.798677 --> 0.758258).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5652342\n",
      "\tspeed: 0.2790s/iter; left time: 2097.4314s\n",
      "\titers: 200, epoch: 3 | loss: 0.4852910\n",
      "\tspeed: 0.0090s/iter; left time: 66.4599s\n",
      "\titers: 300, epoch: 3 | loss: 0.5203076\n",
      "\tspeed: 0.0507s/iter; left time: 371.2124s\n",
      "\titers: 400, epoch: 3 | loss: 0.5636650\n",
      "\tspeed: 0.0089s/iter; left time: 64.4285s\n",
      "\titers: 500, epoch: 3 | loss: 0.4209502\n",
      "\tspeed: 0.0075s/iter; left time: 53.4776s\n",
      "\titers: 600, epoch: 3 | loss: 0.5262769\n",
      "\tspeed: 0.0512s/iter; left time: 359.4724s\n",
      "\titers: 700, epoch: 3 | loss: 0.5076457\n",
      "\tspeed: 0.0219s/iter; left time: 151.5192s\n",
      "\titers: 800, epoch: 3 | loss: 0.5658609\n",
      "\tspeed: 0.0031s/iter; left time: 21.1485s\n",
      "\titers: 900, epoch: 3 | loss: 0.4809586\n",
      "\tspeed: 0.0224s/iter; left time: 150.7167s\n",
      "Epoch: 3 cost time: 20.04761290550232\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.5215725 Vali Loss: 0.7720830 Test Loss: 1.1134716\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4470363\n",
      "\tspeed: 0.3232s/iter; left time: 2121.9223s\n",
      "\titers: 200, epoch: 4 | loss: 0.5503871\n",
      "\tspeed: 0.0044s/iter; left time: 28.5428s\n",
      "\titers: 300, epoch: 4 | loss: 0.5580165\n",
      "\tspeed: 0.0193s/iter; left time: 123.0609s\n",
      "\titers: 400, epoch: 4 | loss: 0.5313561\n",
      "\tspeed: 0.0385s/iter; left time: 241.0484s\n",
      "\titers: 500, epoch: 4 | loss: 0.4674892\n",
      "\tspeed: 0.0034s/iter; left time: 20.7544s\n",
      "\titers: 600, epoch: 4 | loss: 0.6112863\n",
      "\tspeed: 0.0074s/iter; left time: 44.6335s\n",
      "\titers: 700, epoch: 4 | loss: 0.4624641\n",
      "\tspeed: 0.0406s/iter; left time: 242.4241s\n",
      "\titers: 800, epoch: 4 | loss: 0.5251780\n",
      "\tspeed: 0.0032s/iter; left time: 18.9777s\n",
      "\titers: 900, epoch: 4 | loss: 0.5608168\n",
      "\tspeed: 0.0063s/iter; left time: 36.1811s\n",
      "Epoch: 4 cost time: 18.436248064041138\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.5203552 Vali Loss: 0.7739650 Test Loss: 1.1188239\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5874925\n",
      "\tspeed: 0.3262s/iter; left time: 1831.0469s\n",
      "\titers: 200, epoch: 5 | loss: 0.4916911\n",
      "\tspeed: 0.0051s/iter; left time: 28.2634s\n",
      "\titers: 300, epoch: 5 | loss: 0.5457378\n",
      "\tspeed: 0.0286s/iter; left time: 154.9205s\n",
      "\titers: 400, epoch: 5 | loss: 0.4367219\n",
      "\tspeed: 0.0195s/iter; left time: 103.4212s\n",
      "\titers: 500, epoch: 5 | loss: 0.5793046\n",
      "\tspeed: 0.0218s/iter; left time: 113.4600s\n",
      "\titers: 600, epoch: 5 | loss: 0.5553367\n",
      "\tspeed: 0.0401s/iter; left time: 204.8485s\n",
      "\titers: 700, epoch: 5 | loss: 0.4789662\n",
      "\tspeed: 0.0145s/iter; left time: 72.9032s\n",
      "\titers: 800, epoch: 5 | loss: 0.4247833\n",
      "\tspeed: 0.0033s/iter; left time: 16.2622s\n",
      "\titers: 900, epoch: 5 | loss: 0.5519770\n",
      "\tspeed: 0.0321s/iter; left time: 154.5590s\n",
      "Epoch: 5 cost time: 23.992138385772705\n",
      "Epoch: 5, Steps: 952 | Train Loss: 0.5198996 Vali Loss: 0.7717260 Test Loss: 1.1155230\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 29) (8663, 1, 96, 29)\n",
      "test shape: (8663, 96, 29) (8663, 96, 29)\n",
      "mse:1.0794105529785156, mae:0.7402054667472839\n",
      "\n",
      "Extracted Part: long_term_forecast__96_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__96_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=29, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_all_columns.csv', dec_in=29, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=29, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_192_df_all_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.6375988\n",
      "\tspeed: 0.0310s/iter; left time: 291.3942s\n",
      "\titers: 200, epoch: 1 | loss: 0.6498512\n",
      "\tspeed: 0.0272s/iter; left time: 253.1288s\n",
      "\titers: 300, epoch: 1 | loss: 0.7383912\n",
      "\tspeed: 0.0191s/iter; left time: 175.2995s\n",
      "\titers: 400, epoch: 1 | loss: 0.6248664\n",
      "\tspeed: 0.0290s/iter; left time: 263.9808s\n",
      "\titers: 500, epoch: 1 | loss: 0.5408130\n",
      "\tspeed: 0.0248s/iter; left time: 222.6636s\n",
      "\titers: 600, epoch: 1 | loss: 0.6815245\n",
      "\tspeed: 0.0275s/iter; left time: 244.8598s\n",
      "\titers: 700, epoch: 1 | loss: 0.7218632\n",
      "\tspeed: 0.0349s/iter; left time: 306.6035s\n",
      "\titers: 800, epoch: 1 | loss: 0.5726955\n",
      "\tspeed: 0.0235s/iter; left time: 203.8286s\n",
      "\titers: 900, epoch: 1 | loss: 0.6462486\n",
      "\tspeed: 0.0276s/iter; left time: 237.4524s\n",
      "Epoch: 1 cost time: 25.7988760471344\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.6139608 Vali Loss: 0.8910472 Test Loss: 1.2952863\n",
      "Validation loss decreased (inf --> 0.891047).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6277521\n",
      "\tspeed: 0.3554s/iter; left time: 3000.7037s\n",
      "\titers: 200, epoch: 2 | loss: 0.6070321\n",
      "\tspeed: 0.0332s/iter; left time: 276.6151s\n",
      "\titers: 300, epoch: 2 | loss: 0.6589794\n",
      "\tspeed: 0.0223s/iter; left time: 183.7841s\n",
      "\titers: 400, epoch: 2 | loss: 0.5662223\n",
      "\tspeed: 0.0342s/iter; left time: 278.5587s\n",
      "\titers: 500, epoch: 2 | loss: 0.4840673\n",
      "\tspeed: 0.0287s/iter; left time: 230.8635s\n",
      "\titers: 600, epoch: 2 | loss: 0.5443634\n",
      "\tspeed: 0.0232s/iter; left time: 184.3695s\n",
      "\titers: 700, epoch: 2 | loss: 0.5306025\n",
      "\tspeed: 0.0145s/iter; left time: 113.5550s\n",
      "\titers: 800, epoch: 2 | loss: 0.4630702\n",
      "\tspeed: 0.0321s/iter; left time: 248.3598s\n",
      "\titers: 900, epoch: 2 | loss: 0.5081156\n",
      "\tspeed: 0.0289s/iter; left time: 220.9933s\n",
      "Epoch: 2 cost time: 26.28254461288452\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.5772745 Vali Loss: 0.8706915 Test Loss: 1.2572480\n",
      "Validation loss decreased (0.891047 --> 0.870691).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5798671\n",
      "\tspeed: 0.3672s/iter; left time: 2751.5164s\n",
      "\titers: 200, epoch: 3 | loss: 0.5370126\n",
      "\tspeed: 0.0277s/iter; left time: 204.6996s\n",
      "\titers: 300, epoch: 3 | loss: 0.5975860\n",
      "\tspeed: 0.0317s/iter; left time: 230.8666s\n",
      "\titers: 400, epoch: 3 | loss: 0.5484046\n",
      "\tspeed: 0.0099s/iter; left time: 70.8911s\n",
      "\titers: 500, epoch: 3 | loss: 0.6206524\n",
      "\tspeed: 0.0349s/iter; left time: 247.2632s\n",
      "\titers: 600, epoch: 3 | loss: 0.5537298\n",
      "\tspeed: 0.0323s/iter; left time: 226.1134s\n",
      "\titers: 700, epoch: 3 | loss: 0.5822453\n",
      "\tspeed: 0.0379s/iter; left time: 261.3434s\n",
      "\titers: 800, epoch: 3 | loss: 0.5342355\n",
      "\tspeed: 0.0398s/iter; left time: 270.6792s\n",
      "\titers: 900, epoch: 3 | loss: 0.6031967\n",
      "\tspeed: 0.0404s/iter; left time: 270.0691s\n",
      "Epoch: 3 cost time: 29.205245971679688\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.5745310 Vali Loss: 0.8805803 Test Loss: 1.2805341\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5704315\n",
      "\tspeed: 0.4297s/iter; left time: 2811.8205s\n",
      "\titers: 200, epoch: 4 | loss: 0.5277311\n",
      "\tspeed: 0.0365s/iter; left time: 235.2957s\n",
      "\titers: 300, epoch: 4 | loss: 0.5347557\n",
      "\tspeed: 0.0341s/iter; left time: 216.2245s\n",
      "\titers: 400, epoch: 4 | loss: 0.5967587\n",
      "\tspeed: 0.0302s/iter; left time: 188.6604s\n",
      "\titers: 500, epoch: 4 | loss: 0.5756212\n",
      "\tspeed: 0.0486s/iter; left time: 298.8011s\n",
      "\titers: 600, epoch: 4 | loss: 0.6456509\n",
      "\tspeed: 0.0368s/iter; left time: 222.6614s\n",
      "\titers: 700, epoch: 4 | loss: 0.6124114\n",
      "\tspeed: 0.0292s/iter; left time: 173.5305s\n",
      "\titers: 800, epoch: 4 | loss: 0.4846733\n",
      "\tspeed: 0.0358s/iter; left time: 209.3901s\n",
      "\titers: 900, epoch: 4 | loss: 0.6134216\n",
      "\tspeed: 0.0471s/iter; left time: 270.6769s\n",
      "Epoch: 4 cost time: 36.52687978744507\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.5737270 Vali Loss: 0.8806707 Test Loss: 1.2804655\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5503904\n",
      "\tspeed: 0.4163s/iter; left time: 2329.2791s\n",
      "\titers: 200, epoch: 5 | loss: 0.6095288\n",
      "\tspeed: 0.0357s/iter; left time: 196.1893s\n",
      "\titers: 300, epoch: 5 | loss: 0.5474584\n",
      "\tspeed: 0.0334s/iter; left time: 180.4148s\n",
      "\titers: 400, epoch: 5 | loss: 0.5223837\n",
      "\tspeed: 0.0343s/iter; left time: 181.4479s\n",
      "\titers: 500, epoch: 5 | loss: 0.5320550\n",
      "\tspeed: 0.0351s/iter; left time: 182.3918s\n",
      "\titers: 600, epoch: 5 | loss: 0.5439659\n",
      "\tspeed: 0.0305s/iter; left time: 155.1810s\n",
      "\titers: 700, epoch: 5 | loss: 0.6654623\n",
      "\tspeed: 0.0431s/iter; left time: 215.4348s\n",
      "\titers: 800, epoch: 5 | loss: 0.5976248\n",
      "\tspeed: 0.0300s/iter; left time: 146.6709s\n",
      "\titers: 900, epoch: 5 | loss: 0.5373340\n",
      "\tspeed: 0.0398s/iter; left time: 190.8820s\n",
      "Epoch: 5 cost time: 33.073339223861694\n",
      "Epoch: 5, Steps: 949 | Train Loss: 0.5733606 Vali Loss: 0.8845646 Test Loss: 1.2903167\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 29) (8567, 1, 192, 29)\n",
      "test shape: (8567, 192, 29) (8567, 192, 29)\n",
      "mse:1.2572482824325562, mae:0.8065916299819946\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.7288939\n",
      "\tspeed: 0.0655s/iter; left time: 614.9467s\n",
      "\titers: 200, epoch: 1 | loss: 0.6255454\n",
      "\tspeed: 0.0222s/iter; left time: 206.1677s\n",
      "\titers: 300, epoch: 1 | loss: 0.5853577\n",
      "\tspeed: 0.0636s/iter; left time: 584.1948s\n",
      "\titers: 400, epoch: 1 | loss: 0.5373601\n",
      "\tspeed: 0.0176s/iter; left time: 159.5983s\n",
      "\titers: 500, epoch: 1 | loss: 0.5846345\n",
      "\tspeed: 0.0610s/iter; left time: 548.8782s\n",
      "\titers: 600, epoch: 1 | loss: 0.6077414\n",
      "\tspeed: 0.0217s/iter; left time: 193.3302s\n",
      "\titers: 700, epoch: 1 | loss: 0.5429401\n",
      "\tspeed: 0.0488s/iter; left time: 429.2848s\n",
      "\titers: 800, epoch: 1 | loss: 0.6147342\n",
      "\tspeed: 0.0092s/iter; left time: 80.2177s\n",
      "\titers: 900, epoch: 1 | loss: 0.5582058\n",
      "\tspeed: 0.0489s/iter; left time: 420.3064s\n",
      "Epoch: 1 cost time: 36.43659210205078\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.6135520 Vali Loss: 0.8974313 Test Loss: 1.3097383\n",
      "Validation loss decreased (inf --> 0.897431).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5341684\n",
      "\tspeed: 0.4739s/iter; left time: 4000.8336s\n",
      "\titers: 200, epoch: 2 | loss: 0.5110150\n",
      "\tspeed: 0.0232s/iter; left time: 193.3627s\n",
      "\titers: 300, epoch: 2 | loss: 0.6179590\n",
      "\tspeed: 0.0609s/iter; left time: 501.9548s\n",
      "\titers: 400, epoch: 2 | loss: 0.5504835\n",
      "\tspeed: 0.0199s/iter; left time: 161.7466s\n",
      "\titers: 500, epoch: 2 | loss: 0.6224058\n",
      "\tspeed: 0.0566s/iter; left time: 455.5234s\n",
      "\titers: 600, epoch: 2 | loss: 0.6304994\n",
      "\tspeed: 0.0151s/iter; left time: 120.2246s\n",
      "\titers: 700, epoch: 2 | loss: 0.5452334\n",
      "\tspeed: 0.0585s/iter; left time: 458.5955s\n",
      "\titers: 800, epoch: 2 | loss: 0.5920624\n",
      "\tspeed: 0.0306s/iter; left time: 236.9199s\n",
      "\titers: 900, epoch: 2 | loss: 0.5741848\n",
      "\tspeed: 0.0398s/iter; left time: 304.2561s\n",
      "Epoch: 2 cost time: 39.867289543151855\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.5772782 Vali Loss: 0.8862280 Test Loss: 1.2915792\n",
      "Validation loss decreased (0.897431 --> 0.886228).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5765485\n",
      "\tspeed: 0.4169s/iter; left time: 3124.1077s\n",
      "\titers: 200, epoch: 3 | loss: 0.5569874\n",
      "\tspeed: 0.0513s/iter; left time: 379.4604s\n",
      "\titers: 300, epoch: 3 | loss: 0.6123449\n",
      "\tspeed: 0.0191s/iter; left time: 139.3556s\n",
      "\titers: 400, epoch: 3 | loss: 0.6225129\n",
      "\tspeed: 0.0473s/iter; left time: 340.1101s\n",
      "\titers: 500, epoch: 3 | loss: 0.7299076\n",
      "\tspeed: 0.0100s/iter; left time: 70.6017s\n",
      "\titers: 600, epoch: 3 | loss: 0.5438495\n",
      "\tspeed: 0.0453s/iter; left time: 316.7265s\n",
      "\titers: 700, epoch: 3 | loss: 0.5921983\n",
      "\tspeed: 0.0101s/iter; left time: 69.8430s\n",
      "\titers: 800, epoch: 3 | loss: 0.6178490\n",
      "\tspeed: 0.0500s/iter; left time: 339.6439s\n",
      "\titers: 900, epoch: 3 | loss: 0.5975685\n",
      "\tspeed: 0.0181s/iter; left time: 121.3561s\n",
      "Epoch: 3 cost time: 31.0286967754364\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.5745636 Vali Loss: 0.8816845 Test Loss: 1.2843478\n",
      "Validation loss decreased (0.886228 --> 0.881685).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5072017\n",
      "\tspeed: 0.4580s/iter; left time: 2997.3688s\n",
      "\titers: 200, epoch: 4 | loss: 0.5319394\n",
      "\tspeed: 0.0566s/iter; left time: 364.6044s\n",
      "\titers: 300, epoch: 4 | loss: 0.5474897\n",
      "\tspeed: 0.0114s/iter; left time: 72.5672s\n",
      "\titers: 400, epoch: 4 | loss: 0.6802754\n",
      "\tspeed: 0.0706s/iter; left time: 441.0731s\n",
      "\titers: 500, epoch: 4 | loss: 0.5118543\n",
      "\tspeed: 0.0166s/iter; left time: 102.0131s\n",
      "\titers: 600, epoch: 4 | loss: 0.5790836\n",
      "\tspeed: 0.0719s/iter; left time: 434.3075s\n",
      "\titers: 700, epoch: 4 | loss: 0.5932488\n",
      "\tspeed: 0.0103s/iter; left time: 61.4084s\n",
      "\titers: 800, epoch: 4 | loss: 0.5218318\n",
      "\tspeed: 0.0506s/iter; left time: 295.7801s\n",
      "\titers: 900, epoch: 4 | loss: 0.5443781\n",
      "\tspeed: 0.0220s/iter; left time: 126.1633s\n",
      "Epoch: 4 cost time: 36.867464542388916\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.5737522 Vali Loss: 0.8837942 Test Loss: 1.2864562\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6558712\n",
      "\tspeed: 0.2866s/iter; left time: 1603.6926s\n",
      "\titers: 200, epoch: 5 | loss: 0.5349551\n",
      "\tspeed: 0.0550s/iter; left time: 302.4553s\n",
      "\titers: 300, epoch: 5 | loss: 0.5039395\n",
      "\tspeed: 0.0060s/iter; left time: 32.5933s\n",
      "\titers: 400, epoch: 5 | loss: 0.5873824\n",
      "\tspeed: 0.0201s/iter; left time: 106.3567s\n",
      "\titers: 500, epoch: 5 | loss: 0.5846761\n",
      "\tspeed: 0.0303s/iter; left time: 157.6348s\n",
      "\titers: 600, epoch: 5 | loss: 0.5079730\n",
      "\tspeed: 0.0159s/iter; left time: 81.0662s\n",
      "\titers: 700, epoch: 5 | loss: 0.4802802\n",
      "\tspeed: 0.0522s/iter; left time: 260.6964s\n",
      "\titers: 800, epoch: 5 | loss: 0.5962517\n",
      "\tspeed: 0.0045s/iter; left time: 22.1943s\n",
      "\titers: 900, epoch: 5 | loss: 0.5397895\n",
      "\tspeed: 0.0486s/iter; left time: 233.1752s\n",
      "Epoch: 5 cost time: 26.795944929122925\n",
      "Epoch: 5, Steps: 949 | Train Loss: 0.5733838 Vali Loss: 0.8860472 Test Loss: 1.2918472\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4927979\n",
      "\tspeed: 0.3134s/iter; left time: 1456.0337s\n",
      "\titers: 200, epoch: 6 | loss: 0.6173344\n",
      "\tspeed: 0.0190s/iter; left time: 86.4629s\n",
      "\titers: 300, epoch: 6 | loss: 0.5873176\n",
      "\tspeed: 0.0474s/iter; left time: 210.5611s\n",
      "\titers: 400, epoch: 6 | loss: 0.5549837\n",
      "\tspeed: 0.0178s/iter; left time: 77.4961s\n",
      "\titers: 500, epoch: 6 | loss: 0.5677401\n",
      "\tspeed: 0.0158s/iter; left time: 67.1528s\n",
      "\titers: 600, epoch: 6 | loss: 0.5768836\n",
      "\tspeed: 0.0494s/iter; left time: 204.8044s\n",
      "\titers: 700, epoch: 6 | loss: 0.4882973\n",
      "\tspeed: 0.0064s/iter; left time: 25.7840s\n",
      "\titers: 800, epoch: 6 | loss: 0.6019175\n",
      "\tspeed: 0.0264s/iter; left time: 104.1268s\n",
      "\titers: 900, epoch: 6 | loss: 0.5459514\n",
      "\tspeed: 0.0243s/iter; left time: 93.3672s\n",
      "Epoch: 6 cost time: 22.377995014190674\n",
      "Epoch: 6, Steps: 949 | Train Loss: 0.5732143 Vali Loss: 0.8777063 Test Loss: 1.2739805\n",
      "Validation loss decreased (0.881685 --> 0.877706).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.5863195\n",
      "\tspeed: 0.2973s/iter; left time: 1099.2855s\n",
      "\titers: 200, epoch: 7 | loss: 0.6291737\n",
      "\tspeed: 0.0466s/iter; left time: 167.5223s\n",
      "\titers: 300, epoch: 7 | loss: 0.5693917\n",
      "\tspeed: 0.0242s/iter; left time: 84.8001s\n",
      "\titers: 400, epoch: 7 | loss: 0.5162443\n",
      "\tspeed: 0.0042s/iter; left time: 14.3832s\n",
      "\titers: 500, epoch: 7 | loss: 0.5529953\n",
      "\tspeed: 0.0306s/iter; left time: 100.7950s\n",
      "\titers: 600, epoch: 7 | loss: 0.6292158\n",
      "\tspeed: 0.0254s/iter; left time: 81.3540s\n",
      "\titers: 700, epoch: 7 | loss: 0.6119898\n",
      "\tspeed: 0.0089s/iter; left time: 27.6499s\n",
      "\titers: 800, epoch: 7 | loss: 0.7016842\n",
      "\tspeed: 0.0272s/iter; left time: 81.4070s\n",
      "\titers: 900, epoch: 7 | loss: 0.5741520\n",
      "\tspeed: 0.0040s/iter; left time: 11.6450s\n",
      "Epoch: 7 cost time: 18.83367943763733\n",
      "Epoch: 7, Steps: 949 | Train Loss: 0.5731304 Vali Loss: 0.8781549 Test Loss: 1.2769756\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.5249053\n",
      "\tspeed: 0.2915s/iter; left time: 801.1510s\n",
      "\titers: 200, epoch: 8 | loss: 0.6778051\n",
      "\tspeed: 0.0103s/iter; left time: 27.3330s\n",
      "\titers: 300, epoch: 8 | loss: 0.5981799\n",
      "\tspeed: 0.0296s/iter; left time: 75.3177s\n",
      "\titers: 400, epoch: 8 | loss: 0.5621905\n",
      "\tspeed: 0.0116s/iter; left time: 28.4812s\n",
      "\titers: 500, epoch: 8 | loss: 0.5736527\n",
      "\tspeed: 0.0142s/iter; left time: 33.3095s\n",
      "\titers: 600, epoch: 8 | loss: 0.5162713\n",
      "\tspeed: 0.0374s/iter; left time: 83.9744s\n",
      "\titers: 700, epoch: 8 | loss: 0.4838111\n",
      "\tspeed: 0.0042s/iter; left time: 9.0238s\n",
      "\titers: 800, epoch: 8 | loss: 0.6291067\n",
      "\tspeed: 0.0185s/iter; left time: 37.8889s\n",
      "\titers: 900, epoch: 8 | loss: 0.6566915\n",
      "\tspeed: 0.0228s/iter; left time: 44.4640s\n",
      "Epoch: 8 cost time: 17.71017050743103\n",
      "Epoch: 8, Steps: 949 | Train Loss: 0.5730875 Vali Loss: 0.8800685 Test Loss: 1.2781178\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.6309643\n",
      "\tspeed: 0.3125s/iter; left time: 562.2716s\n",
      "\titers: 200, epoch: 9 | loss: 0.5576715\n",
      "\tspeed: 0.0267s/iter; left time: 45.3123s\n",
      "\titers: 300, epoch: 9 | loss: 0.6006632\n",
      "\tspeed: 0.0320s/iter; left time: 51.1276s\n",
      "\titers: 400, epoch: 9 | loss: 0.6357015\n",
      "\tspeed: 0.0039s/iter; left time: 5.7908s\n",
      "\titers: 500, epoch: 9 | loss: 0.5935329\n",
      "\tspeed: 0.0382s/iter; left time: 53.3892s\n",
      "\titers: 600, epoch: 9 | loss: 0.5872557\n",
      "\tspeed: 0.0224s/iter; left time: 29.0605s\n",
      "\titers: 700, epoch: 9 | loss: 0.5478910\n",
      "\tspeed: 0.0041s/iter; left time: 4.8630s\n",
      "\titers: 800, epoch: 9 | loss: 0.5119638\n",
      "\tspeed: 0.0232s/iter; left time: 25.5441s\n",
      "\titers: 900, epoch: 9 | loss: 0.6167104\n",
      "\tspeed: 0.0308s/iter; left time: 30.7969s\n",
      "Epoch: 9 cost time: 20.069897174835205\n",
      "Epoch: 9, Steps: 949 | Train Loss: 0.5730654 Vali Loss: 0.8791109 Test Loss: 1.2779485\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 29) (8567, 1, 192, 29)\n",
      "test shape: (8567, 192, 29) (8567, 192, 29)\n",
      "mse:1.2739810943603516, mae:0.8100464940071106\n",
      "\n",
      "Extracted Part: long_term_forecast__192_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__192_df_all_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=3, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=3, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=3, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_24_df_most_important_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=24, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.5649291\n",
      "\tspeed: 0.0126s/iter; left time: 118.7323s\n",
      "\titers: 200, epoch: 1 | loss: 0.4344932\n",
      "\tspeed: 0.0043s/iter; left time: 39.9337s\n",
      "\titers: 300, epoch: 1 | loss: 0.3475446\n",
      "\tspeed: 0.0038s/iter; left time: 35.1376s\n",
      "\titers: 400, epoch: 1 | loss: 0.3639378\n",
      "\tspeed: 0.0039s/iter; left time: 35.9600s\n",
      "\titers: 500, epoch: 1 | loss: 0.3564283\n",
      "\tspeed: 0.0041s/iter; left time: 37.0116s\n",
      "\titers: 600, epoch: 1 | loss: 0.4071647\n",
      "\tspeed: 0.0042s/iter; left time: 37.8168s\n",
      "\titers: 700, epoch: 1 | loss: 0.3216216\n",
      "\tspeed: 0.0031s/iter; left time: 27.2715s\n",
      "\titers: 800, epoch: 1 | loss: 0.3333094\n",
      "\tspeed: 0.0035s/iter; left time: 30.6999s\n",
      "\titers: 900, epoch: 1 | loss: 0.2902330\n",
      "\tspeed: 0.0043s/iter; left time: 37.3969s\n",
      "Epoch: 1 cost time: 4.562222242355347\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.3844034 Vali Loss: 0.3505510 Test Loss: 0.4048974\n",
      "Validation loss decreased (inf --> 0.350551).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3159476\n",
      "\tspeed: 0.2260s/iter; left time: 1918.4204s\n",
      "\titers: 200, epoch: 2 | loss: 0.2619142\n",
      "\tspeed: 0.0042s/iter; left time: 34.9047s\n",
      "\titers: 300, epoch: 2 | loss: 0.3199750\n",
      "\tspeed: 0.0043s/iter; left time: 35.2471s\n",
      "\titers: 400, epoch: 2 | loss: 0.2979984\n",
      "\tspeed: 0.0040s/iter; left time: 32.8251s\n",
      "\titers: 500, epoch: 2 | loss: 0.3467621\n",
      "\tspeed: 0.0042s/iter; left time: 34.3433s\n",
      "\titers: 600, epoch: 2 | loss: 0.3552548\n",
      "\tspeed: 0.0042s/iter; left time: 33.5370s\n",
      "\titers: 700, epoch: 2 | loss: 0.3459911\n",
      "\tspeed: 0.0045s/iter; left time: 35.6440s\n",
      "\titers: 800, epoch: 2 | loss: 0.2192300\n",
      "\tspeed: 0.0044s/iter; left time: 34.1488s\n",
      "\titers: 900, epoch: 2 | loss: 0.2976035\n",
      "\tspeed: 0.0045s/iter; left time: 34.5214s\n",
      "Epoch: 2 cost time: 4.49843692779541\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.2884276 Vali Loss: 0.3252091 Test Loss: 0.3766881\n",
      "Validation loss decreased (0.350551 --> 0.325209).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3336061\n",
      "\tspeed: 0.2323s/iter; left time: 1750.1852s\n",
      "\titers: 200, epoch: 3 | loss: 0.2778234\n",
      "\tspeed: 0.0038s/iter; left time: 28.2420s\n",
      "\titers: 300, epoch: 3 | loss: 0.2364693\n",
      "\tspeed: 0.0032s/iter; left time: 23.3192s\n",
      "\titers: 400, epoch: 3 | loss: 0.3033659\n",
      "\tspeed: 0.0041s/iter; left time: 29.4602s\n",
      "\titers: 500, epoch: 3 | loss: 0.2797276\n",
      "\tspeed: 0.0044s/iter; left time: 31.0793s\n",
      "\titers: 600, epoch: 3 | loss: 0.3424759\n",
      "\tspeed: 0.0044s/iter; left time: 31.2028s\n",
      "\titers: 700, epoch: 3 | loss: 0.2713056\n",
      "\tspeed: 0.0039s/iter; left time: 26.7693s\n",
      "\titers: 800, epoch: 3 | loss: 0.2377493\n",
      "\tspeed: 0.0040s/iter; left time: 27.0608s\n",
      "\titers: 900, epoch: 3 | loss: 0.2346266\n",
      "\tspeed: 0.0036s/iter; left time: 23.9217s\n",
      "Epoch: 3 cost time: 4.217016696929932\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.2765580 Vali Loss: 0.3180549 Test Loss: 0.3684038\n",
      "Validation loss decreased (0.325209 --> 0.318055).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2775852\n",
      "\tspeed: 0.2393s/iter; left time: 1574.2770s\n",
      "\titers: 200, epoch: 4 | loss: 0.1896365\n",
      "\tspeed: 0.0072s/iter; left time: 46.9242s\n",
      "\titers: 300, epoch: 4 | loss: 0.2669756\n",
      "\tspeed: 0.0046s/iter; left time: 29.0747s\n",
      "\titers: 400, epoch: 4 | loss: 0.2270399\n",
      "\tspeed: 0.0038s/iter; left time: 24.1149s\n",
      "\titers: 500, epoch: 4 | loss: 0.2441383\n",
      "\tspeed: 0.0033s/iter; left time: 20.4206s\n",
      "\titers: 600, epoch: 4 | loss: 0.2773022\n",
      "\tspeed: 0.0045s/iter; left time: 27.1332s\n",
      "\titers: 700, epoch: 4 | loss: 0.3131367\n",
      "\tspeed: 0.0040s/iter; left time: 23.6484s\n",
      "\titers: 800, epoch: 4 | loss: 0.2887701\n",
      "\tspeed: 0.0035s/iter; left time: 20.8187s\n",
      "\titers: 900, epoch: 4 | loss: 0.2792796\n",
      "\tspeed: 0.0046s/iter; left time: 26.5200s\n",
      "Epoch: 4 cost time: 5.111321210861206\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.2728651 Vali Loss: 0.3160514 Test Loss: 0.3652412\n",
      "Validation loss decreased (0.318055 --> 0.316051).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2753162\n",
      "\tspeed: 0.2489s/iter; left time: 1399.8399s\n",
      "\titers: 200, epoch: 5 | loss: 0.2160514\n",
      "\tspeed: 0.0043s/iter; left time: 23.9953s\n",
      "\titers: 300, epoch: 5 | loss: 0.2091457\n",
      "\tspeed: 0.0036s/iter; left time: 19.7211s\n",
      "\titers: 400, epoch: 5 | loss: 0.2156653\n",
      "\tspeed: 0.0041s/iter; left time: 21.9462s\n",
      "\titers: 500, epoch: 5 | loss: 0.2801885\n",
      "\tspeed: 0.0042s/iter; left time: 21.8667s\n",
      "\titers: 600, epoch: 5 | loss: 0.2984682\n",
      "\tspeed: 0.0046s/iter; left time: 23.7822s\n",
      "\titers: 700, epoch: 5 | loss: 0.2691831\n",
      "\tspeed: 0.0046s/iter; left time: 22.9690s\n",
      "\titers: 800, epoch: 5 | loss: 0.2717763\n",
      "\tspeed: 0.0043s/iter; left time: 20.9518s\n",
      "\titers: 900, epoch: 5 | loss: 0.3673374\n",
      "\tspeed: 0.0028s/iter; left time: 13.3226s\n",
      "Epoch: 5 cost time: 4.5444416999816895\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.2714462 Vali Loss: 0.3141751 Test Loss: 0.3639940\n",
      "Validation loss decreased (0.316051 --> 0.314175).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2875891\n",
      "\tspeed: 0.2556s/iter; left time: 1194.0358s\n",
      "\titers: 200, epoch: 6 | loss: 0.2440499\n",
      "\tspeed: 0.0048s/iter; left time: 22.0581s\n",
      "\titers: 300, epoch: 6 | loss: 0.2984364\n",
      "\tspeed: 0.0043s/iter; left time: 19.2081s\n",
      "\titers: 400, epoch: 6 | loss: 0.2158648\n",
      "\tspeed: 0.0049s/iter; left time: 21.5651s\n",
      "\titers: 500, epoch: 6 | loss: 0.2652418\n",
      "\tspeed: 0.0036s/iter; left time: 15.5204s\n",
      "\titers: 600, epoch: 6 | loss: 0.2473775\n",
      "\tspeed: 0.0045s/iter; left time: 18.5758s\n",
      "\titers: 700, epoch: 6 | loss: 0.3101393\n",
      "\tspeed: 0.0042s/iter; left time: 17.2928s\n",
      "\titers: 800, epoch: 6 | loss: 0.2879519\n",
      "\tspeed: 0.0040s/iter; left time: 16.0695s\n",
      "\titers: 900, epoch: 6 | loss: 0.2505571\n",
      "\tspeed: 0.0046s/iter; left time: 17.9193s\n",
      "Epoch: 6 cost time: 4.810804843902588\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.2707388 Vali Loss: 0.3144524 Test Loss: 0.3638014\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3811579\n",
      "\tspeed: 0.2529s/iter; left time: 940.1423s\n",
      "\titers: 200, epoch: 7 | loss: 0.2067435\n",
      "\tspeed: 0.0040s/iter; left time: 14.4050s\n",
      "\titers: 300, epoch: 7 | loss: 0.2404372\n",
      "\tspeed: 0.0043s/iter; left time: 15.0467s\n",
      "\titers: 400, epoch: 7 | loss: 0.2382314\n",
      "\tspeed: 0.0042s/iter; left time: 14.3838s\n",
      "\titers: 500, epoch: 7 | loss: 0.2231297\n",
      "\tspeed: 0.0039s/iter; left time: 12.8050s\n",
      "\titers: 600, epoch: 7 | loss: 0.2453893\n",
      "\tspeed: 0.0040s/iter; left time: 12.8180s\n",
      "\titers: 700, epoch: 7 | loss: 0.2478337\n",
      "\tspeed: 0.0031s/iter; left time: 9.5221s\n",
      "\titers: 800, epoch: 7 | loss: 0.2215373\n",
      "\tspeed: 0.0039s/iter; left time: 11.6364s\n",
      "\titers: 900, epoch: 7 | loss: 0.2695889\n",
      "\tspeed: 0.0035s/iter; left time: 10.2725s\n",
      "Epoch: 7 cost time: 4.3688576221466064\n",
      "Epoch: 7, Steps: 954 | Train Loss: 0.2703998 Vali Loss: 0.3138879 Test Loss: 0.3635324\n",
      "Validation loss decreased (0.314175 --> 0.313888).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2445943\n",
      "\tspeed: 0.2304s/iter; left time: 636.6869s\n",
      "\titers: 200, epoch: 8 | loss: 0.3533172\n",
      "\tspeed: 0.0049s/iter; left time: 13.1291s\n",
      "\titers: 300, epoch: 8 | loss: 0.2664070\n",
      "\tspeed: 0.0045s/iter; left time: 11.5948s\n",
      "\titers: 400, epoch: 8 | loss: 0.2515060\n",
      "\tspeed: 0.0037s/iter; left time: 9.2311s\n",
      "\titers: 500, epoch: 8 | loss: 0.1892574\n",
      "\tspeed: 0.0036s/iter; left time: 8.6167s\n",
      "\titers: 600, epoch: 8 | loss: 0.2652540\n",
      "\tspeed: 0.0042s/iter; left time: 9.3922s\n",
      "\titers: 700, epoch: 8 | loss: 0.2549227\n",
      "\tspeed: 0.0031s/iter; left time: 6.7684s\n",
      "\titers: 800, epoch: 8 | loss: 0.2353481\n",
      "\tspeed: 0.0042s/iter; left time: 8.7133s\n",
      "\titers: 900, epoch: 8 | loss: 0.2796791\n",
      "\tspeed: 0.0041s/iter; left time: 7.9833s\n",
      "Epoch: 8 cost time: 4.248951435089111\n",
      "Epoch: 8, Steps: 954 | Train Loss: 0.2702606 Vali Loss: 0.3138194 Test Loss: 0.3633203\n",
      "Validation loss decreased (0.313888 --> 0.313819).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2816288\n",
      "\tspeed: 0.2442s/iter; left time: 441.7242s\n",
      "\titers: 200, epoch: 9 | loss: 0.2420102\n",
      "\tspeed: 0.0039s/iter; left time: 6.6781s\n",
      "\titers: 300, epoch: 9 | loss: 0.3032297\n",
      "\tspeed: 0.0040s/iter; left time: 6.4612s\n",
      "\titers: 400, epoch: 9 | loss: 0.2228847\n",
      "\tspeed: 0.0041s/iter; left time: 6.2591s\n",
      "\titers: 500, epoch: 9 | loss: 0.3140182\n",
      "\tspeed: 0.0043s/iter; left time: 5.9983s\n",
      "\titers: 600, epoch: 9 | loss: 0.3273507\n",
      "\tspeed: 0.0047s/iter; left time: 6.1906s\n",
      "\titers: 700, epoch: 9 | loss: 0.3070334\n",
      "\tspeed: 0.0038s/iter; left time: 4.5811s\n",
      "\titers: 800, epoch: 9 | loss: 0.2518920\n",
      "\tspeed: 0.0039s/iter; left time: 4.3010s\n",
      "\titers: 900, epoch: 9 | loss: 0.2204683\n",
      "\tspeed: 0.0043s/iter; left time: 4.3763s\n",
      "Epoch: 9 cost time: 4.650211572647095\n",
      "Epoch: 9, Steps: 954 | Train Loss: 0.2701191 Vali Loss: 0.3138024 Test Loss: 0.3632525\n",
      "Validation loss decreased (0.313819 --> 0.313802).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2647845\n",
      "\tspeed: 0.2512s/iter; left time: 214.7717s\n",
      "\titers: 200, epoch: 10 | loss: 0.2695982\n",
      "\tspeed: 0.0052s/iter; left time: 3.9350s\n",
      "\titers: 300, epoch: 10 | loss: 0.2882809\n",
      "\tspeed: 0.0046s/iter; left time: 2.9874s\n",
      "\titers: 400, epoch: 10 | loss: 0.2467038\n",
      "\tspeed: 0.0040s/iter; left time: 2.2253s\n",
      "\titers: 500, epoch: 10 | loss: 0.2661532\n",
      "\tspeed: 0.0041s/iter; left time: 1.8579s\n",
      "\titers: 600, epoch: 10 | loss: 0.2877898\n",
      "\tspeed: 0.0028s/iter; left time: 0.9828s\n",
      "\titers: 700, epoch: 10 | loss: 0.2715085\n",
      "\tspeed: 0.0043s/iter; left time: 1.0887s\n",
      "\titers: 800, epoch: 10 | loss: 0.2236114\n",
      "\tspeed: 0.0059s/iter; left time: 0.9178s\n",
      "\titers: 900, epoch: 10 | loss: 0.2212952\n",
      "\tspeed: 0.0043s/iter; left time: 0.2381s\n",
      "Epoch: 10 cost time: 4.676373481750488\n",
      "Epoch: 10, Steps: 954 | Train Loss: 0.2701036 Vali Loss: 0.3133961 Test Loss: 0.3632098\n",
      "Validation loss decreased (0.313802 --> 0.313396).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__24_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 3) (8735, 1, 24, 3)\n",
      "test shape: (8735, 24, 3) (8735, 24, 3)\n",
      "mse:0.3632097542285919, mae:0.4098028540611267\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.5241695\n",
      "\tspeed: 0.0114s/iter; left time: 108.0298s\n",
      "\titers: 200, epoch: 1 | loss: 0.4470467\n",
      "\tspeed: 0.0035s/iter; left time: 32.4351s\n",
      "\titers: 300, epoch: 1 | loss: 0.4264511\n",
      "\tspeed: 0.0043s/iter; left time: 39.7124s\n",
      "\titers: 400, epoch: 1 | loss: 0.2943478\n",
      "\tspeed: 0.0045s/iter; left time: 41.1778s\n",
      "\titers: 500, epoch: 1 | loss: 0.3686642\n",
      "\tspeed: 0.0041s/iter; left time: 36.6291s\n",
      "\titers: 600, epoch: 1 | loss: 0.2819323\n",
      "\tspeed: 0.0043s/iter; left time: 38.1081s\n",
      "\titers: 700, epoch: 1 | loss: 0.3649096\n",
      "\tspeed: 0.0043s/iter; left time: 37.9035s\n",
      "\titers: 800, epoch: 1 | loss: 0.2590094\n",
      "\tspeed: 0.0038s/iter; left time: 32.9105s\n",
      "\titers: 900, epoch: 1 | loss: 0.2776882\n",
      "\tspeed: 0.0046s/iter; left time: 39.5144s\n",
      "Epoch: 1 cost time: 4.761610269546509\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.3832757 Vali Loss: 0.3499306 Test Loss: 0.4022302\n",
      "Validation loss decreased (inf --> 0.349931).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3166883\n",
      "\tspeed: 0.2760s/iter; left time: 2342.3181s\n",
      "\titers: 200, epoch: 2 | loss: 0.3681630\n",
      "\tspeed: 0.0036s/iter; left time: 30.2092s\n",
      "\titers: 300, epoch: 2 | loss: 0.2920911\n",
      "\tspeed: 0.0043s/iter; left time: 35.5826s\n",
      "\titers: 400, epoch: 2 | loss: 0.2493393\n",
      "\tspeed: 0.0044s/iter; left time: 36.1258s\n",
      "\titers: 500, epoch: 2 | loss: 0.2141585\n",
      "\tspeed: 0.0035s/iter; left time: 27.9316s\n",
      "\titers: 600, epoch: 2 | loss: 0.2928536\n",
      "\tspeed: 0.0040s/iter; left time: 32.1820s\n",
      "\titers: 700, epoch: 2 | loss: 0.2819700\n",
      "\tspeed: 0.0045s/iter; left time: 35.6164s\n",
      "\titers: 800, epoch: 2 | loss: 0.2576062\n",
      "\tspeed: 0.0033s/iter; left time: 25.5817s\n",
      "\titers: 900, epoch: 2 | loss: 0.3033564\n",
      "\tspeed: 0.0040s/iter; left time: 30.4898s\n",
      "Epoch: 2 cost time: 4.553012132644653\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.2882844 Vali Loss: 0.3251486 Test Loss: 0.3770411\n",
      "Validation loss decreased (0.349931 --> 0.325149).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2291120\n",
      "\tspeed: 0.2686s/iter; left time: 2023.0242s\n",
      "\titers: 200, epoch: 3 | loss: 0.2837096\n",
      "\tspeed: 0.0038s/iter; left time: 28.2254s\n",
      "\titers: 300, epoch: 3 | loss: 0.2768014\n",
      "\tspeed: 0.0038s/iter; left time: 28.0980s\n",
      "\titers: 400, epoch: 3 | loss: 0.3193339\n",
      "\tspeed: 0.0040s/iter; left time: 29.1428s\n",
      "\titers: 500, epoch: 3 | loss: 0.2741933\n",
      "\tspeed: 0.0044s/iter; left time: 31.1837s\n",
      "\titers: 600, epoch: 3 | loss: 0.3603616\n",
      "\tspeed: 0.0041s/iter; left time: 29.0125s\n",
      "\titers: 700, epoch: 3 | loss: 0.2628143\n",
      "\tspeed: 0.0036s/iter; left time: 24.9122s\n",
      "\titers: 800, epoch: 3 | loss: 0.2924534\n",
      "\tspeed: 0.0047s/iter; left time: 32.0413s\n",
      "\titers: 900, epoch: 3 | loss: 0.3953549\n",
      "\tspeed: 0.0041s/iter; left time: 27.4692s\n",
      "Epoch: 3 cost time: 4.968858242034912\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.2765918 Vali Loss: 0.3191511 Test Loss: 0.3702883\n",
      "Validation loss decreased (0.325149 --> 0.319151).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3704593\n",
      "\tspeed: 0.2559s/iter; left time: 1683.5981s\n",
      "\titers: 200, epoch: 4 | loss: 0.3169901\n",
      "\tspeed: 0.0039s/iter; left time: 25.3729s\n",
      "\titers: 300, epoch: 4 | loss: 0.3395526\n",
      "\tspeed: 0.0038s/iter; left time: 24.1515s\n",
      "\titers: 400, epoch: 4 | loss: 0.2347777\n",
      "\tspeed: 0.0040s/iter; left time: 24.9320s\n",
      "\titers: 500, epoch: 4 | loss: 0.2216666\n",
      "\tspeed: 0.0040s/iter; left time: 24.5085s\n",
      "\titers: 600, epoch: 4 | loss: 0.2793914\n",
      "\tspeed: 0.0038s/iter; left time: 23.3556s\n",
      "\titers: 700, epoch: 4 | loss: 0.2818891\n",
      "\tspeed: 0.0033s/iter; left time: 19.4388s\n",
      "\titers: 800, epoch: 4 | loss: 0.2372089\n",
      "\tspeed: 0.0036s/iter; left time: 21.1765s\n",
      "\titers: 900, epoch: 4 | loss: 0.3001018\n",
      "\tspeed: 0.0046s/iter; left time: 26.3491s\n",
      "Epoch: 4 cost time: 4.388867378234863\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.2729830 Vali Loss: 0.3159948 Test Loss: 0.3657596\n",
      "Validation loss decreased (0.319151 --> 0.315995).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3843496\n",
      "\tspeed: 0.2508s/iter; left time: 1410.7589s\n",
      "\titers: 200, epoch: 5 | loss: 0.2670099\n",
      "\tspeed: 0.0049s/iter; left time: 27.0236s\n",
      "\titers: 300, epoch: 5 | loss: 0.2512964\n",
      "\tspeed: 0.0049s/iter; left time: 26.7240s\n",
      "\titers: 400, epoch: 5 | loss: 0.2433633\n",
      "\tspeed: 0.0056s/iter; left time: 29.5971s\n",
      "\titers: 500, epoch: 5 | loss: 0.2813548\n",
      "\tspeed: 0.0032s/iter; left time: 16.9148s\n",
      "\titers: 600, epoch: 5 | loss: 0.2606401\n",
      "\tspeed: 0.0036s/iter; left time: 18.7048s\n",
      "\titers: 700, epoch: 5 | loss: 0.3691440\n",
      "\tspeed: 0.0037s/iter; left time: 18.6115s\n",
      "\titers: 800, epoch: 5 | loss: 0.3423695\n",
      "\tspeed: 0.0051s/iter; left time: 25.1942s\n",
      "\titers: 900, epoch: 5 | loss: 0.2855386\n",
      "\tspeed: 0.0047s/iter; left time: 22.7550s\n",
      "Epoch: 5 cost time: 5.097625494003296\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.2714717 Vali Loss: 0.3146165 Test Loss: 0.3641263\n",
      "Validation loss decreased (0.315995 --> 0.314617).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3183233\n",
      "\tspeed: 0.2637s/iter; left time: 1231.8143s\n",
      "\titers: 200, epoch: 6 | loss: 0.2919273\n",
      "\tspeed: 0.0043s/iter; left time: 19.4975s\n",
      "\titers: 300, epoch: 6 | loss: 0.2787233\n",
      "\tspeed: 0.0042s/iter; left time: 18.9289s\n",
      "\titers: 400, epoch: 6 | loss: 0.2366362\n",
      "\tspeed: 0.0048s/iter; left time: 20.9807s\n",
      "\titers: 500, epoch: 6 | loss: 0.2532217\n",
      "\tspeed: 0.0038s/iter; left time: 16.4317s\n",
      "\titers: 600, epoch: 6 | loss: 0.3065977\n",
      "\tspeed: 0.0033s/iter; left time: 13.8921s\n",
      "\titers: 700, epoch: 6 | loss: 0.2734644\n",
      "\tspeed: 0.0041s/iter; left time: 16.5933s\n",
      "\titers: 800, epoch: 6 | loss: 0.3161458\n",
      "\tspeed: 0.0050s/iter; left time: 19.8147s\n",
      "\titers: 900, epoch: 6 | loss: 0.2451928\n",
      "\tspeed: 0.0040s/iter; left time: 15.4645s\n",
      "Epoch: 6 cost time: 4.610977411270142\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.2707869 Vali Loss: 0.3141659 Test Loss: 0.3635370\n",
      "Validation loss decreased (0.314617 --> 0.314166).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2430947\n",
      "\tspeed: 0.2095s/iter; left time: 778.6391s\n",
      "\titers: 200, epoch: 7 | loss: 0.2584682\n",
      "\tspeed: 0.0042s/iter; left time: 15.0551s\n",
      "\titers: 300, epoch: 7 | loss: 0.1936294\n",
      "\tspeed: 0.0051s/iter; left time: 17.8601s\n",
      "\titers: 400, epoch: 7 | loss: 0.3025993\n",
      "\tspeed: 0.0045s/iter; left time: 15.2810s\n",
      "\titers: 500, epoch: 7 | loss: 0.2514590\n",
      "\tspeed: 0.0033s/iter; left time: 10.8646s\n",
      "\titers: 600, epoch: 7 | loss: 0.2865775\n",
      "\tspeed: 0.0039s/iter; left time: 12.5121s\n",
      "\titers: 700, epoch: 7 | loss: 0.2288323\n",
      "\tspeed: 0.0035s/iter; left time: 10.7630s\n",
      "\titers: 800, epoch: 7 | loss: 0.2623269\n",
      "\tspeed: 0.0037s/iter; left time: 11.2011s\n",
      "\titers: 900, epoch: 7 | loss: 0.3345537\n",
      "\tspeed: 0.0038s/iter; left time: 11.0796s\n",
      "Epoch: 7 cost time: 4.4299468994140625\n",
      "Epoch: 7, Steps: 954 | Train Loss: 0.2704484 Vali Loss: 0.3138435 Test Loss: 0.3634461\n",
      "Validation loss decreased (0.314166 --> 0.313844).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2232896\n",
      "\tspeed: 0.2111s/iter; left time: 583.1890s\n",
      "\titers: 200, epoch: 8 | loss: 0.3197750\n",
      "\tspeed: 0.0031s/iter; left time: 8.3274s\n",
      "\titers: 300, epoch: 8 | loss: 0.3589851\n",
      "\tspeed: 0.0036s/iter; left time: 9.2650s\n",
      "\titers: 400, epoch: 8 | loss: 0.2371247\n",
      "\tspeed: 0.0034s/iter; left time: 8.2710s\n",
      "\titers: 500, epoch: 8 | loss: 0.2256419\n",
      "\tspeed: 0.0034s/iter; left time: 8.0948s\n",
      "\titers: 600, epoch: 8 | loss: 0.3058769\n",
      "\tspeed: 0.0034s/iter; left time: 7.6614s\n",
      "\titers: 700, epoch: 8 | loss: 0.2691728\n",
      "\tspeed: 0.0032s/iter; left time: 6.9069s\n",
      "\titers: 800, epoch: 8 | loss: 0.1984241\n",
      "\tspeed: 0.0030s/iter; left time: 6.2832s\n",
      "\titers: 900, epoch: 8 | loss: 0.2504999\n",
      "\tspeed: 0.0031s/iter; left time: 6.1511s\n",
      "Epoch: 8 cost time: 3.7434704303741455\n",
      "Epoch: 8, Steps: 954 | Train Loss: 0.2702671 Vali Loss: 0.3138322 Test Loss: 0.3632934\n",
      "Validation loss decreased (0.313844 --> 0.313832).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2861861\n",
      "\tspeed: 0.1989s/iter; left time: 359.8818s\n",
      "\titers: 200, epoch: 9 | loss: 0.2681449\n",
      "\tspeed: 0.0030s/iter; left time: 5.0740s\n",
      "\titers: 300, epoch: 9 | loss: 0.2439607\n",
      "\tspeed: 0.0029s/iter; left time: 4.6901s\n",
      "\titers: 400, epoch: 9 | loss: 0.2219133\n",
      "\tspeed: 0.0030s/iter; left time: 4.5813s\n",
      "\titers: 500, epoch: 9 | loss: 0.2919542\n",
      "\tspeed: 0.0029s/iter; left time: 4.0428s\n",
      "\titers: 600, epoch: 9 | loss: 0.2846240\n",
      "\tspeed: 0.0028s/iter; left time: 3.7285s\n",
      "\titers: 700, epoch: 9 | loss: 0.2745820\n",
      "\tspeed: 0.0028s/iter; left time: 3.4178s\n",
      "\titers: 800, epoch: 9 | loss: 0.2173990\n",
      "\tspeed: 0.0030s/iter; left time: 3.2995s\n",
      "\titers: 900, epoch: 9 | loss: 0.3386143\n",
      "\tspeed: 0.0028s/iter; left time: 2.8724s\n",
      "Epoch: 9 cost time: 3.3898682594299316\n",
      "Epoch: 9, Steps: 954 | Train Loss: 0.2701913 Vali Loss: 0.3138105 Test Loss: 0.3632444\n",
      "Validation loss decreased (0.313832 --> 0.313810).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2206071\n",
      "\tspeed: 0.1892s/iter; left time: 161.7299s\n",
      "\titers: 200, epoch: 10 | loss: 0.2197933\n",
      "\tspeed: 0.0034s/iter; left time: 2.5735s\n",
      "\titers: 300, epoch: 10 | loss: 0.2331544\n",
      "\tspeed: 0.0035s/iter; left time: 2.3093s\n",
      "\titers: 400, epoch: 10 | loss: 0.2642142\n",
      "\tspeed: 0.0043s/iter; left time: 2.3836s\n",
      "\titers: 500, epoch: 10 | loss: 0.2882536\n",
      "\tspeed: 0.0042s/iter; left time: 1.8898s\n",
      "\titers: 600, epoch: 10 | loss: 0.2241704\n",
      "\tspeed: 0.0042s/iter; left time: 1.4984s\n",
      "\titers: 700, epoch: 10 | loss: 0.2445943\n",
      "\tspeed: 0.0036s/iter; left time: 0.9160s\n",
      "\titers: 800, epoch: 10 | loss: 0.2707341\n",
      "\tspeed: 0.0030s/iter; left time: 0.4587s\n",
      "\titers: 900, epoch: 10 | loss: 0.2463283\n",
      "\tspeed: 0.0030s/iter; left time: 0.1631s\n",
      "Epoch: 10 cost time: 4.035002708435059\n",
      "Epoch: 10, Steps: 954 | Train Loss: 0.2701255 Vali Loss: 0.3136534 Test Loss: 0.3632146\n",
      "Validation loss decreased (0.313810 --> 0.313653).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__24_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 3) (8735, 1, 24, 3)\n",
      "test shape: (8735, 24, 3) (8735, 24, 3)\n",
      "mse:0.36321452260017395, mae:0.4098758399486542\n",
      "\n",
      "Extracted Part: long_term_forecast__24_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__24_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=3, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=3, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=3, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_48_df_most_important_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=48, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.6695442\n",
      "\tspeed: 0.0116s/iter; left time: 109.6127s\n",
      "\titers: 200, epoch: 1 | loss: 0.5083510\n",
      "\tspeed: 0.0049s/iter; left time: 45.4789s\n",
      "\titers: 300, epoch: 1 | loss: 0.5081122\n",
      "\tspeed: 0.0058s/iter; left time: 53.1425s\n",
      "\titers: 400, epoch: 1 | loss: 0.4340261\n",
      "\tspeed: 0.0056s/iter; left time: 51.4757s\n",
      "\titers: 500, epoch: 1 | loss: 0.3478800\n",
      "\tspeed: 0.0046s/iter; left time: 41.5774s\n",
      "\titers: 600, epoch: 1 | loss: 0.4313635\n",
      "\tspeed: 0.0051s/iter; left time: 45.7184s\n",
      "\titers: 700, epoch: 1 | loss: 0.4020737\n",
      "\tspeed: 0.0046s/iter; left time: 40.8568s\n",
      "\titers: 800, epoch: 1 | loss: 0.4156059\n",
      "\tspeed: 0.0050s/iter; left time: 43.8397s\n",
      "\titers: 900, epoch: 1 | loss: 0.3684657\n",
      "\tspeed: 0.0044s/iter; left time: 38.0722s\n",
      "Epoch: 1 cost time: 5.42598819732666\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.4698183 Vali Loss: 0.4596010 Test Loss: 0.5340716\n",
      "Validation loss decreased (inf --> 0.459601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4602184\n",
      "\tspeed: 0.2323s/iter; left time: 1969.6983s\n",
      "\titers: 200, epoch: 2 | loss: 0.3615978\n",
      "\tspeed: 0.0046s/iter; left time: 38.6477s\n",
      "\titers: 300, epoch: 2 | loss: 0.2976266\n",
      "\tspeed: 0.0047s/iter; left time: 39.0123s\n",
      "\titers: 400, epoch: 2 | loss: 0.4233715\n",
      "\tspeed: 0.0044s/iter; left time: 36.0996s\n",
      "\titers: 500, epoch: 2 | loss: 0.4381317\n",
      "\tspeed: 0.0044s/iter; left time: 35.9454s\n",
      "\titers: 600, epoch: 2 | loss: 0.3512861\n",
      "\tspeed: 0.0043s/iter; left time: 34.2543s\n",
      "\titers: 700, epoch: 2 | loss: 0.3895432\n",
      "\tspeed: 0.0044s/iter; left time: 34.7749s\n",
      "\titers: 800, epoch: 2 | loss: 0.3677114\n",
      "\tspeed: 0.0047s/iter; left time: 36.7126s\n",
      "\titers: 900, epoch: 2 | loss: 0.3560131\n",
      "\tspeed: 0.0046s/iter; left time: 35.4705s\n",
      "Epoch: 2 cost time: 4.595116138458252\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.3914420 Vali Loss: 0.4421902 Test Loss: 0.5150215\n",
      "Validation loss decreased (0.459601 --> 0.442190).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4304243\n",
      "\tspeed: 0.2230s/iter; left time: 1678.1183s\n",
      "\titers: 200, epoch: 3 | loss: 0.3354222\n",
      "\tspeed: 0.0047s/iter; left time: 35.0768s\n",
      "\titers: 300, epoch: 3 | loss: 0.3285944\n",
      "\tspeed: 0.0049s/iter; left time: 35.6844s\n",
      "\titers: 400, epoch: 3 | loss: 0.4469893\n",
      "\tspeed: 0.0046s/iter; left time: 33.3081s\n",
      "\titers: 500, epoch: 3 | loss: 0.3592949\n",
      "\tspeed: 0.0048s/iter; left time: 33.8917s\n",
      "\titers: 600, epoch: 3 | loss: 0.3382647\n",
      "\tspeed: 0.0049s/iter; left time: 34.4979s\n",
      "\titers: 700, epoch: 3 | loss: 0.4029591\n",
      "\tspeed: 0.0049s/iter; left time: 34.0285s\n",
      "\titers: 800, epoch: 3 | loss: 0.3361446\n",
      "\tspeed: 0.0046s/iter; left time: 31.4607s\n",
      "\titers: 900, epoch: 3 | loss: 0.3683013\n",
      "\tspeed: 0.0048s/iter; left time: 32.5670s\n",
      "Epoch: 3 cost time: 4.859874248504639\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.3832325 Vali Loss: 0.4388527 Test Loss: 0.5114282\n",
      "Validation loss decreased (0.442190 --> 0.438853).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3621445\n",
      "\tspeed: 0.2249s/iter; left time: 1477.9707s\n",
      "\titers: 200, epoch: 4 | loss: 0.3591920\n",
      "\tspeed: 0.0046s/iter; left time: 29.4824s\n",
      "\titers: 300, epoch: 4 | loss: 0.3467677\n",
      "\tspeed: 0.0048s/iter; left time: 30.5050s\n",
      "\titers: 400, epoch: 4 | loss: 0.3334418\n",
      "\tspeed: 0.0047s/iter; left time: 29.3810s\n",
      "\titers: 500, epoch: 4 | loss: 0.4138473\n",
      "\tspeed: 0.0048s/iter; left time: 29.7067s\n",
      "\titers: 600, epoch: 4 | loss: 0.3648972\n",
      "\tspeed: 0.0046s/iter; left time: 27.9234s\n",
      "\titers: 700, epoch: 4 | loss: 0.3679643\n",
      "\tspeed: 0.0047s/iter; left time: 28.0048s\n",
      "\titers: 800, epoch: 4 | loss: 0.3826341\n",
      "\tspeed: 0.0046s/iter; left time: 27.1976s\n",
      "\titers: 900, epoch: 4 | loss: 0.3720850\n",
      "\tspeed: 0.0048s/iter; left time: 27.6103s\n",
      "Epoch: 4 cost time: 4.843790054321289\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.3805666 Vali Loss: 0.4366500 Test Loss: 0.5088086\n",
      "Validation loss decreased (0.438853 --> 0.436650).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3668722\n",
      "\tspeed: 0.2257s/iter; left time: 1268.3903s\n",
      "\titers: 200, epoch: 5 | loss: 0.3885707\n",
      "\tspeed: 0.0048s/iter; left time: 26.5470s\n",
      "\titers: 300, epoch: 5 | loss: 0.4546503\n",
      "\tspeed: 0.0059s/iter; left time: 31.7505s\n",
      "\titers: 400, epoch: 5 | loss: 0.4065916\n",
      "\tspeed: 0.0065s/iter; left time: 34.6003s\n",
      "\titers: 500, epoch: 5 | loss: 0.3041668\n",
      "\tspeed: 0.0061s/iter; left time: 31.7255s\n",
      "\titers: 600, epoch: 5 | loss: 0.4212773\n",
      "\tspeed: 0.0058s/iter; left time: 29.5318s\n",
      "\titers: 700, epoch: 5 | loss: 0.4172812\n",
      "\tspeed: 0.0058s/iter; left time: 29.3255s\n",
      "\titers: 800, epoch: 5 | loss: 0.3192398\n",
      "\tspeed: 0.0062s/iter; left time: 30.6724s\n",
      "\titers: 900, epoch: 5 | loss: 0.3952116\n",
      "\tspeed: 0.0058s/iter; left time: 27.9533s\n",
      "Epoch: 5 cost time: 5.743211030960083\n",
      "Epoch: 5, Steps: 953 | Train Loss: 0.3795232 Vali Loss: 0.4355399 Test Loss: 0.5076181\n",
      "Validation loss decreased (0.436650 --> 0.435540).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3227426\n",
      "\tspeed: 0.2239s/iter; left time: 1044.4869s\n",
      "\titers: 200, epoch: 6 | loss: 0.3592637\n",
      "\tspeed: 0.0048s/iter; left time: 21.8713s\n",
      "\titers: 300, epoch: 6 | loss: 0.3142755\n",
      "\tspeed: 0.0046s/iter; left time: 20.6972s\n",
      "\titers: 400, epoch: 6 | loss: 0.4084866\n",
      "\tspeed: 0.0047s/iter; left time: 20.4612s\n",
      "\titers: 500, epoch: 6 | loss: 0.3519216\n",
      "\tspeed: 0.0047s/iter; left time: 20.0785s\n",
      "\titers: 600, epoch: 6 | loss: 0.3654469\n",
      "\tspeed: 0.0046s/iter; left time: 19.2306s\n",
      "\titers: 700, epoch: 6 | loss: 0.3620719\n",
      "\tspeed: 0.0046s/iter; left time: 18.7911s\n",
      "\titers: 800, epoch: 6 | loss: 0.4533243\n",
      "\tspeed: 0.0053s/iter; left time: 21.1595s\n",
      "\titers: 900, epoch: 6 | loss: 0.3998324\n",
      "\tspeed: 0.0050s/iter; left time: 19.3731s\n",
      "Epoch: 6 cost time: 4.937457799911499\n",
      "Epoch: 6, Steps: 953 | Train Loss: 0.3790695 Vali Loss: 0.4355597 Test Loss: 0.5076533\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3370800\n",
      "\tspeed: 0.2199s/iter; left time: 816.3309s\n",
      "\titers: 200, epoch: 7 | loss: 0.3225236\n",
      "\tspeed: 0.0046s/iter; left time: 16.7336s\n",
      "\titers: 300, epoch: 7 | loss: 0.3817839\n",
      "\tspeed: 0.0047s/iter; left time: 16.5883s\n",
      "\titers: 400, epoch: 7 | loss: 0.3312688\n",
      "\tspeed: 0.0047s/iter; left time: 16.0556s\n",
      "\titers: 500, epoch: 7 | loss: 0.3478500\n",
      "\tspeed: 0.0047s/iter; left time: 15.7219s\n",
      "\titers: 600, epoch: 7 | loss: 0.3909325\n",
      "\tspeed: 0.0049s/iter; left time: 15.7166s\n",
      "\titers: 700, epoch: 7 | loss: 0.3109375\n",
      "\tspeed: 0.0046s/iter; left time: 14.4052s\n",
      "\titers: 800, epoch: 7 | loss: 0.3188328\n",
      "\tspeed: 0.0047s/iter; left time: 14.0456s\n",
      "\titers: 900, epoch: 7 | loss: 0.4238644\n",
      "\tspeed: 0.0050s/iter; left time: 14.6381s\n",
      "Epoch: 7 cost time: 4.828157663345337\n",
      "Epoch: 7, Steps: 953 | Train Loss: 0.3787394 Vali Loss: 0.4355501 Test Loss: 0.5074760\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3996991\n",
      "\tspeed: 0.2284s/iter; left time: 630.4994s\n",
      "\titers: 200, epoch: 8 | loss: 0.3989358\n",
      "\tspeed: 0.0049s/iter; left time: 13.0855s\n",
      "\titers: 300, epoch: 8 | loss: 0.3856125\n",
      "\tspeed: 0.0047s/iter; left time: 12.0775s\n",
      "\titers: 400, epoch: 8 | loss: 0.3327017\n",
      "\tspeed: 0.0050s/iter; left time: 12.1940s\n",
      "\titers: 500, epoch: 8 | loss: 0.3616465\n",
      "\tspeed: 0.0052s/iter; left time: 12.3866s\n",
      "\titers: 600, epoch: 8 | loss: 0.3666105\n",
      "\tspeed: 0.0044s/iter; left time: 9.9888s\n",
      "\titers: 700, epoch: 8 | loss: 0.3744734\n",
      "\tspeed: 0.0049s/iter; left time: 10.6904s\n",
      "\titers: 800, epoch: 8 | loss: 0.3675046\n",
      "\tspeed: 0.0045s/iter; left time: 9.2956s\n",
      "\titers: 900, epoch: 8 | loss: 0.4099782\n",
      "\tspeed: 0.0045s/iter; left time: 8.8012s\n",
      "Epoch: 8 cost time: 4.818526029586792\n",
      "Epoch: 8, Steps: 953 | Train Loss: 0.3786702 Vali Loss: 0.4352970 Test Loss: 0.5073752\n",
      "Validation loss decreased (0.435540 --> 0.435297).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.3389564\n",
      "\tspeed: 0.2267s/iter; left time: 409.6943s\n",
      "\titers: 200, epoch: 9 | loss: 0.4290912\n",
      "\tspeed: 0.0048s/iter; left time: 8.1863s\n",
      "\titers: 300, epoch: 9 | loss: 0.3062594\n",
      "\tspeed: 0.0046s/iter; left time: 7.4520s\n",
      "\titers: 400, epoch: 9 | loss: 0.3024665\n",
      "\tspeed: 0.0048s/iter; left time: 7.1953s\n",
      "\titers: 500, epoch: 9 | loss: 0.3339422\n",
      "\tspeed: 0.0045s/iter; left time: 6.3770s\n",
      "\titers: 600, epoch: 9 | loss: 0.2965822\n",
      "\tspeed: 0.0047s/iter; left time: 6.1863s\n",
      "\titers: 700, epoch: 9 | loss: 0.3922484\n",
      "\tspeed: 0.0047s/iter; left time: 5.6240s\n",
      "\titers: 800, epoch: 9 | loss: 0.3753959\n",
      "\tspeed: 0.0048s/iter; left time: 5.3559s\n",
      "\titers: 900, epoch: 9 | loss: 0.4580540\n",
      "\tspeed: 0.0048s/iter; left time: 4.8536s\n",
      "Epoch: 9 cost time: 4.912511825561523\n",
      "Epoch: 9, Steps: 953 | Train Loss: 0.3786239 Vali Loss: 0.4350931 Test Loss: 0.5073102\n",
      "Validation loss decreased (0.435297 --> 0.435093).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2986507\n",
      "\tspeed: 0.2179s/iter; left time: 186.1049s\n",
      "\titers: 200, epoch: 10 | loss: 0.3429589\n",
      "\tspeed: 0.0049s/iter; left time: 3.6690s\n",
      "\titers: 300, epoch: 10 | loss: 0.3348576\n",
      "\tspeed: 0.0048s/iter; left time: 3.1345s\n",
      "\titers: 400, epoch: 10 | loss: 0.4101371\n",
      "\tspeed: 0.0032s/iter; left time: 1.7796s\n",
      "\titers: 500, epoch: 10 | loss: 0.3659053\n",
      "\tspeed: 0.0029s/iter; left time: 1.3329s\n",
      "\titers: 600, epoch: 10 | loss: 0.4080626\n",
      "\tspeed: 0.0029s/iter; left time: 1.0255s\n",
      "\titers: 700, epoch: 10 | loss: 0.2828461\n",
      "\tspeed: 0.0029s/iter; left time: 0.7319s\n",
      "\titers: 800, epoch: 10 | loss: 0.3118666\n",
      "\tspeed: 0.0031s/iter; left time: 0.4778s\n",
      "\titers: 900, epoch: 10 | loss: 0.3704010\n",
      "\tspeed: 0.0027s/iter; left time: 0.1443s\n",
      "Epoch: 10 cost time: 3.710179328918457\n",
      "Epoch: 10, Steps: 953 | Train Loss: 0.3785481 Vali Loss: 0.4350919 Test Loss: 0.5072773\n",
      "Validation loss decreased (0.435093 --> 0.435092).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__48_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 3) (8711, 1, 48, 3)\n",
      "test shape: (8711, 48, 3) (8711, 48, 3)\n",
      "mse:0.5072773694992065, mae:0.4964156150817871\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.5881717\n",
      "\tspeed: 0.0087s/iter; left time: 81.5979s\n",
      "\titers: 200, epoch: 1 | loss: 0.4759251\n",
      "\tspeed: 0.0033s/iter; left time: 30.6972s\n",
      "\titers: 300, epoch: 1 | loss: 0.3470285\n",
      "\tspeed: 0.0040s/iter; left time: 36.9915s\n",
      "\titers: 400, epoch: 1 | loss: 0.4451419\n",
      "\tspeed: 0.0034s/iter; left time: 30.9275s\n",
      "\titers: 500, epoch: 1 | loss: 0.4086084\n",
      "\tspeed: 0.0046s/iter; left time: 41.8651s\n",
      "\titers: 600, epoch: 1 | loss: 0.4019609\n",
      "\tspeed: 0.0052s/iter; left time: 46.1952s\n",
      "\titers: 700, epoch: 1 | loss: 0.4018760\n",
      "\tspeed: 0.0039s/iter; left time: 34.4140s\n",
      "\titers: 800, epoch: 1 | loss: 0.3887506\n",
      "\tspeed: 0.0035s/iter; left time: 30.1860s\n",
      "\titers: 900, epoch: 1 | loss: 0.4852002\n",
      "\tspeed: 0.0035s/iter; left time: 30.0617s\n",
      "Epoch: 1 cost time: 4.281886339187622\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.4693992 Vali Loss: 0.4610954 Test Loss: 0.5369126\n",
      "Validation loss decreased (inf --> 0.461095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3938169\n",
      "\tspeed: 0.2066s/iter; left time: 1751.6173s\n",
      "\titers: 200, epoch: 2 | loss: 0.3924574\n",
      "\tspeed: 0.0030s/iter; left time: 25.1969s\n",
      "\titers: 300, epoch: 2 | loss: 0.3622039\n",
      "\tspeed: 0.0031s/iter; left time: 25.9561s\n",
      "\titers: 400, epoch: 2 | loss: 0.4361795\n",
      "\tspeed: 0.0034s/iter; left time: 28.1995s\n",
      "\titers: 500, epoch: 2 | loss: 0.3330298\n",
      "\tspeed: 0.0033s/iter; left time: 26.8518s\n",
      "\titers: 600, epoch: 2 | loss: 0.3448246\n",
      "\tspeed: 0.0037s/iter; left time: 29.6454s\n",
      "\titers: 700, epoch: 2 | loss: 0.4003654\n",
      "\tspeed: 0.0035s/iter; left time: 27.6275s\n",
      "\titers: 800, epoch: 2 | loss: 0.3316648\n",
      "\tspeed: 0.0034s/iter; left time: 26.5446s\n",
      "\titers: 900, epoch: 2 | loss: 0.3924618\n",
      "\tspeed: 0.0033s/iter; left time: 25.4295s\n",
      "Epoch: 2 cost time: 3.821727991104126\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.3912996 Vali Loss: 0.4430696 Test Loss: 0.5176356\n",
      "Validation loss decreased (0.461095 --> 0.443070).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4306332\n",
      "\tspeed: 0.1960s/iter; left time: 1474.7885s\n",
      "\titers: 200, epoch: 3 | loss: 0.4224650\n",
      "\tspeed: 0.0042s/iter; left time: 31.1838s\n",
      "\titers: 300, epoch: 3 | loss: 0.3305871\n",
      "\tspeed: 0.0041s/iter; left time: 30.2608s\n",
      "\titers: 400, epoch: 3 | loss: 0.3799008\n",
      "\tspeed: 0.0037s/iter; left time: 26.8652s\n",
      "\titers: 500, epoch: 3 | loss: 0.3860042\n",
      "\tspeed: 0.0033s/iter; left time: 23.5908s\n",
      "\titers: 600, epoch: 3 | loss: 0.3402222\n",
      "\tspeed: 0.0029s/iter; left time: 20.2362s\n",
      "\titers: 700, epoch: 3 | loss: 0.4571321\n",
      "\tspeed: 0.0027s/iter; left time: 18.8126s\n",
      "\titers: 800, epoch: 3 | loss: 0.4265193\n",
      "\tspeed: 0.0032s/iter; left time: 21.6602s\n",
      "\titers: 900, epoch: 3 | loss: 0.3924704\n",
      "\tspeed: 0.0032s/iter; left time: 21.4354s\n",
      "Epoch: 3 cost time: 3.8835835456848145\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.3831862 Vali Loss: 0.4389270 Test Loss: 0.5118620\n",
      "Validation loss decreased (0.443070 --> 0.438927).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4421860\n",
      "\tspeed: 0.1935s/iter; left time: 1271.8715s\n",
      "\titers: 200, epoch: 4 | loss: 0.4262811\n",
      "\tspeed: 0.0032s/iter; left time: 20.6463s\n",
      "\titers: 300, epoch: 4 | loss: 0.3267565\n",
      "\tspeed: 0.0032s/iter; left time: 20.2544s\n",
      "\titers: 400, epoch: 4 | loss: 0.3900005\n",
      "\tspeed: 0.0032s/iter; left time: 20.1888s\n",
      "\titers: 500, epoch: 4 | loss: 0.4495412\n",
      "\tspeed: 0.0033s/iter; left time: 20.0890s\n",
      "\titers: 600, epoch: 4 | loss: 0.3758648\n",
      "\tspeed: 0.0031s/iter; left time: 18.9915s\n",
      "\titers: 700, epoch: 4 | loss: 0.4199040\n",
      "\tspeed: 0.0036s/iter; left time: 21.4742s\n",
      "\titers: 800, epoch: 4 | loss: 0.3576439\n",
      "\tspeed: 0.0030s/iter; left time: 17.8158s\n",
      "\titers: 900, epoch: 4 | loss: 0.3728296\n",
      "\tspeed: 0.0031s/iter; left time: 17.9161s\n",
      "Epoch: 4 cost time: 3.72190260887146\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.3806454 Vali Loss: 0.4367361 Test Loss: 0.5090842\n",
      "Validation loss decreased (0.438927 --> 0.436736).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3266643\n",
      "\tspeed: 0.1964s/iter; left time: 1103.3393s\n",
      "\titers: 200, epoch: 5 | loss: 0.3653139\n",
      "\tspeed: 0.0042s/iter; left time: 23.0458s\n",
      "\titers: 300, epoch: 5 | loss: 0.4041225\n",
      "\tspeed: 0.0046s/iter; left time: 25.0646s\n",
      "\titers: 400, epoch: 5 | loss: 0.3566990\n",
      "\tspeed: 0.0054s/iter; left time: 28.6244s\n",
      "\titers: 500, epoch: 5 | loss: 0.3745586\n",
      "\tspeed: 0.0042s/iter; left time: 21.7484s\n",
      "\titers: 600, epoch: 5 | loss: 0.4143792\n",
      "\tspeed: 0.0042s/iter; left time: 21.2492s\n",
      "\titers: 700, epoch: 5 | loss: 0.3885082\n",
      "\tspeed: 0.0036s/iter; left time: 18.0329s\n",
      "\titers: 800, epoch: 5 | loss: 0.3525006\n",
      "\tspeed: 0.0032s/iter; left time: 15.6434s\n",
      "\titers: 900, epoch: 5 | loss: 0.3765783\n",
      "\tspeed: 0.0036s/iter; left time: 17.3921s\n",
      "Epoch: 5 cost time: 4.506773471832275\n",
      "Epoch: 5, Steps: 953 | Train Loss: 0.3795108 Vali Loss: 0.4349630 Test Loss: 0.5073813\n",
      "Validation loss decreased (0.436736 --> 0.434963).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3140434\n",
      "\tspeed: 0.1930s/iter; left time: 900.4181s\n",
      "\titers: 200, epoch: 6 | loss: 0.4149082\n",
      "\tspeed: 0.0034s/iter; left time: 15.5674s\n",
      "\titers: 300, epoch: 6 | loss: 0.4226266\n",
      "\tspeed: 0.0032s/iter; left time: 14.4013s\n",
      "\titers: 400, epoch: 6 | loss: 0.3480498\n",
      "\tspeed: 0.0035s/iter; left time: 15.1330s\n",
      "\titers: 500, epoch: 6 | loss: 0.3350725\n",
      "\tspeed: 0.0041s/iter; left time: 17.6069s\n",
      "\titers: 600, epoch: 6 | loss: 0.3616329\n",
      "\tspeed: 0.0034s/iter; left time: 14.1053s\n",
      "\titers: 700, epoch: 6 | loss: 0.3073423\n",
      "\tspeed: 0.0034s/iter; left time: 13.9239s\n",
      "\titers: 800, epoch: 6 | loss: 0.4123999\n",
      "\tspeed: 0.0041s/iter; left time: 16.3430s\n",
      "\titers: 900, epoch: 6 | loss: 0.4188646\n",
      "\tspeed: 0.0032s/iter; left time: 12.3141s\n",
      "Epoch: 6 cost time: 4.059579133987427\n",
      "Epoch: 6, Steps: 953 | Train Loss: 0.3790438 Vali Loss: 0.4357517 Test Loss: 0.5080319\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3624154\n",
      "\tspeed: 0.1982s/iter; left time: 736.0305s\n",
      "\titers: 200, epoch: 7 | loss: 0.4048328\n",
      "\tspeed: 0.0036s/iter; left time: 13.1655s\n",
      "\titers: 300, epoch: 7 | loss: 0.3787183\n",
      "\tspeed: 0.0035s/iter; left time: 12.2107s\n",
      "\titers: 400, epoch: 7 | loss: 0.3293303\n",
      "\tspeed: 0.0032s/iter; left time: 10.7928s\n",
      "\titers: 500, epoch: 7 | loss: 0.4356769\n",
      "\tspeed: 0.0036s/iter; left time: 11.8067s\n",
      "\titers: 600, epoch: 7 | loss: 0.5374249\n",
      "\tspeed: 0.0036s/iter; left time: 11.6640s\n",
      "\titers: 700, epoch: 7 | loss: 0.3291128\n",
      "\tspeed: 0.0040s/iter; left time: 12.3746s\n",
      "\titers: 800, epoch: 7 | loss: 0.4685010\n",
      "\tspeed: 0.0035s/iter; left time: 10.4926s\n",
      "\titers: 900, epoch: 7 | loss: 0.2810131\n",
      "\tspeed: 0.0030s/iter; left time: 8.7225s\n",
      "Epoch: 7 cost time: 3.905682325363159\n",
      "Epoch: 7, Steps: 953 | Train Loss: 0.3787709 Vali Loss: 0.4354052 Test Loss: 0.5075700\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4029332\n",
      "\tspeed: 0.1984s/iter; left time: 547.4796s\n",
      "\titers: 200, epoch: 8 | loss: 0.4527030\n",
      "\tspeed: 0.0040s/iter; left time: 10.7050s\n",
      "\titers: 300, epoch: 8 | loss: 0.3783762\n",
      "\tspeed: 0.0039s/iter; left time: 10.0202s\n",
      "\titers: 400, epoch: 8 | loss: 0.4122992\n",
      "\tspeed: 0.0038s/iter; left time: 9.4280s\n",
      "\titers: 500, epoch: 8 | loss: 0.4852032\n",
      "\tspeed: 0.0043s/iter; left time: 10.0947s\n",
      "\titers: 600, epoch: 8 | loss: 0.4668220\n",
      "\tspeed: 0.0046s/iter; left time: 10.4057s\n",
      "\titers: 700, epoch: 8 | loss: 0.3549354\n",
      "\tspeed: 0.0039s/iter; left time: 8.4532s\n",
      "\titers: 800, epoch: 8 | loss: 0.2925063\n",
      "\tspeed: 0.0037s/iter; left time: 7.6262s\n",
      "\titers: 900, epoch: 8 | loss: 0.3971786\n",
      "\tspeed: 0.0029s/iter; left time: 5.6283s\n",
      "Epoch: 8 cost time: 4.30727219581604\n",
      "Epoch: 8, Steps: 953 | Train Loss: 0.3786113 Vali Loss: 0.4352994 Test Loss: 0.5074809\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 3) (8711, 1, 48, 3)\n",
      "test shape: (8711, 48, 3) (8711, 48, 3)\n",
      "mse:0.5073811411857605, mae:0.49663713574409485\n",
      "\n",
      "Extracted Part: long_term_forecast__48_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__48_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=3, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=3, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=3, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_96_df_most_important_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.6791396\n",
      "\tspeed: 0.0113s/iter; left time: 106.6103s\n",
      "\titers: 200, epoch: 1 | loss: 0.5281612\n",
      "\tspeed: 0.0030s/iter; left time: 27.5113s\n",
      "\titers: 300, epoch: 1 | loss: 0.4698624\n",
      "\tspeed: 0.0031s/iter; left time: 28.7434s\n",
      "\titers: 400, epoch: 1 | loss: 0.4497033\n",
      "\tspeed: 0.0032s/iter; left time: 28.8822s\n",
      "\titers: 500, epoch: 1 | loss: 0.4245471\n",
      "\tspeed: 0.0029s/iter; left time: 25.9835s\n",
      "\titers: 600, epoch: 1 | loss: 0.4847340\n",
      "\tspeed: 0.0033s/iter; left time: 29.5523s\n",
      "\titers: 700, epoch: 1 | loss: 0.4004161\n",
      "\tspeed: 0.0032s/iter; left time: 28.0816s\n",
      "\titers: 800, epoch: 1 | loss: 0.4932185\n",
      "\tspeed: 0.0040s/iter; left time: 35.1209s\n",
      "\titers: 900, epoch: 1 | loss: 0.3933861\n",
      "\tspeed: 0.0036s/iter; left time: 30.8966s\n",
      "Epoch: 1 cost time: 3.995990753173828\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.5149260 Vali Loss: 0.5259265 Test Loss: 0.6203136\n",
      "Validation loss decreased (inf --> 0.525927).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3822233\n",
      "\tspeed: 0.1811s/iter; left time: 1533.7840s\n",
      "\titers: 200, epoch: 2 | loss: 0.4417066\n",
      "\tspeed: 0.0035s/iter; left time: 28.9815s\n",
      "\titers: 300, epoch: 2 | loss: 0.5119870\n",
      "\tspeed: 0.0033s/iter; left time: 27.5264s\n",
      "\titers: 400, epoch: 2 | loss: 0.4321629\n",
      "\tspeed: 0.0043s/iter; left time: 34.8860s\n",
      "\titers: 500, epoch: 2 | loss: 0.5247489\n",
      "\tspeed: 0.0038s/iter; left time: 30.7072s\n",
      "\titers: 600, epoch: 2 | loss: 0.4284758\n",
      "\tspeed: 0.0027s/iter; left time: 21.7829s\n",
      "\titers: 700, epoch: 2 | loss: 0.4567796\n",
      "\tspeed: 0.0030s/iter; left time: 23.6423s\n",
      "\titers: 800, epoch: 2 | loss: 0.4135364\n",
      "\tspeed: 0.0028s/iter; left time: 21.6972s\n",
      "\titers: 900, epoch: 2 | loss: 0.5110835\n",
      "\tspeed: 0.0028s/iter; left time: 21.7417s\n",
      "Epoch: 2 cost time: 3.5557572841644287\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.4497325 Vali Loss: 0.5129219 Test Loss: 0.6067830\n",
      "Validation loss decreased (0.525927 --> 0.512922).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4143271\n",
      "\tspeed: 0.1790s/iter; left time: 1345.4279s\n",
      "\titers: 200, epoch: 3 | loss: 0.4625848\n",
      "\tspeed: 0.0030s/iter; left time: 22.3235s\n",
      "\titers: 300, epoch: 3 | loss: 0.5217215\n",
      "\tspeed: 0.0030s/iter; left time: 22.0196s\n",
      "\titers: 400, epoch: 3 | loss: 0.5651174\n",
      "\tspeed: 0.0029s/iter; left time: 21.2849s\n",
      "\titers: 500, epoch: 3 | loss: 0.4069293\n",
      "\tspeed: 0.0029s/iter; left time: 20.9515s\n",
      "\titers: 600, epoch: 3 | loss: 0.4070099\n",
      "\tspeed: 0.0030s/iter; left time: 21.2831s\n",
      "\titers: 700, epoch: 3 | loss: 0.4889875\n",
      "\tspeed: 0.0030s/iter; left time: 21.0793s\n",
      "\titers: 800, epoch: 3 | loss: 0.4767236\n",
      "\tspeed: 0.0030s/iter; left time: 20.1768s\n",
      "\titers: 900, epoch: 3 | loss: 0.4186114\n",
      "\tspeed: 0.0031s/iter; left time: 20.7238s\n",
      "Epoch: 3 cost time: 3.2582802772521973\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.4444092 Vali Loss: 0.5102302 Test Loss: 0.6035292\n",
      "Validation loss decreased (0.512922 --> 0.510230).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4212860\n",
      "\tspeed: 0.1872s/iter; left time: 1228.7517s\n",
      "\titers: 200, epoch: 4 | loss: 0.5047054\n",
      "\tspeed: 0.0037s/iter; left time: 24.0525s\n",
      "\titers: 300, epoch: 4 | loss: 0.3814500\n",
      "\tspeed: 0.0031s/iter; left time: 19.4724s\n",
      "\titers: 400, epoch: 4 | loss: 0.4047632\n",
      "\tspeed: 0.0032s/iter; left time: 19.7895s\n",
      "\titers: 500, epoch: 4 | loss: 0.4108755\n",
      "\tspeed: 0.0033s/iter; left time: 20.0379s\n",
      "\titers: 600, epoch: 4 | loss: 0.4712012\n",
      "\tspeed: 0.0032s/iter; left time: 19.4340s\n",
      "\titers: 700, epoch: 4 | loss: 0.4585569\n",
      "\tspeed: 0.0031s/iter; left time: 18.6702s\n",
      "\titers: 800, epoch: 4 | loss: 0.4436258\n",
      "\tspeed: 0.0033s/iter; left time: 19.2282s\n",
      "\titers: 900, epoch: 4 | loss: 0.3769175\n",
      "\tspeed: 0.0037s/iter; left time: 21.4430s\n",
      "Epoch: 4 cost time: 3.6338694095611572\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.4426065 Vali Loss: 0.5081657 Test Loss: 0.6019377\n",
      "Validation loss decreased (0.510230 --> 0.508166).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4220396\n",
      "\tspeed: 0.1933s/iter; left time: 1085.2723s\n",
      "\titers: 200, epoch: 5 | loss: 0.5107253\n",
      "\tspeed: 0.0043s/iter; left time: 23.9557s\n",
      "\titers: 300, epoch: 5 | loss: 0.4941892\n",
      "\tspeed: 0.0031s/iter; left time: 16.8789s\n",
      "\titers: 400, epoch: 5 | loss: 0.4897058\n",
      "\tspeed: 0.0034s/iter; left time: 17.8581s\n",
      "\titers: 500, epoch: 5 | loss: 0.4405862\n",
      "\tspeed: 0.0030s/iter; left time: 15.8927s\n",
      "\titers: 600, epoch: 5 | loss: 0.3740095\n",
      "\tspeed: 0.0033s/iter; left time: 16.6953s\n",
      "\titers: 700, epoch: 5 | loss: 0.4544004\n",
      "\tspeed: 0.0031s/iter; left time: 15.6719s\n",
      "\titers: 800, epoch: 5 | loss: 0.4610953\n",
      "\tspeed: 0.0033s/iter; left time: 16.0458s\n",
      "\titers: 900, epoch: 5 | loss: 0.4809174\n",
      "\tspeed: 0.0032s/iter; left time: 15.3574s\n",
      "Epoch: 5 cost time: 3.563786506652832\n",
      "Epoch: 5, Steps: 952 | Train Loss: 0.4418904 Vali Loss: 0.5084711 Test Loss: 0.6017660\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4346617\n",
      "\tspeed: 0.1873s/iter; left time: 873.2019s\n",
      "\titers: 200, epoch: 6 | loss: 0.4114881\n",
      "\tspeed: 0.0047s/iter; left time: 21.3600s\n",
      "\titers: 300, epoch: 6 | loss: 0.3587012\n",
      "\tspeed: 0.0050s/iter; left time: 22.1227s\n",
      "\titers: 400, epoch: 6 | loss: 0.4721965\n",
      "\tspeed: 0.0049s/iter; left time: 21.4256s\n",
      "\titers: 500, epoch: 6 | loss: 0.5401015\n",
      "\tspeed: 0.0055s/iter; left time: 23.3326s\n",
      "\titers: 600, epoch: 6 | loss: 0.4231816\n",
      "\tspeed: 0.0049s/iter; left time: 20.5390s\n",
      "\titers: 700, epoch: 6 | loss: 0.4243748\n",
      "\tspeed: 0.0046s/iter; left time: 18.6057s\n",
      "\titers: 800, epoch: 6 | loss: 0.4059565\n",
      "\tspeed: 0.0033s/iter; left time: 13.1376s\n",
      "\titers: 900, epoch: 6 | loss: 0.4058627\n",
      "\tspeed: 0.0032s/iter; left time: 12.2439s\n",
      "Epoch: 6 cost time: 4.589077949523926\n",
      "Epoch: 6, Steps: 952 | Train Loss: 0.4415252 Vali Loss: 0.5085823 Test Loss: 0.6015922\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4851846\n",
      "\tspeed: 0.2001s/iter; left time: 742.0222s\n",
      "\titers: 200, epoch: 7 | loss: 0.4054599\n",
      "\tspeed: 0.0047s/iter; left time: 17.0502s\n",
      "\titers: 300, epoch: 7 | loss: 0.4364311\n",
      "\tspeed: 0.0047s/iter; left time: 16.4800s\n",
      "\titers: 400, epoch: 7 | loss: 0.5176480\n",
      "\tspeed: 0.0046s/iter; left time: 15.6427s\n",
      "\titers: 500, epoch: 7 | loss: 0.4449213\n",
      "\tspeed: 0.0048s/iter; left time: 15.7531s\n",
      "\titers: 600, epoch: 7 | loss: 0.4928716\n",
      "\tspeed: 0.0045s/iter; left time: 14.5593s\n",
      "\titers: 700, epoch: 7 | loss: 0.5513806\n",
      "\tspeed: 0.0048s/iter; left time: 14.9550s\n",
      "\titers: 800, epoch: 7 | loss: 0.5003352\n",
      "\tspeed: 0.0046s/iter; left time: 13.9329s\n",
      "\titers: 900, epoch: 7 | loss: 0.5313649\n",
      "\tspeed: 0.0049s/iter; left time: 14.3067s\n",
      "Epoch: 7 cost time: 4.785990953445435\n",
      "Epoch: 7, Steps: 952 | Train Loss: 0.4413540 Vali Loss: 0.5082552 Test Loss: 0.6014338\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 3) (8663, 1, 96, 3)\n",
      "test shape: (8663, 96, 3) (8663, 96, 3)\n",
      "mse:0.6019377708435059, mae:0.539582371711731\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.6384457\n",
      "\tspeed: 0.0093s/iter; left time: 87.9198s\n",
      "\titers: 200, epoch: 1 | loss: 0.4854325\n",
      "\tspeed: 0.0049s/iter; left time: 45.3860s\n",
      "\titers: 300, epoch: 1 | loss: 0.4753910\n",
      "\tspeed: 0.0051s/iter; left time: 47.4085s\n",
      "\titers: 400, epoch: 1 | loss: 0.4523420\n",
      "\tspeed: 0.0050s/iter; left time: 45.4678s\n",
      "\titers: 500, epoch: 1 | loss: 0.4910108\n",
      "\tspeed: 0.0053s/iter; left time: 48.1409s\n",
      "\titers: 600, epoch: 1 | loss: 0.4110650\n",
      "\tspeed: 0.0049s/iter; left time: 44.0482s\n",
      "\titers: 700, epoch: 1 | loss: 0.3587025\n",
      "\tspeed: 0.0051s/iter; left time: 44.8187s\n",
      "\titers: 800, epoch: 1 | loss: 0.4280343\n",
      "\tspeed: 0.0050s/iter; left time: 44.0113s\n",
      "\titers: 900, epoch: 1 | loss: 0.4285378\n",
      "\tspeed: 0.0051s/iter; left time: 43.5514s\n",
      "Epoch: 1 cost time: 5.300440073013306\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.5156764 Vali Loss: 0.5245188 Test Loss: 0.6227885\n",
      "Validation loss decreased (inf --> 0.524519).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4523534\n",
      "\tspeed: 0.2257s/iter; left time: 1911.1878s\n",
      "\titers: 200, epoch: 2 | loss: 0.5694659\n",
      "\tspeed: 0.0047s/iter; left time: 39.0094s\n",
      "\titers: 300, epoch: 2 | loss: 0.5837811\n",
      "\tspeed: 0.0047s/iter; left time: 38.9937s\n",
      "\titers: 400, epoch: 2 | loss: 0.4874513\n",
      "\tspeed: 0.0047s/iter; left time: 38.7892s\n",
      "\titers: 500, epoch: 2 | loss: 0.5249636\n",
      "\tspeed: 0.0049s/iter; left time: 39.2861s\n",
      "\titers: 600, epoch: 2 | loss: 0.4075831\n",
      "\tspeed: 0.0049s/iter; left time: 38.9429s\n",
      "\titers: 700, epoch: 2 | loss: 0.4180516\n",
      "\tspeed: 0.0047s/iter; left time: 36.7723s\n",
      "\titers: 800, epoch: 2 | loss: 0.4763730\n",
      "\tspeed: 0.0046s/iter; left time: 35.3645s\n",
      "\titers: 900, epoch: 2 | loss: 0.3401211\n",
      "\tspeed: 0.0052s/iter; left time: 40.1810s\n",
      "Epoch: 2 cost time: 5.062237977981567\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.4496980 Vali Loss: 0.5129482 Test Loss: 0.6047899\n",
      "Validation loss decreased (0.524519 --> 0.512948).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5019990\n",
      "\tspeed: 0.2245s/iter; left time: 1687.3716s\n",
      "\titers: 200, epoch: 3 | loss: 0.4307573\n",
      "\tspeed: 0.0047s/iter; left time: 35.2044s\n",
      "\titers: 300, epoch: 3 | loss: 0.4254438\n",
      "\tspeed: 0.0055s/iter; left time: 39.9750s\n",
      "\titers: 400, epoch: 3 | loss: 0.4666508\n",
      "\tspeed: 0.0045s/iter; left time: 32.4453s\n",
      "\titers: 500, epoch: 3 | loss: 0.3783898\n",
      "\tspeed: 0.0043s/iter; left time: 30.3352s\n",
      "\titers: 600, epoch: 3 | loss: 0.4511935\n",
      "\tspeed: 0.0049s/iter; left time: 34.3995s\n",
      "\titers: 700, epoch: 3 | loss: 0.4496206\n",
      "\tspeed: 0.0046s/iter; left time: 31.9652s\n",
      "\titers: 800, epoch: 3 | loss: 0.4891700\n",
      "\tspeed: 0.0044s/iter; left time: 30.1567s\n",
      "\titers: 900, epoch: 3 | loss: 0.4159304\n",
      "\tspeed: 0.0049s/iter; left time: 32.9745s\n",
      "Epoch: 3 cost time: 4.959806680679321\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.4443505 Vali Loss: 0.5098889 Test Loss: 0.6039740\n",
      "Validation loss decreased (0.512948 --> 0.509889).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3692480\n",
      "\tspeed: 0.2218s/iter; left time: 1456.4095s\n",
      "\titers: 200, epoch: 4 | loss: 0.4804188\n",
      "\tspeed: 0.0046s/iter; left time: 29.4892s\n",
      "\titers: 300, epoch: 4 | loss: 0.5199937\n",
      "\tspeed: 0.0048s/iter; left time: 30.6683s\n",
      "\titers: 400, epoch: 4 | loss: 0.4773224\n",
      "\tspeed: 0.0051s/iter; left time: 31.6456s\n",
      "\titers: 500, epoch: 4 | loss: 0.3826231\n",
      "\tspeed: 0.0049s/iter; left time: 30.2761s\n",
      "\titers: 600, epoch: 4 | loss: 0.5574463\n",
      "\tspeed: 0.0049s/iter; left time: 29.4550s\n",
      "\titers: 700, epoch: 4 | loss: 0.3920061\n",
      "\tspeed: 0.0051s/iter; left time: 30.2174s\n",
      "\titers: 800, epoch: 4 | loss: 0.4224180\n",
      "\tspeed: 0.0047s/iter; left time: 27.5851s\n",
      "\titers: 900, epoch: 4 | loss: 0.4878662\n",
      "\tspeed: 0.0051s/iter; left time: 29.4166s\n",
      "Epoch: 4 cost time: 5.21519660949707\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.4425660 Vali Loss: 0.5091317 Test Loss: 0.6027468\n",
      "Validation loss decreased (0.509889 --> 0.509132).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5053234\n",
      "\tspeed: 0.2263s/iter; left time: 1270.4462s\n",
      "\titers: 200, epoch: 5 | loss: 0.3935184\n",
      "\tspeed: 0.0051s/iter; left time: 28.2960s\n",
      "\titers: 300, epoch: 5 | loss: 0.4624500\n",
      "\tspeed: 0.0050s/iter; left time: 26.8456s\n",
      "\titers: 400, epoch: 5 | loss: 0.3668140\n",
      "\tspeed: 0.0050s/iter; left time: 26.5861s\n",
      "\titers: 500, epoch: 5 | loss: 0.5262613\n",
      "\tspeed: 0.0048s/iter; left time: 25.0212s\n",
      "\titers: 600, epoch: 5 | loss: 0.4838891\n",
      "\tspeed: 0.0051s/iter; left time: 26.0743s\n",
      "\titers: 700, epoch: 5 | loss: 0.4372658\n",
      "\tspeed: 0.0045s/iter; left time: 22.6051s\n",
      "\titers: 800, epoch: 5 | loss: 0.3588900\n",
      "\tspeed: 0.0049s/iter; left time: 24.0408s\n",
      "\titers: 900, epoch: 5 | loss: 0.4876001\n",
      "\tspeed: 0.0048s/iter; left time: 22.9252s\n",
      "Epoch: 5 cost time: 5.149986505508423\n",
      "Epoch: 5, Steps: 952 | Train Loss: 0.4418568 Vali Loss: 0.5081474 Test Loss: 0.6025053\n",
      "Validation loss decreased (0.509132 --> 0.508147).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3763971\n",
      "\tspeed: 0.2284s/iter; left time: 1064.5021s\n",
      "\titers: 200, epoch: 6 | loss: 0.5006353\n",
      "\tspeed: 0.0046s/iter; left time: 21.2051s\n",
      "\titers: 300, epoch: 6 | loss: 0.5161236\n",
      "\tspeed: 0.0046s/iter; left time: 20.5188s\n",
      "\titers: 400, epoch: 6 | loss: 0.4817904\n",
      "\tspeed: 0.0045s/iter; left time: 19.7760s\n",
      "\titers: 500, epoch: 6 | loss: 0.4354608\n",
      "\tspeed: 0.0048s/iter; left time: 20.4486s\n",
      "\titers: 600, epoch: 6 | loss: 0.3876670\n",
      "\tspeed: 0.0047s/iter; left time: 19.6686s\n",
      "\titers: 700, epoch: 6 | loss: 0.5226950\n",
      "\tspeed: 0.0048s/iter; left time: 19.4315s\n",
      "\titers: 800, epoch: 6 | loss: 0.5212376\n",
      "\tspeed: 0.0049s/iter; left time: 19.3142s\n",
      "\titers: 900, epoch: 6 | loss: 0.3867555\n",
      "\tspeed: 0.0049s/iter; left time: 18.7958s\n",
      "Epoch: 6 cost time: 5.039311647415161\n",
      "Epoch: 6, Steps: 952 | Train Loss: 0.4415069 Vali Loss: 0.5087374 Test Loss: 0.6014000\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3837442\n",
      "\tspeed: 0.2201s/iter; left time: 816.1661s\n",
      "\titers: 200, epoch: 7 | loss: 0.4192843\n",
      "\tspeed: 0.0045s/iter; left time: 16.4024s\n",
      "\titers: 300, epoch: 7 | loss: 0.4278761\n",
      "\tspeed: 0.0046s/iter; left time: 16.2754s\n",
      "\titers: 400, epoch: 7 | loss: 0.3874289\n",
      "\tspeed: 0.0047s/iter; left time: 16.1515s\n",
      "\titers: 500, epoch: 7 | loss: 0.4148082\n",
      "\tspeed: 0.0048s/iter; left time: 15.8413s\n",
      "\titers: 600, epoch: 7 | loss: 0.4710375\n",
      "\tspeed: 0.0047s/iter; left time: 15.1769s\n",
      "\titers: 700, epoch: 7 | loss: 0.4144770\n",
      "\tspeed: 0.0047s/iter; left time: 14.6989s\n",
      "\titers: 800, epoch: 7 | loss: 0.4934514\n",
      "\tspeed: 0.0048s/iter; left time: 14.5117s\n",
      "\titers: 900, epoch: 7 | loss: 0.4440736\n",
      "\tspeed: 0.0049s/iter; left time: 14.3951s\n",
      "Epoch: 7 cost time: 5.0437633991241455\n",
      "Epoch: 7, Steps: 952 | Train Loss: 0.4413313 Vali Loss: 0.5086272 Test Loss: 0.6015592\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.5153064\n",
      "\tspeed: 0.2024s/iter; left time: 558.0079s\n",
      "\titers: 200, epoch: 8 | loss: 0.4084119\n",
      "\tspeed: 0.0037s/iter; left time: 9.8202s\n",
      "\titers: 300, epoch: 8 | loss: 0.3899070\n",
      "\tspeed: 0.0033s/iter; left time: 8.5198s\n",
      "\titers: 400, epoch: 8 | loss: 0.4826986\n",
      "\tspeed: 0.0037s/iter; left time: 9.1574s\n",
      "\titers: 500, epoch: 8 | loss: 0.4794619\n",
      "\tspeed: 0.0036s/iter; left time: 8.4420s\n",
      "\titers: 600, epoch: 8 | loss: 0.3695648\n",
      "\tspeed: 0.0040s/iter; left time: 9.0544s\n",
      "\titers: 700, epoch: 8 | loss: 0.3594994\n",
      "\tspeed: 0.0032s/iter; left time: 6.8084s\n",
      "\titers: 800, epoch: 8 | loss: 0.5386033\n",
      "\tspeed: 0.0032s/iter; left time: 6.6498s\n",
      "\titers: 900, epoch: 8 | loss: 0.4609437\n",
      "\tspeed: 0.0034s/iter; left time: 6.7418s\n",
      "Epoch: 8 cost time: 3.9750611782073975\n",
      "Epoch: 8, Steps: 952 | Train Loss: 0.4412421 Vali Loss: 0.5082886 Test Loss: 0.6014915\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 3) (8663, 1, 96, 3)\n",
      "test shape: (8663, 96, 3) (8663, 96, 3)\n",
      "mse:0.6025053262710571, mae:0.5401743650436401\n",
      "\n",
      "Extracted Part: long_term_forecast__96_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__96_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=3, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=3, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=3, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_192_df_most_important_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.6316953\n",
      "\tspeed: 0.0109s/iter; left time: 102.0775s\n",
      "\titers: 200, epoch: 1 | loss: 0.5679190\n",
      "\tspeed: 0.0029s/iter; left time: 27.3584s\n",
      "\titers: 300, epoch: 1 | loss: 0.6507168\n",
      "\tspeed: 0.0031s/iter; left time: 28.0941s\n",
      "\titers: 400, epoch: 1 | loss: 0.5205719\n",
      "\tspeed: 0.0030s/iter; left time: 27.3610s\n",
      "\titers: 500, epoch: 1 | loss: 0.4534538\n",
      "\tspeed: 0.0030s/iter; left time: 26.9653s\n",
      "\titers: 600, epoch: 1 | loss: 0.5638279\n",
      "\tspeed: 0.0031s/iter; left time: 27.5899s\n",
      "\titers: 700, epoch: 1 | loss: 0.6081110\n",
      "\tspeed: 0.0040s/iter; left time: 34.8925s\n",
      "\titers: 800, epoch: 1 | loss: 0.4674313\n",
      "\tspeed: 0.0038s/iter; left time: 32.7098s\n",
      "\titers: 900, epoch: 1 | loss: 0.5376261\n",
      "\tspeed: 0.0037s/iter; left time: 31.9219s\n",
      "Epoch: 1 cost time: 3.9356281757354736\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.5403768 Vali Loss: 0.5691858 Test Loss: 0.6717113\n",
      "Validation loss decreased (inf --> 0.569186).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5208071\n",
      "\tspeed: 0.2089s/iter; left time: 1763.1457s\n",
      "\titers: 200, epoch: 2 | loss: 0.5186585\n",
      "\tspeed: 0.0035s/iter; left time: 29.1078s\n",
      "\titers: 300, epoch: 2 | loss: 0.5284565\n",
      "\tspeed: 0.0034s/iter; left time: 28.1263s\n",
      "\titers: 400, epoch: 2 | loss: 0.4740712\n",
      "\tspeed: 0.0035s/iter; left time: 28.7343s\n",
      "\titers: 500, epoch: 2 | loss: 0.4100129\n",
      "\tspeed: 0.0035s/iter; left time: 27.9802s\n",
      "\titers: 600, epoch: 2 | loss: 0.4725884\n",
      "\tspeed: 0.0038s/iter; left time: 30.0133s\n",
      "\titers: 700, epoch: 2 | loss: 0.4327057\n",
      "\tspeed: 0.0033s/iter; left time: 25.7451s\n",
      "\titers: 800, epoch: 2 | loss: 0.3720272\n",
      "\tspeed: 0.0032s/iter; left time: 24.4482s\n",
      "\titers: 900, epoch: 2 | loss: 0.4176665\n",
      "\tspeed: 0.0034s/iter; left time: 25.6444s\n",
      "Epoch: 2 cost time: 3.7979421615600586\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.4814073 Vali Loss: 0.5613643 Test Loss: 0.6624954\n",
      "Validation loss decreased (0.569186 --> 0.561364).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4761148\n",
      "\tspeed: 0.1905s/iter; left time: 1427.1056s\n",
      "\titers: 200, epoch: 3 | loss: 0.4375238\n",
      "\tspeed: 0.0048s/iter; left time: 35.7684s\n",
      "\titers: 300, epoch: 3 | loss: 0.4880992\n",
      "\tspeed: 0.0034s/iter; left time: 24.5409s\n",
      "\titers: 400, epoch: 3 | loss: 0.4526366\n",
      "\tspeed: 0.0037s/iter; left time: 26.7192s\n",
      "\titers: 500, epoch: 3 | loss: 0.5115069\n",
      "\tspeed: 0.0036s/iter; left time: 25.1815s\n",
      "\titers: 600, epoch: 3 | loss: 0.4433860\n",
      "\tspeed: 0.0034s/iter; left time: 24.0761s\n",
      "\titers: 700, epoch: 3 | loss: 0.4847013\n",
      "\tspeed: 0.0028s/iter; left time: 19.5552s\n",
      "\titers: 800, epoch: 3 | loss: 0.4517713\n",
      "\tspeed: 0.0032s/iter; left time: 21.4561s\n",
      "\titers: 900, epoch: 3 | loss: 0.4848234\n",
      "\tspeed: 0.0035s/iter; left time: 23.5590s\n",
      "Epoch: 3 cost time: 3.895221710205078\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.4776056 Vali Loss: 0.5597354 Test Loss: 0.6619192\n",
      "Validation loss decreased (0.561364 --> 0.559735).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4522542\n",
      "\tspeed: 0.2010s/iter; left time: 1315.6603s\n",
      "\titers: 200, epoch: 4 | loss: 0.4266724\n",
      "\tspeed: 0.0053s/iter; left time: 34.2304s\n",
      "\titers: 300, epoch: 4 | loss: 0.4201670\n",
      "\tspeed: 0.0036s/iter; left time: 22.6378s\n",
      "\titers: 400, epoch: 4 | loss: 0.4710099\n",
      "\tspeed: 0.0037s/iter; left time: 22.9108s\n",
      "\titers: 500, epoch: 4 | loss: 0.4395703\n",
      "\tspeed: 0.0034s/iter; left time: 20.7335s\n",
      "\titers: 600, epoch: 4 | loss: 0.5462182\n",
      "\tspeed: 0.0034s/iter; left time: 20.3048s\n",
      "\titers: 700, epoch: 4 | loss: 0.5115110\n",
      "\tspeed: 0.0041s/iter; left time: 24.6131s\n",
      "\titers: 800, epoch: 4 | loss: 0.4385462\n",
      "\tspeed: 0.0038s/iter; left time: 22.3914s\n",
      "\titers: 900, epoch: 4 | loss: 0.4858245\n",
      "\tspeed: 0.0034s/iter; left time: 19.4641s\n",
      "Epoch: 4 cost time: 4.352876901626587\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.4763364 Vali Loss: 0.5587096 Test Loss: 0.6601549\n",
      "Validation loss decreased (0.559735 --> 0.558710).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4463638\n",
      "\tspeed: 0.1896s/iter; left time: 1060.7595s\n",
      "\titers: 200, epoch: 5 | loss: 0.4822240\n",
      "\tspeed: 0.0040s/iter; left time: 22.2099s\n",
      "\titers: 300, epoch: 5 | loss: 0.4674365\n",
      "\tspeed: 0.0035s/iter; left time: 18.9739s\n",
      "\titers: 400, epoch: 5 | loss: 0.4332844\n",
      "\tspeed: 0.0035s/iter; left time: 18.5960s\n",
      "\titers: 500, epoch: 5 | loss: 0.4307538\n",
      "\tspeed: 0.0031s/iter; left time: 16.1929s\n",
      "\titers: 600, epoch: 5 | loss: 0.4386550\n",
      "\tspeed: 0.0034s/iter; left time: 17.1449s\n",
      "\titers: 700, epoch: 5 | loss: 0.5502038\n",
      "\tspeed: 0.0040s/iter; left time: 20.0225s\n",
      "\titers: 800, epoch: 5 | loss: 0.5110431\n",
      "\tspeed: 0.0031s/iter; left time: 15.2573s\n",
      "\titers: 900, epoch: 5 | loss: 0.4531458\n",
      "\tspeed: 0.0045s/iter; left time: 21.7099s\n",
      "Epoch: 5 cost time: 3.9956552982330322\n",
      "Epoch: 5, Steps: 949 | Train Loss: 0.4757642 Vali Loss: 0.5583149 Test Loss: 0.6604679\n",
      "Validation loss decreased (0.558710 --> 0.558315).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.5602576\n",
      "\tspeed: 0.1913s/iter; left time: 888.5994s\n",
      "\titers: 200, epoch: 6 | loss: 0.4630166\n",
      "\tspeed: 0.0037s/iter; left time: 16.8657s\n",
      "\titers: 300, epoch: 6 | loss: 0.4818941\n",
      "\tspeed: 0.0041s/iter; left time: 18.1173s\n",
      "\titers: 400, epoch: 6 | loss: 0.5378614\n",
      "\tspeed: 0.0045s/iter; left time: 19.5460s\n",
      "\titers: 500, epoch: 6 | loss: 0.4604146\n",
      "\tspeed: 0.0040s/iter; left time: 16.9981s\n",
      "\titers: 600, epoch: 6 | loss: 0.4226449\n",
      "\tspeed: 0.0039s/iter; left time: 16.0593s\n",
      "\titers: 700, epoch: 6 | loss: 0.4291672\n",
      "\tspeed: 0.0036s/iter; left time: 14.7424s\n",
      "\titers: 800, epoch: 6 | loss: 0.4748926\n",
      "\tspeed: 0.0038s/iter; left time: 14.9515s\n",
      "\titers: 900, epoch: 6 | loss: 0.5025671\n",
      "\tspeed: 0.0035s/iter; left time: 13.4335s\n",
      "Epoch: 6 cost time: 4.123133420944214\n",
      "Epoch: 6, Steps: 949 | Train Loss: 0.4755016 Vali Loss: 0.5588252 Test Loss: 0.6593233\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4428252\n",
      "\tspeed: 0.1981s/iter; left time: 732.2321s\n",
      "\titers: 200, epoch: 7 | loss: 0.4517424\n",
      "\tspeed: 0.0031s/iter; left time: 11.3018s\n",
      "\titers: 300, epoch: 7 | loss: 0.5379096\n",
      "\tspeed: 0.0031s/iter; left time: 10.7205s\n",
      "\titers: 400, epoch: 7 | loss: 0.4698745\n",
      "\tspeed: 0.0030s/iter; left time: 10.1817s\n",
      "\titers: 500, epoch: 7 | loss: 0.5049584\n",
      "\tspeed: 0.0032s/iter; left time: 10.5594s\n",
      "\titers: 600, epoch: 7 | loss: 0.4606802\n",
      "\tspeed: 0.0032s/iter; left time: 10.1712s\n",
      "\titers: 700, epoch: 7 | loss: 0.4693760\n",
      "\tspeed: 0.0036s/iter; left time: 11.1039s\n",
      "\titers: 800, epoch: 7 | loss: 0.4962919\n",
      "\tspeed: 0.0039s/iter; left time: 11.6590s\n",
      "\titers: 900, epoch: 7 | loss: 0.5096636\n",
      "\tspeed: 0.0041s/iter; left time: 11.7722s\n",
      "Epoch: 7 cost time: 3.5325541496276855\n",
      "Epoch: 7, Steps: 949 | Train Loss: 0.4753694 Vali Loss: 0.5587292 Test Loss: 0.6594846\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4878820\n",
      "\tspeed: 0.1972s/iter; left time: 541.9301s\n",
      "\titers: 200, epoch: 8 | loss: 0.4910156\n",
      "\tspeed: 0.0031s/iter; left time: 8.1734s\n",
      "\titers: 300, epoch: 8 | loss: 0.5370070\n",
      "\tspeed: 0.0030s/iter; left time: 7.7094s\n",
      "\titers: 400, epoch: 8 | loss: 0.4206192\n",
      "\tspeed: 0.0034s/iter; left time: 8.2503s\n",
      "\titers: 500, epoch: 8 | loss: 0.4794467\n",
      "\tspeed: 0.0033s/iter; left time: 7.7615s\n",
      "\titers: 600, epoch: 8 | loss: 0.4878747\n",
      "\tspeed: 0.0035s/iter; left time: 7.9049s\n",
      "\titers: 700, epoch: 8 | loss: 0.5409036\n",
      "\tspeed: 0.0030s/iter; left time: 6.3981s\n",
      "\titers: 800, epoch: 8 | loss: 0.5486099\n",
      "\tspeed: 0.0035s/iter; left time: 7.1534s\n",
      "\titers: 900, epoch: 8 | loss: 0.5506483\n",
      "\tspeed: 0.0031s/iter; left time: 6.0898s\n",
      "Epoch: 8 cost time: 3.5473904609680176\n",
      "Epoch: 8, Steps: 949 | Train Loss: 0.4753024 Vali Loss: 0.5580766 Test Loss: 0.6593986\n",
      "Validation loss decreased (0.558315 --> 0.558077).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.5354718\n",
      "\tspeed: 0.1924s/iter; left time: 346.1364s\n",
      "\titers: 200, epoch: 9 | loss: 0.5219553\n",
      "\tspeed: 0.0035s/iter; left time: 5.9185s\n",
      "\titers: 300, epoch: 9 | loss: 0.4443630\n",
      "\tspeed: 0.0033s/iter; left time: 5.3023s\n",
      "\titers: 400, epoch: 9 | loss: 0.4460225\n",
      "\tspeed: 0.0036s/iter; left time: 5.4399s\n",
      "\titers: 500, epoch: 9 | loss: 0.4224988\n",
      "\tspeed: 0.0041s/iter; left time: 5.6693s\n",
      "\titers: 600, epoch: 9 | loss: 0.4801428\n",
      "\tspeed: 0.0043s/iter; left time: 5.5641s\n",
      "\titers: 700, epoch: 9 | loss: 0.4637537\n",
      "\tspeed: 0.0033s/iter; left time: 3.9115s\n",
      "\titers: 800, epoch: 9 | loss: 0.4112603\n",
      "\tspeed: 0.0034s/iter; left time: 3.6850s\n",
      "\titers: 900, epoch: 9 | loss: 0.4503305\n",
      "\tspeed: 0.0031s/iter; left time: 3.1079s\n",
      "Epoch: 9 cost time: 3.836834192276001\n",
      "Epoch: 9, Steps: 949 | Train Loss: 0.4752686 Vali Loss: 0.5580322 Test Loss: 0.6593570\n",
      "Validation loss decreased (0.558077 --> 0.558032).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.4598733\n",
      "\tspeed: 0.1852s/iter; left time: 157.4611s\n",
      "\titers: 200, epoch: 10 | loss: 0.5164322\n",
      "\tspeed: 0.0031s/iter; left time: 2.3229s\n",
      "\titers: 300, epoch: 10 | loss: 0.5033478\n",
      "\tspeed: 0.0032s/iter; left time: 2.1089s\n",
      "\titers: 400, epoch: 10 | loss: 0.4865873\n",
      "\tspeed: 0.0033s/iter; left time: 1.8392s\n",
      "\titers: 500, epoch: 10 | loss: 0.3665295\n",
      "\tspeed: 0.0029s/iter; left time: 1.2917s\n",
      "\titers: 600, epoch: 10 | loss: 0.4187215\n",
      "\tspeed: 0.0035s/iter; left time: 1.2296s\n",
      "\titers: 700, epoch: 10 | loss: 0.4969371\n",
      "\tspeed: 0.0034s/iter; left time: 0.8460s\n",
      "\titers: 800, epoch: 10 | loss: 0.4106290\n",
      "\tspeed: 0.0033s/iter; left time: 0.4997s\n",
      "\titers: 900, epoch: 10 | loss: 0.4989110\n",
      "\tspeed: 0.0035s/iter; left time: 0.1766s\n",
      "Epoch: 10 cost time: 3.5030977725982666\n",
      "Epoch: 10, Steps: 949 | Train Loss: 0.4752518 Vali Loss: 0.5582564 Test Loss: 0.6593548\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__192_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 3) (8567, 1, 192, 3)\n",
      "test shape: (8567, 192, 3) (8567, 192, 3)\n",
      "mse:0.6593570709228516, mae:0.5620564222335815\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.6132754\n",
      "\tspeed: 0.0083s/iter; left time: 77.9196s\n",
      "\titers: 200, epoch: 1 | loss: 0.5575588\n",
      "\tspeed: 0.0032s/iter; left time: 29.8116s\n",
      "\titers: 300, epoch: 1 | loss: 0.5322520\n",
      "\tspeed: 0.0032s/iter; left time: 29.3714s\n",
      "\titers: 400, epoch: 1 | loss: 0.4778554\n",
      "\tspeed: 0.0031s/iter; left time: 28.0977s\n",
      "\titers: 500, epoch: 1 | loss: 0.5090240\n",
      "\tspeed: 0.0030s/iter; left time: 27.1319s\n",
      "\titers: 600, epoch: 1 | loss: 0.4914988\n",
      "\tspeed: 0.0031s/iter; left time: 27.9233s\n",
      "\titers: 700, epoch: 1 | loss: 0.4261098\n",
      "\tspeed: 0.0032s/iter; left time: 27.9830s\n",
      "\titers: 800, epoch: 1 | loss: 0.5167281\n",
      "\tspeed: 0.0031s/iter; left time: 26.9771s\n",
      "\titers: 900, epoch: 1 | loss: 0.4717055\n",
      "\tspeed: 0.0030s/iter; left time: 26.1954s\n",
      "Epoch: 1 cost time: 3.5760161876678467\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.5392965 Vali Loss: 0.5687986 Test Loss: 0.6714114\n",
      "Validation loss decreased (inf --> 0.568799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4982337\n",
      "\tspeed: 0.2037s/iter; left time: 1719.5624s\n",
      "\titers: 200, epoch: 2 | loss: 0.5077246\n",
      "\tspeed: 0.0052s/iter; left time: 43.0039s\n",
      "\titers: 300, epoch: 2 | loss: 0.4625853\n",
      "\tspeed: 0.0051s/iter; left time: 42.1398s\n",
      "\titers: 400, epoch: 2 | loss: 0.4371251\n",
      "\tspeed: 0.0047s/iter; left time: 38.4225s\n",
      "\titers: 500, epoch: 2 | loss: 0.4947130\n",
      "\tspeed: 0.0050s/iter; left time: 39.8263s\n",
      "\titers: 600, epoch: 2 | loss: 0.5142614\n",
      "\tspeed: 0.0052s/iter; left time: 41.2757s\n",
      "\titers: 700, epoch: 2 | loss: 0.5057310\n",
      "\tspeed: 0.0047s/iter; left time: 36.5736s\n",
      "\titers: 800, epoch: 2 | loss: 0.6001538\n",
      "\tspeed: 0.0049s/iter; left time: 37.8700s\n",
      "\titers: 900, epoch: 2 | loss: 0.4746226\n",
      "\tspeed: 0.0050s/iter; left time: 37.9086s\n",
      "Epoch: 2 cost time: 5.163691759109497\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.4813396 Vali Loss: 0.5615017 Test Loss: 0.6635142\n",
      "Validation loss decreased (0.568799 --> 0.561502).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4429765\n",
      "\tspeed: 0.2256s/iter; left time: 1690.5619s\n",
      "\titers: 200, epoch: 3 | loss: 0.5749977\n",
      "\tspeed: 0.0046s/iter; left time: 34.3724s\n",
      "\titers: 300, epoch: 3 | loss: 0.5017709\n",
      "\tspeed: 0.0050s/iter; left time: 36.4476s\n",
      "\titers: 400, epoch: 3 | loss: 0.4731995\n",
      "\tspeed: 0.0045s/iter; left time: 32.4771s\n",
      "\titers: 500, epoch: 3 | loss: 0.4890688\n",
      "\tspeed: 0.0041s/iter; left time: 29.0047s\n",
      "\titers: 600, epoch: 3 | loss: 0.4304489\n",
      "\tspeed: 0.0047s/iter; left time: 32.6038s\n",
      "\titers: 700, epoch: 3 | loss: 0.3977296\n",
      "\tspeed: 0.0050s/iter; left time: 34.1612s\n",
      "\titers: 800, epoch: 3 | loss: 0.5647461\n",
      "\tspeed: 0.0047s/iter; left time: 31.7643s\n",
      "\titers: 900, epoch: 3 | loss: 0.5747555\n",
      "\tspeed: 0.0047s/iter; left time: 31.2173s\n",
      "Epoch: 3 cost time: 4.982707977294922\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.4775843 Vali Loss: 0.5598101 Test Loss: 0.6606797\n",
      "Validation loss decreased (0.561502 --> 0.559810).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4990036\n",
      "\tspeed: 0.2275s/iter; left time: 1488.9162s\n",
      "\titers: 200, epoch: 4 | loss: 0.4788341\n",
      "\tspeed: 0.0047s/iter; left time: 30.1424s\n",
      "\titers: 300, epoch: 4 | loss: 0.5170830\n",
      "\tspeed: 0.0050s/iter; left time: 31.7983s\n",
      "\titers: 400, epoch: 4 | loss: 0.5329221\n",
      "\tspeed: 0.0051s/iter; left time: 31.5402s\n",
      "\titers: 500, epoch: 4 | loss: 0.5009136\n",
      "\tspeed: 0.0050s/iter; left time: 30.6785s\n",
      "\titers: 600, epoch: 4 | loss: 0.4890832\n",
      "\tspeed: 0.0048s/iter; left time: 29.3081s\n",
      "\titers: 700, epoch: 4 | loss: 0.4195101\n",
      "\tspeed: 0.0046s/iter; left time: 27.2401s\n",
      "\titers: 800, epoch: 4 | loss: 0.4096963\n",
      "\tspeed: 0.0048s/iter; left time: 27.9003s\n",
      "\titers: 900, epoch: 4 | loss: 0.4991236\n",
      "\tspeed: 0.0051s/iter; left time: 29.4650s\n",
      "Epoch: 4 cost time: 5.1208813190460205\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.4763161 Vali Loss: 0.5588740 Test Loss: 0.6608083\n",
      "Validation loss decreased (0.559810 --> 0.558874).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5162781\n",
      "\tspeed: 0.2317s/iter; left time: 1296.1104s\n",
      "\titers: 200, epoch: 5 | loss: 0.4694658\n",
      "\tspeed: 0.0053s/iter; left time: 29.3965s\n",
      "\titers: 300, epoch: 5 | loss: 0.4419652\n",
      "\tspeed: 0.0049s/iter; left time: 26.4297s\n",
      "\titers: 400, epoch: 5 | loss: 0.4414949\n",
      "\tspeed: 0.0055s/iter; left time: 29.0580s\n",
      "\titers: 500, epoch: 5 | loss: 0.5166953\n",
      "\tspeed: 0.0050s/iter; left time: 26.0686s\n",
      "\titers: 600, epoch: 5 | loss: 0.4920350\n",
      "\tspeed: 0.0045s/iter; left time: 22.9583s\n",
      "\titers: 700, epoch: 5 | loss: 0.5520469\n",
      "\tspeed: 0.0049s/iter; left time: 24.2299s\n",
      "\titers: 800, epoch: 5 | loss: 0.4732305\n",
      "\tspeed: 0.0046s/iter; left time: 22.5296s\n",
      "\titers: 900, epoch: 5 | loss: 0.5164964\n",
      "\tspeed: 0.0053s/iter; left time: 25.5200s\n",
      "Epoch: 5 cost time: 5.247276306152344\n",
      "Epoch: 5, Steps: 949 | Train Loss: 0.4757448 Vali Loss: 0.5583161 Test Loss: 0.6597573\n",
      "Validation loss decreased (0.558874 --> 0.558316).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4442027\n",
      "\tspeed: 0.2302s/iter; left time: 1069.6473s\n",
      "\titers: 200, epoch: 6 | loss: 0.5003323\n",
      "\tspeed: 0.0050s/iter; left time: 22.9316s\n",
      "\titers: 300, epoch: 6 | loss: 0.4204741\n",
      "\tspeed: 0.0050s/iter; left time: 22.0679s\n",
      "\titers: 400, epoch: 6 | loss: 0.4915060\n",
      "\tspeed: 0.0049s/iter; left time: 21.4011s\n",
      "\titers: 500, epoch: 6 | loss: 0.5199988\n",
      "\tspeed: 0.0052s/iter; left time: 22.0964s\n",
      "\titers: 600, epoch: 6 | loss: 0.5140561\n",
      "\tspeed: 0.0046s/iter; left time: 19.1235s\n",
      "\titers: 700, epoch: 6 | loss: 0.5153345\n",
      "\tspeed: 0.0051s/iter; left time: 20.4602s\n",
      "\titers: 800, epoch: 6 | loss: 0.5259832\n",
      "\tspeed: 0.0050s/iter; left time: 19.8083s\n",
      "\titers: 900, epoch: 6 | loss: 0.4473621\n",
      "\tspeed: 0.0049s/iter; left time: 18.9770s\n",
      "Epoch: 6 cost time: 5.1939496994018555\n",
      "Epoch: 6, Steps: 949 | Train Loss: 0.4754856 Vali Loss: 0.5587674 Test Loss: 0.6594754\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.5353904\n",
      "\tspeed: 0.2215s/iter; left time: 819.0525s\n",
      "\titers: 200, epoch: 7 | loss: 0.4234756\n",
      "\tspeed: 0.0047s/iter; left time: 16.9602s\n",
      "\titers: 300, epoch: 7 | loss: 0.4964464\n",
      "\tspeed: 0.0055s/iter; left time: 19.2581s\n",
      "\titers: 400, epoch: 7 | loss: 0.4327399\n",
      "\tspeed: 0.0046s/iter; left time: 15.6133s\n",
      "\titers: 500, epoch: 7 | loss: 0.4298688\n",
      "\tspeed: 0.0051s/iter; left time: 16.6558s\n",
      "\titers: 600, epoch: 7 | loss: 0.5219218\n",
      "\tspeed: 0.0048s/iter; left time: 15.4999s\n",
      "\titers: 700, epoch: 7 | loss: 0.4588951\n",
      "\tspeed: 0.0048s/iter; left time: 14.9724s\n",
      "\titers: 800, epoch: 7 | loss: 0.4351191\n",
      "\tspeed: 0.0046s/iter; left time: 13.7655s\n",
      "\titers: 900, epoch: 7 | loss: 0.4608791\n",
      "\tspeed: 0.0053s/iter; left time: 15.4331s\n",
      "Epoch: 7 cost time: 5.187928199768066\n",
      "Epoch: 7, Steps: 949 | Train Loss: 0.4753495 Vali Loss: 0.5580583 Test Loss: 0.6595520\n",
      "Validation loss decreased (0.558316 --> 0.558058).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4918791\n",
      "\tspeed: 0.2268s/iter; left time: 623.3522s\n",
      "\titers: 200, epoch: 8 | loss: 0.4486375\n",
      "\tspeed: 0.0047s/iter; left time: 12.4550s\n",
      "\titers: 300, epoch: 8 | loss: 0.5066507\n",
      "\tspeed: 0.0049s/iter; left time: 12.5847s\n",
      "\titers: 400, epoch: 8 | loss: 0.5719014\n",
      "\tspeed: 0.0049s/iter; left time: 12.0064s\n",
      "\titers: 500, epoch: 8 | loss: 0.5210342\n",
      "\tspeed: 0.0045s/iter; left time: 10.4554s\n",
      "\titers: 600, epoch: 8 | loss: 0.4279589\n",
      "\tspeed: 0.0045s/iter; left time: 10.1636s\n",
      "\titers: 700, epoch: 8 | loss: 0.4760810\n",
      "\tspeed: 0.0048s/iter; left time: 10.3246s\n",
      "\titers: 800, epoch: 8 | loss: 0.4778478\n",
      "\tspeed: 0.0045s/iter; left time: 9.2317s\n",
      "\titers: 900, epoch: 8 | loss: 0.4299009\n",
      "\tspeed: 0.0046s/iter; left time: 9.0513s\n",
      "Epoch: 8 cost time: 4.935185432434082\n",
      "Epoch: 8, Steps: 949 | Train Loss: 0.4752809 Vali Loss: 0.5583321 Test Loss: 0.6594984\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.4392982\n",
      "\tspeed: 0.2256s/iter; left time: 405.7895s\n",
      "\titers: 200, epoch: 9 | loss: 0.4958439\n",
      "\tspeed: 0.0048s/iter; left time: 8.0716s\n",
      "\titers: 300, epoch: 9 | loss: 0.4370824\n",
      "\tspeed: 0.0045s/iter; left time: 7.1396s\n",
      "\titers: 400, epoch: 9 | loss: 0.5153330\n",
      "\tspeed: 0.0047s/iter; left time: 7.0161s\n",
      "\titers: 500, epoch: 9 | loss: 0.5068967\n",
      "\tspeed: 0.0046s/iter; left time: 6.4090s\n",
      "\titers: 600, epoch: 9 | loss: 0.4052487\n",
      "\tspeed: 0.0060s/iter; left time: 7.7717s\n",
      "\titers: 700, epoch: 9 | loss: 0.4311876\n",
      "\tspeed: 0.0064s/iter; left time: 7.6881s\n",
      "\titers: 800, epoch: 9 | loss: 0.4533989\n",
      "\tspeed: 0.0066s/iter; left time: 7.2075s\n",
      "\titers: 900, epoch: 9 | loss: 0.3752394\n",
      "\tspeed: 0.0062s/iter; left time: 6.2395s\n",
      "Epoch: 9 cost time: 5.648606538772583\n",
      "Epoch: 9, Steps: 949 | Train Loss: 0.4752478 Vali Loss: 0.5574678 Test Loss: 0.6594358\n",
      "Validation loss decreased (0.558058 --> 0.557468).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.3856498\n",
      "\tspeed: 0.2358s/iter; left time: 200.4461s\n",
      "\titers: 200, epoch: 10 | loss: 0.4703931\n",
      "\tspeed: 0.0050s/iter; left time: 3.7595s\n",
      "\titers: 300, epoch: 10 | loss: 0.5046048\n",
      "\tspeed: 0.0046s/iter; left time: 2.9991s\n",
      "\titers: 400, epoch: 10 | loss: 0.5580084\n",
      "\tspeed: 0.0048s/iter; left time: 2.6163s\n",
      "\titers: 500, epoch: 10 | loss: 0.4274097\n",
      "\tspeed: 0.0047s/iter; left time: 2.1297s\n",
      "\titers: 600, epoch: 10 | loss: 0.4745276\n",
      "\tspeed: 0.0046s/iter; left time: 1.5966s\n",
      "\titers: 700, epoch: 10 | loss: 0.4872518\n",
      "\tspeed: 0.0047s/iter; left time: 1.1653s\n",
      "\titers: 800, epoch: 10 | loss: 0.5148694\n",
      "\tspeed: 0.0046s/iter; left time: 0.6934s\n",
      "\titers: 900, epoch: 10 | loss: 0.4149368\n",
      "\tspeed: 0.0046s/iter; left time: 0.2305s\n",
      "Epoch: 10 cost time: 4.954620361328125\n",
      "Epoch: 10, Steps: 949 | Train Loss: 0.4752309 Vali Loss: 0.5589436 Test Loss: 0.6594254\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__192_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 3) (8567, 1, 192, 3)\n",
      "test shape: (8567, 192, 3) (8567, 192, 3)\n",
      "mse:0.6594357490539551, mae:0.5620729327201843\n",
      "\n",
      "Extracted Part: long_term_forecast__192_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__192_df_most_important_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=21, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_only_generation_columns.csv', dec_in=21, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=21, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_24_df_only_generation_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=24, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.6124679\n",
      "\tspeed: 0.0159s/iter; left time: 150.2255s\n",
      "\titers: 200, epoch: 1 | loss: 0.5007629\n",
      "\tspeed: 0.0063s/iter; left time: 59.0226s\n",
      "\titers: 300, epoch: 1 | loss: 0.4238974\n",
      "\tspeed: 0.0067s/iter; left time: 61.4903s\n",
      "\titers: 400, epoch: 1 | loss: 0.4234231\n",
      "\tspeed: 0.0063s/iter; left time: 57.9318s\n",
      "\titers: 500, epoch: 1 | loss: 0.4362870\n",
      "\tspeed: 0.0073s/iter; left time: 65.5532s\n",
      "\titers: 600, epoch: 1 | loss: 0.5145205\n",
      "\tspeed: 0.0069s/iter; left time: 61.3856s\n",
      "\titers: 700, epoch: 1 | loss: 0.3984233\n",
      "\tspeed: 0.0070s/iter; left time: 61.9979s\n",
      "\titers: 800, epoch: 1 | loss: 0.4289896\n",
      "\tspeed: 0.0069s/iter; left time: 60.5682s\n",
      "\titers: 900, epoch: 1 | loss: 0.3752534\n",
      "\tspeed: 0.0059s/iter; left time: 51.3356s\n",
      "Epoch: 1 cost time: 7.349714279174805\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.4643068 Vali Loss: 0.5924697 Test Loss: 0.8539650\n",
      "Validation loss decreased (inf --> 0.592470).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4175507\n",
      "\tspeed: 0.1952s/iter; left time: 1656.6884s\n",
      "\titers: 200, epoch: 2 | loss: 0.3403660\n",
      "\tspeed: 0.0073s/iter; left time: 60.9421s\n",
      "\titers: 300, epoch: 2 | loss: 0.3962896\n",
      "\tspeed: 0.0067s/iter; left time: 55.1786s\n",
      "\titers: 400, epoch: 2 | loss: 0.3715179\n",
      "\tspeed: 0.0066s/iter; left time: 54.3736s\n",
      "\titers: 500, epoch: 2 | loss: 0.4432782\n",
      "\tspeed: 0.0061s/iter; left time: 49.4772s\n",
      "\titers: 600, epoch: 2 | loss: 0.4843291\n",
      "\tspeed: 0.0082s/iter; left time: 65.7049s\n",
      "\titers: 700, epoch: 2 | loss: 0.4380193\n",
      "\tspeed: 0.0055s/iter; left time: 43.0505s\n",
      "\titers: 800, epoch: 2 | loss: 0.2933019\n",
      "\tspeed: 0.0035s/iter; left time: 27.4857s\n",
      "\titers: 900, epoch: 2 | loss: 0.3779651\n",
      "\tspeed: 0.0048s/iter; left time: 37.2390s\n",
      "Epoch: 2 cost time: 6.129167318344116\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.3769226 Vali Loss: 0.5605176 Test Loss: 0.8110582\n",
      "Validation loss decreased (0.592470 --> 0.560518).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4299026\n",
      "\tspeed: 0.1989s/iter; left time: 1498.0224s\n",
      "\titers: 200, epoch: 3 | loss: 0.3598689\n",
      "\tspeed: 0.0051s/iter; left time: 37.5762s\n",
      "\titers: 300, epoch: 3 | loss: 0.3389876\n",
      "\tspeed: 0.0036s/iter; left time: 26.2562s\n",
      "\titers: 400, epoch: 3 | loss: 0.4028165\n",
      "\tspeed: 0.0037s/iter; left time: 26.5871s\n",
      "\titers: 500, epoch: 3 | loss: 0.3850666\n",
      "\tspeed: 0.0032s/iter; left time: 22.8019s\n",
      "\titers: 600, epoch: 3 | loss: 0.4176738\n",
      "\tspeed: 0.0055s/iter; left time: 38.8686s\n",
      "\titers: 700, epoch: 3 | loss: 0.4116303\n",
      "\tspeed: 0.0048s/iter; left time: 33.4157s\n",
      "\titers: 800, epoch: 3 | loss: 0.3382657\n",
      "\tspeed: 0.0044s/iter; left time: 30.1082s\n",
      "\titers: 900, epoch: 3 | loss: 0.3375070\n",
      "\tspeed: 0.0037s/iter; left time: 25.1620s\n",
      "Epoch: 3 cost time: 4.645024538040161\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.3654378 Vali Loss: 0.5521783 Test Loss: 0.7995325\n",
      "Validation loss decreased (0.560518 --> 0.552178).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4009387\n",
      "\tspeed: 0.2007s/iter; left time: 1320.0934s\n",
      "\titers: 200, epoch: 4 | loss: 0.3196361\n",
      "\tspeed: 0.0076s/iter; left time: 49.4511s\n",
      "\titers: 300, epoch: 4 | loss: 0.3460827\n",
      "\tspeed: 0.0068s/iter; left time: 43.4191s\n",
      "\titers: 400, epoch: 4 | loss: 0.3098644\n",
      "\tspeed: 0.0048s/iter; left time: 29.8885s\n",
      "\titers: 500, epoch: 4 | loss: 0.3155978\n",
      "\tspeed: 0.0052s/iter; left time: 32.2206s\n",
      "\titers: 600, epoch: 4 | loss: 0.3742568\n",
      "\tspeed: 0.0055s/iter; left time: 33.6186s\n",
      "\titers: 700, epoch: 4 | loss: 0.3893903\n",
      "\tspeed: 0.0030s/iter; left time: 17.9934s\n",
      "\titers: 800, epoch: 4 | loss: 0.3772433\n",
      "\tspeed: 0.0030s/iter; left time: 17.3728s\n",
      "\titers: 900, epoch: 4 | loss: 0.3751881\n",
      "\tspeed: 0.0029s/iter; left time: 17.0349s\n",
      "Epoch: 4 cost time: 5.358542203903198\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.3623166 Vali Loss: 0.5496883 Test Loss: 0.7943478\n",
      "Validation loss decreased (0.552178 --> 0.549688).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3816795\n",
      "\tspeed: 0.2069s/iter; left time: 1163.8319s\n",
      "\titers: 200, epoch: 5 | loss: 0.3083377\n",
      "\tspeed: 0.0047s/iter; left time: 25.6995s\n",
      "\titers: 300, epoch: 5 | loss: 0.3246894\n",
      "\tspeed: 0.0042s/iter; left time: 22.6106s\n",
      "\titers: 400, epoch: 5 | loss: 0.2818119\n",
      "\tspeed: 0.0047s/iter; left time: 24.8655s\n",
      "\titers: 500, epoch: 5 | loss: 0.3443863\n",
      "\tspeed: 0.0052s/iter; left time: 27.0781s\n",
      "\titers: 600, epoch: 5 | loss: 0.3959190\n",
      "\tspeed: 0.0058s/iter; left time: 29.9757s\n",
      "\titers: 700, epoch: 5 | loss: 0.3769239\n",
      "\tspeed: 0.0074s/iter; left time: 37.2980s\n",
      "\titers: 800, epoch: 5 | loss: 0.3428083\n",
      "\tspeed: 0.0057s/iter; left time: 28.2140s\n",
      "\titers: 900, epoch: 5 | loss: 0.4866290\n",
      "\tspeed: 0.0058s/iter; left time: 27.9930s\n",
      "Epoch: 5 cost time: 5.43524694442749\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.3611621 Vali Loss: 0.5473773 Test Loss: 0.7927310\n",
      "Validation loss decreased (0.549688 --> 0.547377).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3963934\n",
      "\tspeed: 0.2132s/iter; left time: 995.6694s\n",
      "\titers: 200, epoch: 6 | loss: 0.3264569\n",
      "\tspeed: 0.0062s/iter; left time: 28.3281s\n",
      "\titers: 300, epoch: 6 | loss: 0.3827617\n",
      "\tspeed: 0.0068s/iter; left time: 30.2645s\n",
      "\titers: 400, epoch: 6 | loss: 0.2939401\n",
      "\tspeed: 0.0068s/iter; left time: 29.5282s\n",
      "\titers: 500, epoch: 6 | loss: 0.3171960\n",
      "\tspeed: 0.0065s/iter; left time: 27.9580s\n",
      "\titers: 600, epoch: 6 | loss: 0.3759393\n",
      "\tspeed: 0.0054s/iter; left time: 22.7080s\n",
      "\titers: 700, epoch: 6 | loss: 0.3920945\n",
      "\tspeed: 0.0056s/iter; left time: 22.6152s\n",
      "\titers: 800, epoch: 6 | loss: 0.3582071\n",
      "\tspeed: 0.0048s/iter; left time: 19.1529s\n",
      "\titers: 900, epoch: 6 | loss: 0.3367629\n",
      "\tspeed: 0.0058s/iter; left time: 22.6007s\n",
      "Epoch: 6 cost time: 6.260724782943726\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.3606065 Vali Loss: 0.5484242 Test Loss: 0.7936008\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4757332\n",
      "\tspeed: 0.2180s/iter; left time: 810.2263s\n",
      "\titers: 200, epoch: 7 | loss: 0.2749156\n",
      "\tspeed: 0.0048s/iter; left time: 17.1942s\n",
      "\titers: 300, epoch: 7 | loss: 0.3252425\n",
      "\tspeed: 0.0065s/iter; left time: 22.8600s\n",
      "\titers: 400, epoch: 7 | loss: 0.3116463\n",
      "\tspeed: 0.0054s/iter; left time: 18.5394s\n",
      "\titers: 500, epoch: 7 | loss: 0.3132376\n",
      "\tspeed: 0.0055s/iter; left time: 18.1676s\n",
      "\titers: 600, epoch: 7 | loss: 0.3377865\n",
      "\tspeed: 0.0061s/iter; left time: 19.4720s\n",
      "\titers: 700, epoch: 7 | loss: 0.3166172\n",
      "\tspeed: 0.0052s/iter; left time: 16.3001s\n",
      "\titers: 800, epoch: 7 | loss: 0.3250062\n",
      "\tspeed: 0.0046s/iter; left time: 13.9741s\n",
      "\titers: 900, epoch: 7 | loss: 0.3255852\n",
      "\tspeed: 0.0041s/iter; left time: 12.0235s\n",
      "Epoch: 7 cost time: 5.41093635559082\n",
      "Epoch: 7, Steps: 954 | Train Loss: 0.3603338 Vali Loss: 0.5476670 Test Loss: 0.7931836\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3088935\n",
      "\tspeed: 0.2054s/iter; left time: 567.6073s\n",
      "\titers: 200, epoch: 8 | loss: 0.4366322\n",
      "\tspeed: 0.0059s/iter; left time: 15.7682s\n",
      "\titers: 300, epoch: 8 | loss: 0.3381667\n",
      "\tspeed: 0.0060s/iter; left time: 15.4300s\n",
      "\titers: 400, epoch: 8 | loss: 0.3633114\n",
      "\tspeed: 0.0066s/iter; left time: 16.1659s\n",
      "\titers: 500, epoch: 8 | loss: 0.2922183\n",
      "\tspeed: 0.0068s/iter; left time: 16.0729s\n",
      "\titers: 600, epoch: 8 | loss: 0.3824241\n",
      "\tspeed: 0.0056s/iter; left time: 12.6239s\n",
      "\titers: 700, epoch: 8 | loss: 0.3499275\n",
      "\tspeed: 0.0066s/iter; left time: 14.2453s\n",
      "\titers: 800, epoch: 8 | loss: 0.3266153\n",
      "\tspeed: 0.0068s/iter; left time: 14.1041s\n",
      "\titers: 900, epoch: 8 | loss: 0.3769897\n",
      "\tspeed: 0.0057s/iter; left time: 11.2251s\n",
      "Epoch: 8 cost time: 6.345325469970703\n",
      "Epoch: 8, Steps: 954 | Train Loss: 0.3602336 Vali Loss: 0.5476085 Test Loss: 0.7928803\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__24_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 21) (8735, 1, 24, 21)\n",
      "test shape: (8735, 24, 21) (8735, 24, 21)\n",
      "mse:0.7927314639091492, mae:0.5778189301490784\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.6346545\n",
      "\tspeed: 0.0119s/iter; left time: 112.4838s\n",
      "\titers: 200, epoch: 1 | loss: 0.4920305\n",
      "\tspeed: 0.0083s/iter; left time: 77.8657s\n",
      "\titers: 300, epoch: 1 | loss: 0.5636643\n",
      "\tspeed: 0.0042s/iter; left time: 39.2711s\n",
      "\titers: 400, epoch: 1 | loss: 0.4879771\n",
      "\tspeed: 0.0061s/iter; left time: 55.5015s\n",
      "\titers: 500, epoch: 1 | loss: 0.4009661\n",
      "\tspeed: 0.0067s/iter; left time: 60.9202s\n",
      "\titers: 600, epoch: 1 | loss: 0.4539473\n",
      "\tspeed: 0.0049s/iter; left time: 44.1460s\n",
      "\titers: 700, epoch: 1 | loss: 0.4050961\n",
      "\tspeed: 0.0052s/iter; left time: 46.3925s\n",
      "\titers: 800, epoch: 1 | loss: 0.4613275\n",
      "\tspeed: 0.0058s/iter; left time: 51.1337s\n",
      "\titers: 900, epoch: 1 | loss: 0.4075676\n",
      "\tspeed: 0.0059s/iter; left time: 50.5690s\n",
      "Epoch: 1 cost time: 6.392148017883301\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.4624567 Vali Loss: 0.5927230 Test Loss: 0.8534104\n",
      "Validation loss decreased (inf --> 0.592723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3191738\n",
      "\tspeed: 0.2194s/iter; left time: 1862.4246s\n",
      "\titers: 200, epoch: 2 | loss: 0.3805647\n",
      "\tspeed: 0.0070s/iter; left time: 58.4598s\n",
      "\titers: 300, epoch: 2 | loss: 0.4523622\n",
      "\tspeed: 0.0059s/iter; left time: 48.5549s\n",
      "\titers: 400, epoch: 2 | loss: 0.3288120\n",
      "\tspeed: 0.0078s/iter; left time: 63.7524s\n",
      "\titers: 500, epoch: 2 | loss: 0.3270658\n",
      "\tspeed: 0.0075s/iter; left time: 60.5154s\n",
      "\titers: 600, epoch: 2 | loss: 0.3757447\n",
      "\tspeed: 0.0054s/iter; left time: 42.9836s\n",
      "\titers: 700, epoch: 2 | loss: 0.3659675\n",
      "\tspeed: 0.0052s/iter; left time: 40.9908s\n",
      "\titers: 800, epoch: 2 | loss: 0.3924233\n",
      "\tspeed: 0.0045s/iter; left time: 34.9740s\n",
      "\titers: 900, epoch: 2 | loss: 0.3299658\n",
      "\tspeed: 0.0040s/iter; left time: 30.7175s\n",
      "Epoch: 2 cost time: 6.33830451965332\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.3767751 Vali Loss: 0.5588350 Test Loss: 0.8076665\n",
      "Validation loss decreased (0.592723 --> 0.558835).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3721583\n",
      "\tspeed: 0.2099s/iter; left time: 1581.3497s\n",
      "\titers: 200, epoch: 3 | loss: 0.3792868\n",
      "\tspeed: 0.0060s/iter; left time: 44.6104s\n",
      "\titers: 300, epoch: 3 | loss: 0.3971437\n",
      "\tspeed: 0.0080s/iter; left time: 58.5593s\n",
      "\titers: 400, epoch: 3 | loss: 0.3543334\n",
      "\tspeed: 0.0061s/iter; left time: 44.0139s\n",
      "\titers: 500, epoch: 3 | loss: 0.3767017\n",
      "\tspeed: 0.0047s/iter; left time: 33.3428s\n",
      "\titers: 600, epoch: 3 | loss: 0.3024268\n",
      "\tspeed: 0.0047s/iter; left time: 33.2822s\n",
      "\titers: 700, epoch: 3 | loss: 0.4120486\n",
      "\tspeed: 0.0042s/iter; left time: 29.3530s\n",
      "\titers: 800, epoch: 3 | loss: 0.3025862\n",
      "\tspeed: 0.0043s/iter; left time: 29.4970s\n",
      "\titers: 900, epoch: 3 | loss: 0.3676212\n",
      "\tspeed: 0.0047s/iter; left time: 31.9424s\n",
      "Epoch: 3 cost time: 5.7730467319488525\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.3654233 Vali Loss: 0.5518783 Test Loss: 0.7968954\n",
      "Validation loss decreased (0.558835 --> 0.551878).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3958927\n",
      "\tspeed: 0.2150s/iter; left time: 1414.7369s\n",
      "\titers: 200, epoch: 4 | loss: 0.4202878\n",
      "\tspeed: 0.0037s/iter; left time: 24.0373s\n",
      "\titers: 300, epoch: 4 | loss: 0.3359287\n",
      "\tspeed: 0.0055s/iter; left time: 35.3811s\n",
      "\titers: 400, epoch: 4 | loss: 0.3087961\n",
      "\tspeed: 0.0039s/iter; left time: 24.6061s\n",
      "\titers: 500, epoch: 4 | loss: 0.2701719\n",
      "\tspeed: 0.0061s/iter; left time: 37.7368s\n",
      "\titers: 600, epoch: 4 | loss: 0.3811686\n",
      "\tspeed: 0.0056s/iter; left time: 34.3174s\n",
      "\titers: 700, epoch: 4 | loss: 0.4232111\n",
      "\tspeed: 0.0045s/iter; left time: 26.7721s\n",
      "\titers: 800, epoch: 4 | loss: 0.3339207\n",
      "\tspeed: 0.0061s/iter; left time: 35.9437s\n",
      "\titers: 900, epoch: 4 | loss: 0.3723218\n",
      "\tspeed: 0.0059s/iter; left time: 34.2935s\n",
      "Epoch: 4 cost time: 5.581623554229736\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.3622948 Vali Loss: 0.5488174 Test Loss: 0.7951356\n",
      "Validation loss decreased (0.551878 --> 0.548817).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3218130\n",
      "\tspeed: 0.2118s/iter; left time: 1191.5241s\n",
      "\titers: 200, epoch: 5 | loss: 0.3863266\n",
      "\tspeed: 0.0067s/iter; left time: 37.2276s\n",
      "\titers: 300, epoch: 5 | loss: 0.3410083\n",
      "\tspeed: 0.0060s/iter; left time: 32.6252s\n",
      "\titers: 400, epoch: 5 | loss: 0.4250197\n",
      "\tspeed: 0.0061s/iter; left time: 32.6683s\n",
      "\titers: 500, epoch: 5 | loss: 0.3379129\n",
      "\tspeed: 0.0064s/iter; left time: 33.6061s\n",
      "\titers: 600, epoch: 5 | loss: 0.5199917\n",
      "\tspeed: 0.0056s/iter; left time: 28.8800s\n",
      "\titers: 700, epoch: 5 | loss: 0.3884871\n",
      "\tspeed: 0.0059s/iter; left time: 29.8931s\n",
      "\titers: 800, epoch: 5 | loss: 0.3554622\n",
      "\tspeed: 0.0069s/iter; left time: 33.9899s\n",
      "\titers: 900, epoch: 5 | loss: 0.4911349\n",
      "\tspeed: 0.0059s/iter; left time: 28.6684s\n",
      "Epoch: 5 cost time: 6.547130584716797\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.3610943 Vali Loss: 0.5491773 Test Loss: 0.7959347\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4372893\n",
      "\tspeed: 0.2395s/iter; left time: 1118.8898s\n",
      "\titers: 200, epoch: 6 | loss: 0.3699742\n",
      "\tspeed: 0.0042s/iter; left time: 19.0346s\n",
      "\titers: 300, epoch: 6 | loss: 0.4517151\n",
      "\tspeed: 0.0029s/iter; left time: 13.1456s\n",
      "\titers: 400, epoch: 6 | loss: 0.2983193\n",
      "\tspeed: 0.0029s/iter; left time: 12.8877s\n",
      "\titers: 500, epoch: 6 | loss: 0.3582346\n",
      "\tspeed: 0.0031s/iter; left time: 13.1221s\n",
      "\titers: 600, epoch: 6 | loss: 0.3524834\n",
      "\tspeed: 0.0030s/iter; left time: 12.6231s\n",
      "\titers: 700, epoch: 6 | loss: 0.3823798\n",
      "\tspeed: 0.0030s/iter; left time: 12.0563s\n",
      "\titers: 800, epoch: 6 | loss: 0.3021536\n",
      "\tspeed: 0.0029s/iter; left time: 11.7130s\n",
      "\titers: 900, epoch: 6 | loss: 0.4137319\n",
      "\tspeed: 0.0033s/iter; left time: 12.9527s\n",
      "Epoch: 6 cost time: 3.6233508586883545\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.3605423 Vali Loss: 0.5476402 Test Loss: 0.7926518\n",
      "Validation loss decreased (0.548817 --> 0.547640).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.5107356\n",
      "\tspeed: 0.2248s/iter; left time: 835.5820s\n",
      "\titers: 200, epoch: 7 | loss: 0.3350744\n",
      "\tspeed: 0.0030s/iter; left time: 10.7034s\n",
      "\titers: 300, epoch: 7 | loss: 0.3594885\n",
      "\tspeed: 0.0030s/iter; left time: 10.5676s\n",
      "\titers: 400, epoch: 7 | loss: 0.3291862\n",
      "\tspeed: 0.0030s/iter; left time: 10.3296s\n",
      "\titers: 500, epoch: 7 | loss: 0.3700702\n",
      "\tspeed: 0.0031s/iter; left time: 10.3280s\n",
      "\titers: 600, epoch: 7 | loss: 0.3707812\n",
      "\tspeed: 0.0031s/iter; left time: 9.8184s\n",
      "\titers: 700, epoch: 7 | loss: 0.4764662\n",
      "\tspeed: 0.0030s/iter; left time: 9.3877s\n",
      "\titers: 800, epoch: 7 | loss: 0.4287574\n",
      "\tspeed: 0.0030s/iter; left time: 9.0564s\n",
      "\titers: 900, epoch: 7 | loss: 0.3929242\n",
      "\tspeed: 0.0030s/iter; left time: 8.7145s\n",
      "Epoch: 7 cost time: 3.460749387741089\n",
      "Epoch: 7, Steps: 954 | Train Loss: 0.3602697 Vali Loss: 0.5472577 Test Loss: 0.7924330\n",
      "Validation loss decreased (0.547640 --> 0.547258).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4126530\n",
      "\tspeed: 0.2257s/iter; left time: 623.6559s\n",
      "\titers: 200, epoch: 8 | loss: 0.3770162\n",
      "\tspeed: 0.0031s/iter; left time: 8.3244s\n",
      "\titers: 300, epoch: 8 | loss: 0.3582368\n",
      "\tspeed: 0.0032s/iter; left time: 8.1328s\n",
      "\titers: 400, epoch: 8 | loss: 0.3339013\n",
      "\tspeed: 0.0029s/iter; left time: 7.1707s\n",
      "\titers: 500, epoch: 8 | loss: 0.3370234\n",
      "\tspeed: 0.0030s/iter; left time: 7.1229s\n",
      "\titers: 600, epoch: 8 | loss: 0.4326009\n",
      "\tspeed: 0.0030s/iter; left time: 6.7156s\n",
      "\titers: 700, epoch: 8 | loss: 0.3333492\n",
      "\tspeed: 0.0029s/iter; left time: 6.2650s\n",
      "\titers: 800, epoch: 8 | loss: 0.4031435\n",
      "\tspeed: 0.0029s/iter; left time: 5.9807s\n",
      "\titers: 900, epoch: 8 | loss: 0.3280439\n",
      "\tspeed: 0.0029s/iter; left time: 5.7316s\n",
      "Epoch: 8 cost time: 3.419095039367676\n",
      "Epoch: 8, Steps: 954 | Train Loss: 0.3601571 Vali Loss: 0.5474467 Test Loss: 0.7924025\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.3084425\n",
      "\tspeed: 0.2299s/iter; left time: 415.8304s\n",
      "\titers: 200, epoch: 9 | loss: 0.3579904\n",
      "\tspeed: 0.0034s/iter; left time: 5.7976s\n",
      "\titers: 300, epoch: 9 | loss: 0.2647028\n",
      "\tspeed: 0.0029s/iter; left time: 4.6498s\n",
      "\titers: 400, epoch: 9 | loss: 0.4022029\n",
      "\tspeed: 0.0029s/iter; left time: 4.3617s\n",
      "\titers: 500, epoch: 9 | loss: 0.3526924\n",
      "\tspeed: 0.0030s/iter; left time: 4.2366s\n",
      "\titers: 600, epoch: 9 | loss: 0.3553822\n",
      "\tspeed: 0.0031s/iter; left time: 4.0146s\n",
      "\titers: 700, epoch: 9 | loss: 0.2968419\n",
      "\tspeed: 0.0029s/iter; left time: 3.4842s\n",
      "\titers: 800, epoch: 9 | loss: 0.3447058\n",
      "\tspeed: 0.0028s/iter; left time: 3.0822s\n",
      "\titers: 900, epoch: 9 | loss: 0.4339416\n",
      "\tspeed: 0.0030s/iter; left time: 2.9926s\n",
      "Epoch: 9 cost time: 3.66298770904541\n",
      "Epoch: 9, Steps: 954 | Train Loss: 0.3600763 Vali Loss: 0.5471634 Test Loss: 0.7924147\n",
      "Validation loss decreased (0.547258 --> 0.547163).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.3215238\n",
      "\tspeed: 0.2268s/iter; left time: 193.8792s\n",
      "\titers: 200, epoch: 10 | loss: 0.3786928\n",
      "\tspeed: 0.0037s/iter; left time: 2.7587s\n",
      "\titers: 300, epoch: 10 | loss: 0.4720888\n",
      "\tspeed: 0.0040s/iter; left time: 2.6184s\n",
      "\titers: 400, epoch: 10 | loss: 0.2857037\n",
      "\tspeed: 0.0036s/iter; left time: 1.9889s\n",
      "\titers: 500, epoch: 10 | loss: 0.2973673\n",
      "\tspeed: 0.0031s/iter; left time: 1.4134s\n",
      "\titers: 600, epoch: 10 | loss: 0.3800771\n",
      "\tspeed: 0.0030s/iter; left time: 1.0747s\n",
      "\titers: 700, epoch: 10 | loss: 0.3561904\n",
      "\tspeed: 0.0030s/iter; left time: 0.7695s\n",
      "\titers: 800, epoch: 10 | loss: 0.2861166\n",
      "\tspeed: 0.0031s/iter; left time: 0.4737s\n",
      "\titers: 900, epoch: 10 | loss: 0.3615782\n",
      "\tspeed: 0.0032s/iter; left time: 0.1758s\n",
      "Epoch: 10 cost time: 3.7679548263549805\n",
      "Epoch: 10, Steps: 954 | Train Loss: 0.3600614 Vali Loss: 0.5469884 Test Loss: 0.7924190\n",
      "Validation loss decreased (0.547163 --> 0.546988).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__24_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 21) (8735, 1, 24, 21)\n",
      "test shape: (8735, 24, 21) (8735, 24, 21)\n",
      "mse:0.7924190759658813, mae:0.5769405364990234\n",
      "\n",
      "Extracted Part: long_term_forecast__24_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__24_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=21, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_only_generation_columns.csv', dec_in=21, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=21, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_48_df_only_generation_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=48, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.7227159\n",
      "\tspeed: 0.0110s/iter; left time: 103.9704s\n",
      "\titers: 200, epoch: 1 | loss: 0.5848286\n",
      "\tspeed: 0.0031s/iter; left time: 28.4753s\n",
      "\titers: 300, epoch: 1 | loss: 0.6129490\n",
      "\tspeed: 0.0040s/iter; left time: 36.5877s\n",
      "\titers: 400, epoch: 1 | loss: 0.5281656\n",
      "\tspeed: 0.0049s/iter; left time: 44.9738s\n",
      "\titers: 500, epoch: 1 | loss: 0.4489545\n",
      "\tspeed: 0.0033s/iter; left time: 29.5930s\n",
      "\titers: 600, epoch: 1 | loss: 0.5301266\n",
      "\tspeed: 0.0031s/iter; left time: 27.3635s\n",
      "\titers: 700, epoch: 1 | loss: 0.4782396\n",
      "\tspeed: 0.0033s/iter; left time: 29.1054s\n",
      "\titers: 800, epoch: 1 | loss: 0.4587657\n",
      "\tspeed: 0.0030s/iter; left time: 26.4768s\n",
      "\titers: 900, epoch: 1 | loss: 0.4603128\n",
      "\tspeed: 0.0037s/iter; left time: 31.8441s\n",
      "Epoch: 1 cost time: 4.1207451820373535\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.5595191 Vali Loss: 0.7401732 Test Loss: 1.0545331\n",
      "Validation loss decreased (inf --> 0.740173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5469858\n",
      "\tspeed: 0.2215s/iter; left time: 1877.5709s\n",
      "\titers: 200, epoch: 2 | loss: 0.4546434\n",
      "\tspeed: 0.0029s/iter; left time: 24.6334s\n",
      "\titers: 300, epoch: 2 | loss: 0.3674487\n",
      "\tspeed: 0.0030s/iter; left time: 24.4925s\n",
      "\titers: 400, epoch: 2 | loss: 0.5155794\n",
      "\tspeed: 0.0041s/iter; left time: 33.3640s\n",
      "\titers: 500, epoch: 2 | loss: 0.5487499\n",
      "\tspeed: 0.0041s/iter; left time: 33.3881s\n",
      "\titers: 600, epoch: 2 | loss: 0.4199290\n",
      "\tspeed: 0.0033s/iter; left time: 26.5915s\n",
      "\titers: 700, epoch: 2 | loss: 0.4752929\n",
      "\tspeed: 0.0032s/iter; left time: 25.4697s\n",
      "\titers: 800, epoch: 2 | loss: 0.4642166\n",
      "\tspeed: 0.0030s/iter; left time: 23.0257s\n",
      "\titers: 900, epoch: 2 | loss: 0.4822364\n",
      "\tspeed: 0.0030s/iter; left time: 22.7391s\n",
      "Epoch: 2 cost time: 3.6191794872283936\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.4938570 Vali Loss: 0.7209666 Test Loss: 1.0292954\n",
      "Validation loss decreased (0.740173 --> 0.720967).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5586449\n",
      "\tspeed: 0.2206s/iter; left time: 1659.9882s\n",
      "\titers: 200, epoch: 3 | loss: 0.4130507\n",
      "\tspeed: 0.0031s/iter; left time: 23.1022s\n",
      "\titers: 300, epoch: 3 | loss: 0.4335353\n",
      "\tspeed: 0.0030s/iter; left time: 22.2505s\n",
      "\titers: 400, epoch: 3 | loss: 0.5444581\n",
      "\tspeed: 0.0030s/iter; left time: 21.3831s\n",
      "\titers: 500, epoch: 3 | loss: 0.4978613\n",
      "\tspeed: 0.0029s/iter; left time: 20.9753s\n",
      "\titers: 600, epoch: 3 | loss: 0.4404124\n",
      "\tspeed: 0.0029s/iter; left time: 20.2877s\n",
      "\titers: 700, epoch: 3 | loss: 0.4888297\n",
      "\tspeed: 0.0029s/iter; left time: 20.1386s\n",
      "\titers: 800, epoch: 3 | loss: 0.4085759\n",
      "\tspeed: 0.0029s/iter; left time: 19.8586s\n",
      "\titers: 900, epoch: 3 | loss: 0.4587961\n",
      "\tspeed: 0.0029s/iter; left time: 19.5615s\n",
      "Epoch: 3 cost time: 3.183133125305176\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.4865777 Vali Loss: 0.7197903 Test Loss: 1.0300082\n",
      "Validation loss decreased (0.720967 --> 0.719790).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4927980\n",
      "\tspeed: 0.1964s/iter; left time: 1290.4225s\n",
      "\titers: 200, epoch: 4 | loss: 0.4278136\n",
      "\tspeed: 0.0055s/iter; left time: 35.5553s\n",
      "\titers: 300, epoch: 4 | loss: 0.4343067\n",
      "\tspeed: 0.0043s/iter; left time: 27.1492s\n",
      "\titers: 400, epoch: 4 | loss: 0.4440740\n",
      "\tspeed: 0.0043s/iter; left time: 27.2435s\n",
      "\titers: 500, epoch: 4 | loss: 0.5516346\n",
      "\tspeed: 0.0043s/iter; left time: 26.2625s\n",
      "\titers: 600, epoch: 4 | loss: 0.4705126\n",
      "\tspeed: 0.0040s/iter; left time: 23.9860s\n",
      "\titers: 700, epoch: 4 | loss: 0.4554642\n",
      "\tspeed: 0.0037s/iter; left time: 22.0562s\n",
      "\titers: 800, epoch: 4 | loss: 0.4817853\n",
      "\tspeed: 0.0053s/iter; left time: 31.4139s\n",
      "\titers: 900, epoch: 4 | loss: 0.4702802\n",
      "\tspeed: 0.0064s/iter; left time: 37.1886s\n",
      "Epoch: 4 cost time: 5.108093976974487\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.4844593 Vali Loss: 0.7160643 Test Loss: 1.0249902\n",
      "Validation loss decreased (0.719790 --> 0.716064).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4598475\n",
      "\tspeed: 0.2125s/iter; left time: 1193.8965s\n",
      "\titers: 200, epoch: 5 | loss: 0.4766992\n",
      "\tspeed: 0.0063s/iter; left time: 34.5647s\n",
      "\titers: 300, epoch: 5 | loss: 0.5610377\n",
      "\tspeed: 0.0062s/iter; left time: 33.4972s\n",
      "\titers: 400, epoch: 5 | loss: 0.5061437\n",
      "\tspeed: 0.0066s/iter; left time: 35.2662s\n",
      "\titers: 500, epoch: 5 | loss: 0.3767020\n",
      "\tspeed: 0.0059s/iter; left time: 30.9948s\n",
      "\titers: 600, epoch: 5 | loss: 0.5159414\n",
      "\tspeed: 0.0069s/iter; left time: 35.1779s\n",
      "\titers: 700, epoch: 5 | loss: 0.4972467\n",
      "\tspeed: 0.0053s/iter; left time: 26.3839s\n",
      "\titers: 800, epoch: 5 | loss: 0.4577623\n",
      "\tspeed: 0.0069s/iter; left time: 33.7525s\n",
      "\titers: 900, epoch: 5 | loss: 0.5441080\n",
      "\tspeed: 0.0046s/iter; left time: 22.2598s\n",
      "Epoch: 5 cost time: 6.236744165420532\n",
      "Epoch: 5, Steps: 953 | Train Loss: 0.4836777 Vali Loss: 0.7148338 Test Loss: 1.0228248\n",
      "Validation loss decreased (0.716064 --> 0.714834).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3976671\n",
      "\tspeed: 0.2196s/iter; left time: 1024.6688s\n",
      "\titers: 200, epoch: 6 | loss: 0.4666028\n",
      "\tspeed: 0.0058s/iter; left time: 26.3704s\n",
      "\titers: 300, epoch: 6 | loss: 0.4053525\n",
      "\tspeed: 0.0060s/iter; left time: 26.6328s\n",
      "\titers: 400, epoch: 6 | loss: 0.5600477\n",
      "\tspeed: 0.0068s/iter; left time: 29.8645s\n",
      "\titers: 500, epoch: 6 | loss: 0.4342990\n",
      "\tspeed: 0.0056s/iter; left time: 23.7659s\n",
      "\titers: 600, epoch: 6 | loss: 0.4588405\n",
      "\tspeed: 0.0053s/iter; left time: 22.1119s\n",
      "\titers: 700, epoch: 6 | loss: 0.4366702\n",
      "\tspeed: 0.0058s/iter; left time: 23.5820s\n",
      "\titers: 800, epoch: 6 | loss: 0.5759586\n",
      "\tspeed: 0.0060s/iter; left time: 23.7101s\n",
      "\titers: 900, epoch: 6 | loss: 0.5159797\n",
      "\tspeed: 0.0075s/iter; left time: 29.1683s\n",
      "Epoch: 6 cost time: 6.214048385620117\n",
      "Epoch: 6, Steps: 953 | Train Loss: 0.4833662 Vali Loss: 0.7154568 Test Loss: 1.0236846\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4462244\n",
      "\tspeed: 0.2071s/iter; left time: 768.9695s\n",
      "\titers: 200, epoch: 7 | loss: 0.4132065\n",
      "\tspeed: 0.0056s/iter; left time: 20.2392s\n",
      "\titers: 300, epoch: 7 | loss: 0.4745565\n",
      "\tspeed: 0.0084s/iter; left time: 29.4475s\n",
      "\titers: 400, epoch: 7 | loss: 0.4717543\n",
      "\tspeed: 0.0067s/iter; left time: 22.9085s\n",
      "\titers: 500, epoch: 7 | loss: 0.4484296\n",
      "\tspeed: 0.0067s/iter; left time: 22.2972s\n",
      "\titers: 600, epoch: 7 | loss: 0.4658909\n",
      "\tspeed: 0.0064s/iter; left time: 20.5521s\n",
      "\titers: 700, epoch: 7 | loss: 0.4513813\n",
      "\tspeed: 0.0067s/iter; left time: 20.9441s\n",
      "\titers: 800, epoch: 7 | loss: 0.3598188\n",
      "\tspeed: 0.0074s/iter; left time: 22.2635s\n",
      "\titers: 900, epoch: 7 | loss: 0.5317304\n",
      "\tspeed: 0.0074s/iter; left time: 21.5636s\n",
      "Epoch: 7 cost time: 7.146371603012085\n",
      "Epoch: 7, Steps: 953 | Train Loss: 0.4830582 Vali Loss: 0.7156614 Test Loss: 1.0237670\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.5288756\n",
      "\tspeed: 0.2009s/iter; left time: 554.5675s\n",
      "\titers: 200, epoch: 8 | loss: 0.5002063\n",
      "\tspeed: 0.0074s/iter; left time: 19.7915s\n",
      "\titers: 300, epoch: 8 | loss: 0.4592357\n",
      "\tspeed: 0.0091s/iter; left time: 23.3351s\n",
      "\titers: 400, epoch: 8 | loss: 0.3910738\n",
      "\tspeed: 0.0072s/iter; left time: 17.7237s\n",
      "\titers: 500, epoch: 8 | loss: 0.4740287\n",
      "\tspeed: 0.0076s/iter; left time: 18.0321s\n",
      "\titers: 600, epoch: 8 | loss: 0.4682784\n",
      "\tspeed: 0.0080s/iter; left time: 17.9865s\n",
      "\titers: 700, epoch: 8 | loss: 0.4930124\n",
      "\tspeed: 0.0077s/iter; left time: 16.7182s\n",
      "\titers: 800, epoch: 8 | loss: 0.4850025\n",
      "\tspeed: 0.0084s/iter; left time: 17.2286s\n",
      "\titers: 900, epoch: 8 | loss: 0.5263506\n",
      "\tspeed: 0.0068s/iter; left time: 13.2337s\n",
      "Epoch: 8 cost time: 7.716223955154419\n",
      "Epoch: 8, Steps: 953 | Train Loss: 0.4830774 Vali Loss: 0.7154693 Test Loss: 1.0236795\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 21) (8711, 1, 48, 21)\n",
      "test shape: (8711, 48, 21) (8711, 48, 21)\n",
      "mse:1.0228244066238403, mae:0.6764160990715027\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.6051890\n",
      "\tspeed: 0.0151s/iter; left time: 142.8504s\n",
      "\titers: 200, epoch: 1 | loss: 0.4972403\n",
      "\tspeed: 0.0065s/iter; left time: 60.8143s\n",
      "\titers: 300, epoch: 1 | loss: 0.5329521\n",
      "\tspeed: 0.0075s/iter; left time: 69.0069s\n",
      "\titers: 400, epoch: 1 | loss: 0.5430284\n",
      "\tspeed: 0.0073s/iter; left time: 67.1127s\n",
      "\titers: 500, epoch: 1 | loss: 0.5469465\n",
      "\tspeed: 0.0075s/iter; left time: 68.0575s\n",
      "\titers: 600, epoch: 1 | loss: 0.4238231\n",
      "\tspeed: 0.0075s/iter; left time: 66.6872s\n",
      "\titers: 700, epoch: 1 | loss: 0.5430009\n",
      "\tspeed: 0.0055s/iter; left time: 48.6316s\n",
      "\titers: 800, epoch: 1 | loss: 0.4876041\n",
      "\tspeed: 0.0059s/iter; left time: 51.8643s\n",
      "\titers: 900, epoch: 1 | loss: 0.4604431\n",
      "\tspeed: 0.0045s/iter; left time: 38.8697s\n",
      "Epoch: 1 cost time: 7.0056047439575195\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.5592849 Vali Loss: 0.7420939 Test Loss: 1.0589974\n",
      "Validation loss decreased (inf --> 0.742094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4490597\n",
      "\tspeed: 0.2034s/iter; left time: 1724.6595s\n",
      "\titers: 200, epoch: 2 | loss: 0.4843643\n",
      "\tspeed: 0.0081s/iter; left time: 68.1334s\n",
      "\titers: 300, epoch: 2 | loss: 0.5062413\n",
      "\tspeed: 0.0057s/iter; left time: 47.3018s\n",
      "\titers: 400, epoch: 2 | loss: 0.4422770\n",
      "\tspeed: 0.0056s/iter; left time: 46.1807s\n",
      "\titers: 500, epoch: 2 | loss: 0.4962302\n",
      "\tspeed: 0.0066s/iter; left time: 53.3025s\n",
      "\titers: 600, epoch: 2 | loss: 0.5200374\n",
      "\tspeed: 0.0062s/iter; left time: 49.0716s\n",
      "\titers: 700, epoch: 2 | loss: 0.5554689\n",
      "\tspeed: 0.0077s/iter; left time: 60.6492s\n",
      "\titers: 800, epoch: 2 | loss: 0.4854243\n",
      "\tspeed: 0.0058s/iter; left time: 45.2728s\n",
      "\titers: 900, epoch: 2 | loss: 0.4789341\n",
      "\tspeed: 0.0051s/iter; left time: 39.4550s\n",
      "Epoch: 2 cost time: 6.761722564697266\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.4939281 Vali Loss: 0.7211406 Test Loss: 1.0276971\n",
      "Validation loss decreased (0.742094 --> 0.721141).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4679400\n",
      "\tspeed: 0.2125s/iter; left time: 1599.2387s\n",
      "\titers: 200, epoch: 3 | loss: 0.4861833\n",
      "\tspeed: 0.0067s/iter; left time: 49.6570s\n",
      "\titers: 300, epoch: 3 | loss: 0.3751252\n",
      "\tspeed: 0.0069s/iter; left time: 50.6362s\n",
      "\titers: 400, epoch: 3 | loss: 0.5121007\n",
      "\tspeed: 0.0065s/iter; left time: 47.0741s\n",
      "\titers: 500, epoch: 3 | loss: 0.5004713\n",
      "\tspeed: 0.0065s/iter; left time: 45.9638s\n",
      "\titers: 600, epoch: 3 | loss: 0.4738905\n",
      "\tspeed: 0.0079s/iter; left time: 55.5604s\n",
      "\titers: 700, epoch: 3 | loss: 0.5045453\n",
      "\tspeed: 0.0065s/iter; left time: 44.9351s\n",
      "\titers: 800, epoch: 3 | loss: 0.4733865\n",
      "\tspeed: 0.0065s/iter; left time: 44.2520s\n",
      "\titers: 900, epoch: 3 | loss: 0.5427957\n",
      "\tspeed: 0.0069s/iter; left time: 46.4979s\n",
      "Epoch: 3 cost time: 7.30229926109314\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.4865655 Vali Loss: 0.7204716 Test Loss: 1.0313410\n",
      "Validation loss decreased (0.721141 --> 0.720472).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4472749\n",
      "\tspeed: 0.2069s/iter; left time: 1359.5619s\n",
      "\titers: 200, epoch: 4 | loss: 0.4821964\n",
      "\tspeed: 0.0084s/iter; left time: 54.5544s\n",
      "\titers: 300, epoch: 4 | loss: 0.4341080\n",
      "\tspeed: 0.0077s/iter; left time: 49.0438s\n",
      "\titers: 400, epoch: 4 | loss: 0.5432011\n",
      "\tspeed: 0.0057s/iter; left time: 35.7024s\n",
      "\titers: 500, epoch: 4 | loss: 0.4062312\n",
      "\tspeed: 0.0038s/iter; left time: 23.2897s\n",
      "\titers: 600, epoch: 4 | loss: 0.4306003\n",
      "\tspeed: 0.0044s/iter; left time: 26.6021s\n",
      "\titers: 700, epoch: 4 | loss: 0.4724577\n",
      "\tspeed: 0.0056s/iter; left time: 33.3867s\n",
      "\titers: 800, epoch: 4 | loss: 0.4389269\n",
      "\tspeed: 0.0063s/iter; left time: 37.2723s\n",
      "\titers: 900, epoch: 4 | loss: 0.4508572\n",
      "\tspeed: 0.0047s/iter; left time: 26.9628s\n",
      "Epoch: 4 cost time: 6.52570104598999\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.4845893 Vali Loss: 0.7175931 Test Loss: 1.0270060\n",
      "Validation loss decreased (0.720472 --> 0.717593).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5742504\n",
      "\tspeed: 0.2263s/iter; left time: 1271.7982s\n",
      "\titers: 200, epoch: 5 | loss: 0.5204883\n",
      "\tspeed: 0.0072s/iter; left time: 39.8751s\n",
      "\titers: 300, epoch: 5 | loss: 0.4310148\n",
      "\tspeed: 0.0066s/iter; left time: 35.8856s\n",
      "\titers: 400, epoch: 5 | loss: 0.4819247\n",
      "\tspeed: 0.0064s/iter; left time: 33.8540s\n",
      "\titers: 500, epoch: 5 | loss: 0.4559435\n",
      "\tspeed: 0.0068s/iter; left time: 35.3768s\n",
      "\titers: 600, epoch: 5 | loss: 0.4267416\n",
      "\tspeed: 0.0055s/iter; left time: 28.3381s\n",
      "\titers: 700, epoch: 5 | loss: 0.5941538\n",
      "\tspeed: 0.0075s/iter; left time: 37.8665s\n",
      "\titers: 800, epoch: 5 | loss: 0.5373426\n",
      "\tspeed: 0.0058s/iter; left time: 28.5366s\n",
      "\titers: 900, epoch: 5 | loss: 0.5083244\n",
      "\tspeed: 0.0068s/iter; left time: 32.6316s\n",
      "Epoch: 5 cost time: 7.0858154296875\n",
      "Epoch: 5, Steps: 953 | Train Loss: 0.4837929 Vali Loss: 0.7169271 Test Loss: 1.0268639\n",
      "Validation loss decreased (0.717593 --> 0.716927).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.5430003\n",
      "\tspeed: 0.2324s/iter; left time: 1084.2017s\n",
      "\titers: 200, epoch: 6 | loss: 0.5437557\n",
      "\tspeed: 0.0075s/iter; left time: 34.3602s\n",
      "\titers: 300, epoch: 6 | loss: 0.4299866\n",
      "\tspeed: 0.0064s/iter; left time: 28.7819s\n",
      "\titers: 400, epoch: 6 | loss: 0.4597334\n",
      "\tspeed: 0.0068s/iter; left time: 29.6164s\n",
      "\titers: 500, epoch: 6 | loss: 0.5612959\n",
      "\tspeed: 0.0069s/iter; left time: 29.5103s\n",
      "\titers: 600, epoch: 6 | loss: 0.4981303\n",
      "\tspeed: 0.0073s/iter; left time: 30.3178s\n",
      "\titers: 700, epoch: 6 | loss: 0.5460879\n",
      "\tspeed: 0.0071s/iter; left time: 28.6774s\n",
      "\titers: 800, epoch: 6 | loss: 0.4390186\n",
      "\tspeed: 0.0063s/iter; left time: 25.1620s\n",
      "\titers: 900, epoch: 6 | loss: 0.4734108\n",
      "\tspeed: 0.0057s/iter; left time: 22.0090s\n",
      "Epoch: 6 cost time: 7.132991552352905\n",
      "Epoch: 6, Steps: 953 | Train Loss: 0.4834123 Vali Loss: 0.7157859 Test Loss: 1.0251417\n",
      "Validation loss decreased (0.716927 --> 0.715786).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4288958\n",
      "\tspeed: 0.2184s/iter; left time: 810.7453s\n",
      "\titers: 200, epoch: 7 | loss: 0.4902309\n",
      "\tspeed: 0.0069s/iter; left time: 24.9650s\n",
      "\titers: 300, epoch: 7 | loss: 0.5351898\n",
      "\tspeed: 0.0070s/iter; left time: 24.5117s\n",
      "\titers: 400, epoch: 7 | loss: 0.4291806\n",
      "\tspeed: 0.0070s/iter; left time: 23.9962s\n",
      "\titers: 500, epoch: 7 | loss: 0.4948030\n",
      "\tspeed: 0.0069s/iter; left time: 22.9297s\n",
      "\titers: 600, epoch: 7 | loss: 0.4989960\n",
      "\tspeed: 0.0068s/iter; left time: 21.8971s\n",
      "\titers: 700, epoch: 7 | loss: 0.4982260\n",
      "\tspeed: 0.0061s/iter; left time: 18.8560s\n",
      "\titers: 800, epoch: 7 | loss: 0.4486053\n",
      "\tspeed: 0.0071s/iter; left time: 21.3540s\n",
      "\titers: 900, epoch: 7 | loss: 0.4787082\n",
      "\tspeed: 0.0072s/iter; left time: 20.8553s\n",
      "Epoch: 7 cost time: 7.146182537078857\n",
      "Epoch: 7, Steps: 953 | Train Loss: 0.4831973 Vali Loss: 0.7144736 Test Loss: 1.0234177\n",
      "Validation loss decreased (0.715786 --> 0.714474).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3859435\n",
      "\tspeed: 0.2150s/iter; left time: 593.4762s\n",
      "\titers: 200, epoch: 8 | loss: 0.5422243\n",
      "\tspeed: 0.0078s/iter; left time: 20.6786s\n",
      "\titers: 300, epoch: 8 | loss: 0.5155236\n",
      "\tspeed: 0.0077s/iter; left time: 19.6773s\n",
      "\titers: 400, epoch: 8 | loss: 0.4358982\n",
      "\tspeed: 0.0067s/iter; left time: 16.3970s\n",
      "\titers: 500, epoch: 8 | loss: 0.4161856\n",
      "\tspeed: 0.0068s/iter; left time: 16.0460s\n",
      "\titers: 600, epoch: 8 | loss: 0.4378700\n",
      "\tspeed: 0.0066s/iter; left time: 14.8813s\n",
      "\titers: 700, epoch: 8 | loss: 0.3921982\n",
      "\tspeed: 0.0072s/iter; left time: 15.4572s\n",
      "\titers: 800, epoch: 8 | loss: 0.5262248\n",
      "\tspeed: 0.0068s/iter; left time: 14.0782s\n",
      "\titers: 900, epoch: 8 | loss: 0.5384398\n",
      "\tspeed: 0.0067s/iter; left time: 13.0497s\n",
      "Epoch: 8 cost time: 7.461161851882935\n",
      "Epoch: 8, Steps: 953 | Train Loss: 0.4831086 Vali Loss: 0.7156683 Test Loss: 1.0238487\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.4508967\n",
      "\tspeed: 0.2162s/iter; left time: 390.6241s\n",
      "\titers: 200, epoch: 9 | loss: 0.4951802\n",
      "\tspeed: 0.0080s/iter; left time: 13.7328s\n",
      "\titers: 300, epoch: 9 | loss: 0.4518647\n",
      "\tspeed: 0.0069s/iter; left time: 11.0913s\n",
      "\titers: 400, epoch: 9 | loss: 0.4027189\n",
      "\tspeed: 0.0091s/iter; left time: 13.7243s\n",
      "\titers: 500, epoch: 9 | loss: 0.5251558\n",
      "\tspeed: 0.0061s/iter; left time: 8.5541s\n",
      "\titers: 600, epoch: 9 | loss: 0.6818663\n",
      "\tspeed: 0.0067s/iter; left time: 8.7103s\n",
      "\titers: 700, epoch: 9 | loss: 0.4224322\n",
      "\tspeed: 0.0074s/iter; left time: 8.9181s\n",
      "\titers: 800, epoch: 9 | loss: 0.5872095\n",
      "\tspeed: 0.0067s/iter; left time: 7.4016s\n",
      "\titers: 900, epoch: 9 | loss: 0.3659100\n",
      "\tspeed: 0.0058s/iter; left time: 5.8744s\n",
      "Epoch: 9 cost time: 7.597451686859131\n",
      "Epoch: 9, Steps: 953 | Train Loss: 0.4830610 Vali Loss: 0.7157952 Test Loss: 1.0238249\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.5127600\n",
      "\tspeed: 0.2074s/iter; left time: 177.1300s\n",
      "\titers: 200, epoch: 10 | loss: 0.5280449\n",
      "\tspeed: 0.0061s/iter; left time: 4.6006s\n",
      "\titers: 300, epoch: 10 | loss: 0.4941888\n",
      "\tspeed: 0.0076s/iter; left time: 4.9896s\n",
      "\titers: 400, epoch: 10 | loss: 0.4680251\n",
      "\tspeed: 0.0060s/iter; left time: 3.3026s\n",
      "\titers: 500, epoch: 10 | loss: 0.5951600\n",
      "\tspeed: 0.0069s/iter; left time: 3.1431s\n",
      "\titers: 600, epoch: 10 | loss: 0.5748143\n",
      "\tspeed: 0.0076s/iter; left time: 2.6912s\n",
      "\titers: 700, epoch: 10 | loss: 0.4555208\n",
      "\tspeed: 0.0067s/iter; left time: 1.6909s\n",
      "\titers: 800, epoch: 10 | loss: 0.3726642\n",
      "\tspeed: 0.0068s/iter; left time: 1.0409s\n",
      "\titers: 900, epoch: 10 | loss: 0.5168236\n",
      "\tspeed: 0.0068s/iter; left time: 0.3650s\n",
      "Epoch: 10 cost time: 6.995216608047485\n",
      "Epoch: 10, Steps: 953 | Train Loss: 0.4829990 Vali Loss: 0.7151641 Test Loss: 1.0238386\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__48_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 21) (8711, 1, 48, 21)\n",
      "test shape: (8711, 48, 21) (8711, 48, 21)\n",
      "mse:1.0234169960021973, mae:0.6762098073959351\n",
      "\n",
      "Extracted Part: long_term_forecast__48_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__48_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=21, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_only_generation_columns.csv', dec_in=21, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=21, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_96_df_only_generation_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.7603845\n",
      "\tspeed: 0.0118s/iter; left time: 111.5869s\n",
      "\titers: 200, epoch: 1 | loss: 0.6599235\n",
      "\tspeed: 0.0040s/iter; left time: 37.5983s\n",
      "\titers: 300, epoch: 1 | loss: 0.5709794\n",
      "\tspeed: 0.0035s/iter; left time: 32.1286s\n",
      "\titers: 400, epoch: 1 | loss: 0.5382944\n",
      "\tspeed: 0.0039s/iter; left time: 35.3902s\n",
      "\titers: 500, epoch: 1 | loss: 0.5182204\n",
      "\tspeed: 0.0031s/iter; left time: 27.9595s\n",
      "\titers: 600, epoch: 1 | loss: 0.5835745\n",
      "\tspeed: 0.0031s/iter; left time: 27.5373s\n",
      "\titers: 700, epoch: 1 | loss: 0.4879533\n",
      "\tspeed: 0.0033s/iter; left time: 29.2428s\n",
      "\titers: 800, epoch: 1 | loss: 0.6053262\n",
      "\tspeed: 0.0044s/iter; left time: 38.2724s\n",
      "\titers: 900, epoch: 1 | loss: 0.4686756\n",
      "\tspeed: 0.0040s/iter; left time: 34.9001s\n",
      "Epoch: 1 cost time: 4.315899610519409\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.6225967 Vali Loss: 0.8579582 Test Loss: 1.2093487\n",
      "Validation loss decreased (inf --> 0.857958).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5003616\n",
      "\tspeed: 0.2181s/iter; left time: 1847.1475s\n",
      "\titers: 200, epoch: 2 | loss: 0.5356220\n",
      "\tspeed: 0.0033s/iter; left time: 27.2061s\n",
      "\titers: 300, epoch: 2 | loss: 0.6171553\n",
      "\tspeed: 0.0032s/iter; left time: 26.3505s\n",
      "\titers: 400, epoch: 2 | loss: 0.5460122\n",
      "\tspeed: 0.0031s/iter; left time: 25.1071s\n",
      "\titers: 500, epoch: 2 | loss: 0.7029061\n",
      "\tspeed: 0.0030s/iter; left time: 24.3817s\n",
      "\titers: 600, epoch: 2 | loss: 0.5434754\n",
      "\tspeed: 0.0030s/iter; left time: 24.0568s\n",
      "\titers: 700, epoch: 2 | loss: 0.5608193\n",
      "\tspeed: 0.0030s/iter; left time: 23.6498s\n",
      "\titers: 800, epoch: 2 | loss: 0.5076069\n",
      "\tspeed: 0.0030s/iter; left time: 23.3422s\n",
      "\titers: 900, epoch: 2 | loss: 0.6488263\n",
      "\tspeed: 0.0030s/iter; left time: 23.1779s\n",
      "Epoch: 2 cost time: 3.321291923522949\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.5715918 Vali Loss: 0.8433230 Test Loss: 1.1936007\n",
      "Validation loss decreased (0.857958 --> 0.843323).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5277871\n",
      "\tspeed: 0.2356s/iter; left time: 1770.9696s\n",
      "\titers: 200, epoch: 3 | loss: 0.5740188\n",
      "\tspeed: 0.0034s/iter; left time: 25.4907s\n",
      "\titers: 300, epoch: 3 | loss: 0.6378926\n",
      "\tspeed: 0.0031s/iter; left time: 23.0190s\n",
      "\titers: 400, epoch: 3 | loss: 0.7349110\n",
      "\tspeed: 0.0032s/iter; left time: 22.9059s\n",
      "\titers: 500, epoch: 3 | loss: 0.4759474\n",
      "\tspeed: 0.0032s/iter; left time: 23.0898s\n",
      "\titers: 600, epoch: 3 | loss: 0.5280952\n",
      "\tspeed: 0.0032s/iter; left time: 22.3984s\n",
      "\titers: 700, epoch: 3 | loss: 0.6002336\n",
      "\tspeed: 0.0032s/iter; left time: 21.9191s\n",
      "\titers: 800, epoch: 3 | loss: 0.6155791\n",
      "\tspeed: 0.0031s/iter; left time: 21.4641s\n",
      "\titers: 900, epoch: 3 | loss: 0.5761640\n",
      "\tspeed: 0.0031s/iter; left time: 21.0261s\n",
      "Epoch: 3 cost time: 3.50034761428833\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.5672076 Vali Loss: 0.8409967 Test Loss: 1.1907666\n",
      "Validation loss decreased (0.843323 --> 0.840997).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5361691\n",
      "\tspeed: 0.2424s/iter; left time: 1591.2549s\n",
      "\titers: 200, epoch: 4 | loss: 0.6339877\n",
      "\tspeed: 0.0032s/iter; left time: 20.5239s\n",
      "\titers: 300, epoch: 4 | loss: 0.4910628\n",
      "\tspeed: 0.0031s/iter; left time: 19.5517s\n",
      "\titers: 400, epoch: 4 | loss: 0.5400496\n",
      "\tspeed: 0.0031s/iter; left time: 19.2155s\n",
      "\titers: 500, epoch: 4 | loss: 0.4944379\n",
      "\tspeed: 0.0031s/iter; left time: 18.8101s\n",
      "\titers: 600, epoch: 4 | loss: 0.5876699\n",
      "\tspeed: 0.0031s/iter; left time: 18.5585s\n",
      "\titers: 700, epoch: 4 | loss: 0.5707722\n",
      "\tspeed: 0.0031s/iter; left time: 18.2278s\n",
      "\titers: 800, epoch: 4 | loss: 0.5760785\n",
      "\tspeed: 0.0031s/iter; left time: 17.9511s\n",
      "\titers: 900, epoch: 4 | loss: 0.5041421\n",
      "\tspeed: 0.0041s/iter; left time: 23.8449s\n",
      "Epoch: 4 cost time: 3.4685425758361816\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.5658604 Vali Loss: 0.8382127 Test Loss: 1.1878917\n",
      "Validation loss decreased (0.840997 --> 0.838213).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5438761\n",
      "\tspeed: 0.2259s/iter; left time: 1267.9202s\n",
      "\titers: 200, epoch: 5 | loss: 0.6138011\n",
      "\tspeed: 0.0033s/iter; left time: 18.2083s\n",
      "\titers: 300, epoch: 5 | loss: 0.6260101\n",
      "\tspeed: 0.0043s/iter; left time: 23.0540s\n",
      "\titers: 400, epoch: 5 | loss: 0.6023792\n",
      "\tspeed: 0.0032s/iter; left time: 17.2557s\n",
      "\titers: 500, epoch: 5 | loss: 0.5253386\n",
      "\tspeed: 0.0031s/iter; left time: 15.9012s\n",
      "\titers: 600, epoch: 5 | loss: 0.4818997\n",
      "\tspeed: 0.0031s/iter; left time: 15.6224s\n",
      "\titers: 700, epoch: 5 | loss: 0.5640824\n",
      "\tspeed: 0.0031s/iter; left time: 15.3945s\n",
      "\titers: 800, epoch: 5 | loss: 0.5792494\n",
      "\tspeed: 0.0031s/iter; left time: 14.9930s\n",
      "\titers: 900, epoch: 5 | loss: 0.6263430\n",
      "\tspeed: 0.0030s/iter; left time: 14.6776s\n",
      "Epoch: 5 cost time: 3.5193674564361572\n",
      "Epoch: 5, Steps: 952 | Train Loss: 0.5653611 Vali Loss: 0.8390157 Test Loss: 1.1893622\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.5587376\n",
      "\tspeed: 0.2233s/iter; left time: 1040.7935s\n",
      "\titers: 200, epoch: 6 | loss: 0.5352028\n",
      "\tspeed: 0.0038s/iter; left time: 17.3870s\n",
      "\titers: 300, epoch: 6 | loss: 0.4801441\n",
      "\tspeed: 0.0036s/iter; left time: 15.9299s\n",
      "\titers: 400, epoch: 6 | loss: 0.5808473\n",
      "\tspeed: 0.0031s/iter; left time: 13.3100s\n",
      "\titers: 500, epoch: 6 | loss: 0.6783204\n",
      "\tspeed: 0.0031s/iter; left time: 13.0870s\n",
      "\titers: 600, epoch: 6 | loss: 0.5293881\n",
      "\tspeed: 0.0030s/iter; left time: 12.6721s\n",
      "\titers: 700, epoch: 6 | loss: 0.5745392\n",
      "\tspeed: 0.0031s/iter; left time: 12.6693s\n",
      "\titers: 800, epoch: 6 | loss: 0.5213118\n",
      "\tspeed: 0.0031s/iter; left time: 12.3274s\n",
      "\titers: 900, epoch: 6 | loss: 0.5240638\n",
      "\tspeed: 0.0030s/iter; left time: 11.6533s\n",
      "Epoch: 6 cost time: 3.5422580242156982\n",
      "Epoch: 6, Steps: 952 | Train Loss: 0.5650933 Vali Loss: 0.8400854 Test Loss: 1.1892300\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.6013586\n",
      "\tspeed: 0.2236s/iter; left time: 829.5008s\n",
      "\titers: 200, epoch: 7 | loss: 0.5305232\n",
      "\tspeed: 0.0030s/iter; left time: 10.7467s\n",
      "\titers: 300, epoch: 7 | loss: 0.5581586\n",
      "\tspeed: 0.0030s/iter; left time: 10.5138s\n",
      "\titers: 400, epoch: 7 | loss: 0.6511360\n",
      "\tspeed: 0.0030s/iter; left time: 10.2004s\n",
      "\titers: 500, epoch: 7 | loss: 0.5840801\n",
      "\tspeed: 0.0028s/iter; left time: 9.2845s\n",
      "\titers: 600, epoch: 7 | loss: 0.6224633\n",
      "\tspeed: 0.0030s/iter; left time: 9.6208s\n",
      "\titers: 700, epoch: 7 | loss: 0.6684657\n",
      "\tspeed: 0.0030s/iter; left time: 9.4126s\n",
      "\titers: 800, epoch: 7 | loss: 0.6165013\n",
      "\tspeed: 0.0030s/iter; left time: 9.0718s\n",
      "\titers: 900, epoch: 7 | loss: 0.6358029\n",
      "\tspeed: 0.0030s/iter; left time: 8.6309s\n",
      "Epoch: 7 cost time: 3.2032041549682617\n",
      "Epoch: 7, Steps: 952 | Train Loss: 0.5649708 Vali Loss: 0.8392038 Test Loss: 1.1888349\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 21) (8663, 1, 96, 21)\n",
      "test shape: (8663, 96, 21) (8663, 96, 21)\n",
      "mse:1.1878925561904907, mae:0.736734926700592\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.7305583\n",
      "\tspeed: 0.0137s/iter; left time: 128.7723s\n",
      "\titers: 200, epoch: 1 | loss: 0.5982665\n",
      "\tspeed: 0.0045s/iter; left time: 42.2501s\n",
      "\titers: 300, epoch: 1 | loss: 0.5686718\n",
      "\tspeed: 0.0047s/iter; left time: 43.4049s\n",
      "\titers: 400, epoch: 1 | loss: 0.5497454\n",
      "\tspeed: 0.0034s/iter; left time: 31.1424s\n",
      "\titers: 500, epoch: 1 | loss: 0.5881000\n",
      "\tspeed: 0.0041s/iter; left time: 36.7180s\n",
      "\titers: 600, epoch: 1 | loss: 0.4928453\n",
      "\tspeed: 0.0054s/iter; left time: 47.8922s\n",
      "\titers: 700, epoch: 1 | loss: 0.4536552\n",
      "\tspeed: 0.0048s/iter; left time: 42.7144s\n",
      "\titers: 800, epoch: 1 | loss: 0.5604931\n",
      "\tspeed: 0.0045s/iter; left time: 38.8585s\n",
      "\titers: 900, epoch: 1 | loss: 0.5605928\n",
      "\tspeed: 0.0047s/iter; left time: 40.2052s\n",
      "Epoch: 1 cost time: 5.457597732543945\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.6232386 Vali Loss: 0.8583781 Test Loss: 1.2223718\n",
      "Validation loss decreased (inf --> 0.858378).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5468209\n",
      "\tspeed: 0.2087s/iter; left time: 1767.4823s\n",
      "\titers: 200, epoch: 2 | loss: 0.7565535\n",
      "\tspeed: 0.0070s/iter; left time: 58.8259s\n",
      "\titers: 300, epoch: 2 | loss: 0.7208747\n",
      "\tspeed: 0.0079s/iter; left time: 65.3641s\n",
      "\titers: 400, epoch: 2 | loss: 0.6295840\n",
      "\tspeed: 0.0083s/iter; left time: 67.4740s\n",
      "\titers: 500, epoch: 2 | loss: 0.6801324\n",
      "\tspeed: 0.0061s/iter; left time: 49.4071s\n",
      "\titers: 600, epoch: 2 | loss: 0.5216228\n",
      "\tspeed: 0.0046s/iter; left time: 36.5728s\n",
      "\titers: 700, epoch: 2 | loss: 0.5334761\n",
      "\tspeed: 0.0049s/iter; left time: 38.8374s\n",
      "\titers: 800, epoch: 2 | loss: 0.6248710\n",
      "\tspeed: 0.0054s/iter; left time: 42.1643s\n",
      "\titers: 900, epoch: 2 | loss: 0.4448650\n",
      "\tspeed: 0.0051s/iter; left time: 38.7911s\n",
      "Epoch: 2 cost time: 6.4665727615356445\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.5715302 Vali Loss: 0.8399474 Test Loss: 1.1821915\n",
      "Validation loss decreased (0.858378 --> 0.839947).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6052098\n",
      "\tspeed: 0.2131s/iter; left time: 1601.9948s\n",
      "\titers: 200, epoch: 3 | loss: 0.5309889\n",
      "\tspeed: 0.0079s/iter; left time: 58.7990s\n",
      "\titers: 300, epoch: 3 | loss: 0.5664127\n",
      "\tspeed: 0.0078s/iter; left time: 56.7507s\n",
      "\titers: 400, epoch: 3 | loss: 0.5881262\n",
      "\tspeed: 0.0084s/iter; left time: 60.5722s\n",
      "\titers: 500, epoch: 3 | loss: 0.4605504\n",
      "\tspeed: 0.0078s/iter; left time: 55.4343s\n",
      "\titers: 600, epoch: 3 | loss: 0.5647121\n",
      "\tspeed: 0.0076s/iter; left time: 53.1841s\n",
      "\titers: 700, epoch: 3 | loss: 0.5487696\n",
      "\tspeed: 0.0076s/iter; left time: 52.6878s\n",
      "\titers: 800, epoch: 3 | loss: 0.5845730\n",
      "\tspeed: 0.0085s/iter; left time: 58.2360s\n",
      "\titers: 900, epoch: 3 | loss: 0.5199427\n",
      "\tspeed: 0.0075s/iter; left time: 50.4510s\n",
      "Epoch: 3 cost time: 8.195655822753906\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.5671446 Vali Loss: 0.8411310 Test Loss: 1.1922605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4825833\n",
      "\tspeed: 0.2148s/iter; left time: 1410.0526s\n",
      "\titers: 200, epoch: 4 | loss: 0.5953854\n",
      "\tspeed: 0.0050s/iter; left time: 32.5718s\n",
      "\titers: 300, epoch: 4 | loss: 0.6389685\n",
      "\tspeed: 0.0052s/iter; left time: 33.0441s\n",
      "\titers: 400, epoch: 4 | loss: 0.5946203\n",
      "\tspeed: 0.0062s/iter; left time: 38.9519s\n",
      "\titers: 500, epoch: 4 | loss: 0.4995180\n",
      "\tspeed: 0.0050s/iter; left time: 30.7393s\n",
      "\titers: 600, epoch: 4 | loss: 0.6580099\n",
      "\tspeed: 0.0057s/iter; left time: 34.3096s\n",
      "\titers: 700, epoch: 4 | loss: 0.4914119\n",
      "\tspeed: 0.0045s/iter; left time: 26.8068s\n",
      "\titers: 800, epoch: 4 | loss: 0.5619413\n",
      "\tspeed: 0.0039s/iter; left time: 22.9453s\n",
      "\titers: 900, epoch: 4 | loss: 0.6205945\n",
      "\tspeed: 0.0048s/iter; left time: 27.5963s\n",
      "Epoch: 4 cost time: 5.725033283233643\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.5658294 Vali Loss: 0.8405191 Test Loss: 1.1917074\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6340428\n",
      "\tspeed: 0.2188s/iter; left time: 1228.0327s\n",
      "\titers: 200, epoch: 5 | loss: 0.5198757\n",
      "\tspeed: 0.0063s/iter; left time: 34.7769s\n",
      "\titers: 300, epoch: 5 | loss: 0.5953390\n",
      "\tspeed: 0.0083s/iter; left time: 45.1314s\n",
      "\titers: 400, epoch: 5 | loss: 0.4693626\n",
      "\tspeed: 0.0083s/iter; left time: 44.2496s\n",
      "\titers: 500, epoch: 5 | loss: 0.6375110\n",
      "\tspeed: 0.0077s/iter; left time: 40.0909s\n",
      "\titers: 600, epoch: 5 | loss: 0.6143222\n",
      "\tspeed: 0.0076s/iter; left time: 38.6135s\n",
      "\titers: 700, epoch: 5 | loss: 0.5354054\n",
      "\tspeed: 0.0075s/iter; left time: 37.5860s\n",
      "\titers: 800, epoch: 5 | loss: 0.4596274\n",
      "\tspeed: 0.0052s/iter; left time: 25.5433s\n",
      "\titers: 900, epoch: 5 | loss: 0.5821191\n",
      "\tspeed: 0.0043s/iter; left time: 20.5637s\n",
      "Epoch: 5 cost time: 7.273146867752075\n",
      "Epoch: 5, Steps: 952 | Train Loss: 0.5653330 Vali Loss: 0.8390691 Test Loss: 1.1912639\n",
      "Validation loss decreased (0.839947 --> 0.839069).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4747145\n",
      "\tspeed: 0.2183s/iter; left time: 1017.3457s\n",
      "\titers: 200, epoch: 6 | loss: 0.6182765\n",
      "\tspeed: 0.0088s/iter; left time: 40.0743s\n",
      "\titers: 300, epoch: 6 | loss: 0.6767745\n",
      "\tspeed: 0.0083s/iter; left time: 36.9620s\n",
      "\titers: 400, epoch: 6 | loss: 0.5989745\n",
      "\tspeed: 0.0075s/iter; left time: 32.8561s\n",
      "\titers: 500, epoch: 6 | loss: 0.5572082\n",
      "\tspeed: 0.0077s/iter; left time: 32.7422s\n",
      "\titers: 600, epoch: 6 | loss: 0.4867305\n",
      "\tspeed: 0.0090s/iter; left time: 37.3380s\n",
      "\titers: 700, epoch: 6 | loss: 0.6516238\n",
      "\tspeed: 0.0077s/iter; left time: 31.3878s\n",
      "\titers: 800, epoch: 6 | loss: 0.6503353\n",
      "\tspeed: 0.0065s/iter; left time: 25.5597s\n",
      "\titers: 900, epoch: 6 | loss: 0.4951600\n",
      "\tspeed: 0.0050s/iter; left time: 19.4824s\n",
      "Epoch: 6 cost time: 8.079098463058472\n",
      "Epoch: 6, Steps: 952 | Train Loss: 0.5650776 Vali Loss: 0.8396130 Test Loss: 1.1885223\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4706641\n",
      "\tspeed: 0.2193s/iter; left time: 813.5250s\n",
      "\titers: 200, epoch: 7 | loss: 0.5280561\n",
      "\tspeed: 0.0054s/iter; left time: 19.5563s\n",
      "\titers: 300, epoch: 7 | loss: 0.5141453\n",
      "\tspeed: 0.0071s/iter; left time: 25.0688s\n",
      "\titers: 400, epoch: 7 | loss: 0.5271742\n",
      "\tspeed: 0.0073s/iter; left time: 24.7335s\n",
      "\titers: 500, epoch: 7 | loss: 0.5556757\n",
      "\tspeed: 0.0076s/iter; left time: 25.2819s\n",
      "\titers: 600, epoch: 7 | loss: 0.5709408\n",
      "\tspeed: 0.0067s/iter; left time: 21.4483s\n",
      "\titers: 700, epoch: 7 | loss: 0.5305105\n",
      "\tspeed: 0.0071s/iter; left time: 21.9642s\n",
      "\titers: 800, epoch: 7 | loss: 0.6398736\n",
      "\tspeed: 0.0066s/iter; left time: 19.7995s\n",
      "\titers: 900, epoch: 7 | loss: 0.6175846\n",
      "\tspeed: 0.0061s/iter; left time: 17.8191s\n",
      "Epoch: 7 cost time: 7.4470884799957275\n",
      "Epoch: 7, Steps: 952 | Train Loss: 0.5649505 Vali Loss: 0.8403972 Test Loss: 1.1894072\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.6141180\n",
      "\tspeed: 0.2164s/iter; left time: 596.6627s\n",
      "\titers: 200, epoch: 8 | loss: 0.5481854\n",
      "\tspeed: 0.0074s/iter; left time: 19.5402s\n",
      "\titers: 300, epoch: 8 | loss: 0.5428175\n",
      "\tspeed: 0.0067s/iter; left time: 17.0785s\n",
      "\titers: 400, epoch: 8 | loss: 0.5996049\n",
      "\tspeed: 0.0078s/iter; left time: 19.1673s\n",
      "\titers: 500, epoch: 8 | loss: 0.6447152\n",
      "\tspeed: 0.0082s/iter; left time: 19.3002s\n",
      "\titers: 600, epoch: 8 | loss: 0.4726804\n",
      "\tspeed: 0.0071s/iter; left time: 16.0125s\n",
      "\titers: 700, epoch: 8 | loss: 0.4699277\n",
      "\tspeed: 0.0061s/iter; left time: 13.2261s\n",
      "\titers: 800, epoch: 8 | loss: 0.6885081\n",
      "\tspeed: 0.0045s/iter; left time: 9.2586s\n",
      "\titers: 900, epoch: 8 | loss: 0.6019046\n",
      "\tspeed: 0.0046s/iter; left time: 8.9315s\n",
      "Epoch: 8 cost time: 6.996175289154053\n",
      "Epoch: 8, Steps: 952 | Train Loss: 0.5648853 Vali Loss: 0.8397675 Test Loss: 1.1893789\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 21) (8663, 1, 96, 21)\n",
      "test shape: (8663, 96, 21) (8663, 96, 21)\n",
      "mse:1.191263198852539, mae:0.7374348640441895\n",
      "\n",
      "Extracted Part: long_term_forecast__96_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__96_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=21, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_only_generation_columns.csv', dec_in=21, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=21, factor=5, features='M', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_192_df_only_generation_columns', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.6933621\n",
      "\tspeed: 0.0138s/iter; left time: 129.3536s\n",
      "\titers: 200, epoch: 1 | loss: 0.6863825\n",
      "\tspeed: 0.0059s/iter; left time: 54.7406s\n",
      "\titers: 300, epoch: 1 | loss: 0.7878625\n",
      "\tspeed: 0.0052s/iter; left time: 48.1922s\n",
      "\titers: 400, epoch: 1 | loss: 0.6630594\n",
      "\tspeed: 0.0053s/iter; left time: 48.1718s\n",
      "\titers: 500, epoch: 1 | loss: 0.5664570\n",
      "\tspeed: 0.0071s/iter; left time: 64.1171s\n",
      "\titers: 600, epoch: 1 | loss: 0.7331268\n",
      "\tspeed: 0.0070s/iter; left time: 61.9945s\n",
      "\titers: 700, epoch: 1 | loss: 0.7617975\n",
      "\tspeed: 0.0066s/iter; left time: 57.7180s\n",
      "\titers: 800, epoch: 1 | loss: 0.6042196\n",
      "\tspeed: 0.0060s/iter; left time: 52.4962s\n",
      "\titers: 900, epoch: 1 | loss: 0.6628391\n",
      "\tspeed: 0.0063s/iter; left time: 54.4062s\n",
      "Epoch: 1 cost time: 6.637128829956055\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.6617314 Vali Loss: 0.9319811 Test Loss: 1.3199738\n",
      "Validation loss decreased (inf --> 0.931981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6669891\n",
      "\tspeed: 0.2146s/iter; left time: 1811.4855s\n",
      "\titers: 200, epoch: 2 | loss: 0.6564152\n",
      "\tspeed: 0.0082s/iter; left time: 68.5690s\n",
      "\titers: 300, epoch: 2 | loss: 0.6860420\n",
      "\tspeed: 0.0080s/iter; left time: 65.6833s\n",
      "\titers: 400, epoch: 2 | loss: 0.5984792\n",
      "\tspeed: 0.0080s/iter; left time: 65.3973s\n",
      "\titers: 500, epoch: 2 | loss: 0.5276303\n",
      "\tspeed: 0.0073s/iter; left time: 58.3862s\n",
      "\titers: 600, epoch: 2 | loss: 0.5770685\n",
      "\tspeed: 0.0060s/iter; left time: 47.5617s\n",
      "\titers: 700, epoch: 2 | loss: 0.5642158\n",
      "\tspeed: 0.0080s/iter; left time: 62.8938s\n",
      "\titers: 800, epoch: 2 | loss: 0.4883773\n",
      "\tspeed: 0.0042s/iter; left time: 32.7710s\n",
      "\titers: 900, epoch: 2 | loss: 0.5359889\n",
      "\tspeed: 0.0045s/iter; left time: 34.3562s\n",
      "Epoch: 2 cost time: 6.956972599029541\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.6176681 Vali Loss: 0.9235939 Test Loss: 1.3066623\n",
      "Validation loss decreased (0.931981 --> 0.923594).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6106462\n",
      "\tspeed: 0.2067s/iter; left time: 1549.0152s\n",
      "\titers: 200, epoch: 3 | loss: 0.5707612\n",
      "\tspeed: 0.0072s/iter; left time: 53.2113s\n",
      "\titers: 300, epoch: 3 | loss: 0.6349810\n",
      "\tspeed: 0.0068s/iter; left time: 49.3526s\n",
      "\titers: 400, epoch: 3 | loss: 0.5714539\n",
      "\tspeed: 0.0061s/iter; left time: 44.1866s\n",
      "\titers: 500, epoch: 3 | loss: 0.6509419\n",
      "\tspeed: 0.0070s/iter; left time: 49.6518s\n",
      "\titers: 600, epoch: 3 | loss: 0.5908701\n",
      "\tspeed: 0.0055s/iter; left time: 38.5458s\n",
      "\titers: 700, epoch: 3 | loss: 0.6202561\n",
      "\tspeed: 0.0054s/iter; left time: 37.0115s\n",
      "\titers: 800, epoch: 3 | loss: 0.5778949\n",
      "\tspeed: 0.0052s/iter; left time: 35.1307s\n",
      "\titers: 900, epoch: 3 | loss: 0.6333322\n",
      "\tspeed: 0.0058s/iter; left time: 38.6660s\n",
      "Epoch: 3 cost time: 6.393604755401611\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.6147147 Vali Loss: 0.9240352 Test Loss: 1.3123982\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5941908\n",
      "\tspeed: 0.2202s/iter; left time: 1440.9481s\n",
      "\titers: 200, epoch: 4 | loss: 0.5715151\n",
      "\tspeed: 0.0078s/iter; left time: 50.0069s\n",
      "\titers: 300, epoch: 4 | loss: 0.5612118\n",
      "\tspeed: 0.0086s/iter; left time: 54.3864s\n",
      "\titers: 400, epoch: 4 | loss: 0.6114111\n",
      "\tspeed: 0.0083s/iter; left time: 51.8694s\n",
      "\titers: 500, epoch: 4 | loss: 0.6089941\n",
      "\tspeed: 0.0077s/iter; left time: 47.4006s\n",
      "\titers: 600, epoch: 4 | loss: 0.6913677\n",
      "\tspeed: 0.0070s/iter; left time: 42.2269s\n",
      "\titers: 700, epoch: 4 | loss: 0.6461498\n",
      "\tspeed: 0.0074s/iter; left time: 44.0765s\n",
      "\titers: 800, epoch: 4 | loss: 0.5203417\n",
      "\tspeed: 0.0075s/iter; left time: 43.9891s\n",
      "\titers: 900, epoch: 4 | loss: 0.6633158\n",
      "\tspeed: 0.0067s/iter; left time: 38.6726s\n",
      "Epoch: 4 cost time: 7.7117180824279785\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.6138270 Vali Loss: 0.9229206 Test Loss: 1.3086909\n",
      "Validation loss decreased (0.923594 --> 0.922921).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5848696\n",
      "\tspeed: 0.2094s/iter; left time: 1171.4618s\n",
      "\titers: 200, epoch: 5 | loss: 0.6291453\n",
      "\tspeed: 0.0074s/iter; left time: 40.5764s\n",
      "\titers: 300, epoch: 5 | loss: 0.5962422\n",
      "\tspeed: 0.0075s/iter; left time: 40.4526s\n",
      "\titers: 400, epoch: 5 | loss: 0.5657960\n",
      "\tspeed: 0.0074s/iter; left time: 39.3405s\n",
      "\titers: 500, epoch: 5 | loss: 0.5804153\n",
      "\tspeed: 0.0071s/iter; left time: 37.1373s\n",
      "\titers: 600, epoch: 5 | loss: 0.5702437\n",
      "\tspeed: 0.0077s/iter; left time: 39.2434s\n",
      "\titers: 700, epoch: 5 | loss: 0.7214497\n",
      "\tspeed: 0.0086s/iter; left time: 42.8015s\n",
      "\titers: 800, epoch: 5 | loss: 0.6568202\n",
      "\tspeed: 0.0088s/iter; left time: 42.8643s\n",
      "\titers: 900, epoch: 5 | loss: 0.5576698\n",
      "\tspeed: 0.0076s/iter; left time: 36.2399s\n",
      "Epoch: 5 cost time: 7.6813201904296875\n",
      "Epoch: 5, Steps: 949 | Train Loss: 0.6134215 Vali Loss: 0.9232787 Test Loss: 1.3114709\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.7381514\n",
      "\tspeed: 0.2680s/iter; left time: 1244.9373s\n",
      "\titers: 200, epoch: 6 | loss: 0.6241431\n",
      "\tspeed: 0.0046s/iter; left time: 20.8244s\n",
      "\titers: 300, epoch: 6 | loss: 0.6293671\n",
      "\tspeed: 0.0046s/iter; left time: 20.5018s\n",
      "\titers: 400, epoch: 6 | loss: 0.6919104\n",
      "\tspeed: 0.0045s/iter; left time: 19.5952s\n",
      "\titers: 500, epoch: 6 | loss: 0.6051923\n",
      "\tspeed: 0.0043s/iter; left time: 18.1334s\n",
      "\titers: 600, epoch: 6 | loss: 0.5317644\n",
      "\tspeed: 0.0039s/iter; left time: 16.1352s\n",
      "\titers: 700, epoch: 6 | loss: 0.5505164\n",
      "\tspeed: 0.0045s/iter; left time: 18.4019s\n",
      "\titers: 800, epoch: 6 | loss: 0.6031919\n",
      "\tspeed: 0.0035s/iter; left time: 13.6828s\n",
      "\titers: 900, epoch: 6 | loss: 0.6652617\n",
      "\tspeed: 0.0040s/iter; left time: 15.3299s\n",
      "Epoch: 6 cost time: 4.447000026702881\n",
      "Epoch: 6, Steps: 949 | Train Loss: 0.6132466 Vali Loss: 0.9233450 Test Loss: 1.3069040\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.5605013\n",
      "\tspeed: 0.2316s/iter; left time: 856.1230s\n",
      "\titers: 200, epoch: 7 | loss: 0.6049776\n",
      "\tspeed: 0.0035s/iter; left time: 12.5588s\n",
      "\titers: 300, epoch: 7 | loss: 0.6997967\n",
      "\tspeed: 0.0032s/iter; left time: 11.3623s\n",
      "\titers: 400, epoch: 7 | loss: 0.6490803\n",
      "\tspeed: 0.0033s/iter; left time: 11.2613s\n",
      "\titers: 500, epoch: 7 | loss: 0.6479628\n",
      "\tspeed: 0.0033s/iter; left time: 10.7884s\n",
      "\titers: 600, epoch: 7 | loss: 0.6186277\n",
      "\tspeed: 0.0033s/iter; left time: 10.5554s\n",
      "\titers: 700, epoch: 7 | loss: 0.6063186\n",
      "\tspeed: 0.0033s/iter; left time: 10.2093s\n",
      "\titers: 800, epoch: 7 | loss: 0.6408663\n",
      "\tspeed: 0.0033s/iter; left time: 9.8185s\n",
      "\titers: 900, epoch: 7 | loss: 0.6837451\n",
      "\tspeed: 0.0033s/iter; left time: 9.4423s\n",
      "Epoch: 7 cost time: 3.7048418521881104\n",
      "Epoch: 7, Steps: 949 | Train Loss: 0.6131512 Vali Loss: 0.9232070 Test Loss: 1.3074967\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 21) (8567, 1, 192, 21)\n",
      "test shape: (8567, 192, 21) (8567, 192, 21)\n",
      "mse:1.3086904287338257, mae:0.7732447385787964\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.7412403\n",
      "\tspeed: 0.0087s/iter; left time: 81.6029s\n",
      "\titers: 200, epoch: 1 | loss: 0.6235813\n",
      "\tspeed: 0.0037s/iter; left time: 34.7242s\n",
      "\titers: 300, epoch: 1 | loss: 0.7068754\n",
      "\tspeed: 0.0033s/iter; left time: 30.7813s\n",
      "\titers: 400, epoch: 1 | loss: 0.6995685\n",
      "\tspeed: 0.0033s/iter; left time: 30.2000s\n",
      "\titers: 500, epoch: 1 | loss: 0.7774752\n",
      "\tspeed: 0.0033s/iter; left time: 29.5982s\n",
      "\titers: 600, epoch: 1 | loss: 0.5991845\n",
      "\tspeed: 0.0033s/iter; left time: 29.2391s\n",
      "\titers: 700, epoch: 1 | loss: 0.6425518\n",
      "\tspeed: 0.0033s/iter; left time: 28.6014s\n",
      "\titers: 800, epoch: 1 | loss: 0.6578235\n",
      "\tspeed: 0.0033s/iter; left time: 28.5477s\n",
      "\titers: 900, epoch: 1 | loss: 0.6561489\n",
      "\tspeed: 0.0033s/iter; left time: 28.5767s\n",
      "Epoch: 1 cost time: 3.8152382373809814\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.6614283 Vali Loss: 0.9329634 Test Loss: 1.3264709\n",
      "Validation loss decreased (inf --> 0.932963).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5563145\n",
      "\tspeed: 0.2366s/iter; left time: 1997.7653s\n",
      "\titers: 200, epoch: 2 | loss: 0.5536387\n",
      "\tspeed: 0.0035s/iter; left time: 29.1724s\n",
      "\titers: 300, epoch: 2 | loss: 0.6059283\n",
      "\tspeed: 0.0035s/iter; left time: 29.0652s\n",
      "\titers: 400, epoch: 2 | loss: 0.7241881\n",
      "\tspeed: 0.0034s/iter; left time: 27.2910s\n",
      "\titers: 500, epoch: 2 | loss: 0.5670480\n",
      "\tspeed: 0.0034s/iter; left time: 27.4834s\n",
      "\titers: 600, epoch: 2 | loss: 0.6105068\n",
      "\tspeed: 0.0034s/iter; left time: 26.8229s\n",
      "\titers: 700, epoch: 2 | loss: 0.6135352\n",
      "\tspeed: 0.0034s/iter; left time: 26.7238s\n",
      "\titers: 800, epoch: 2 | loss: 0.5407314\n",
      "\tspeed: 0.0034s/iter; left time: 26.1466s\n",
      "\titers: 900, epoch: 2 | loss: 0.5862910\n",
      "\tspeed: 0.0034s/iter; left time: 25.8050s\n",
      "Epoch: 2 cost time: 3.939208984375\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.6176979 Vali Loss: 0.9267133 Test Loss: 1.3146257\n",
      "Validation loss decreased (0.932963 --> 0.926713).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6978564\n",
      "\tspeed: 0.2472s/iter; left time: 1852.1571s\n",
      "\titers: 200, epoch: 3 | loss: 0.5716848\n",
      "\tspeed: 0.0037s/iter; left time: 27.6439s\n",
      "\titers: 300, epoch: 3 | loss: 0.5346519\n",
      "\tspeed: 0.0039s/iter; left time: 28.2101s\n",
      "\titers: 400, epoch: 3 | loss: 0.6531712\n",
      "\tspeed: 0.0037s/iter; left time: 26.5734s\n",
      "\titers: 500, epoch: 3 | loss: 0.6485257\n",
      "\tspeed: 0.0036s/iter; left time: 25.8835s\n",
      "\titers: 600, epoch: 3 | loss: 0.5579225\n",
      "\tspeed: 0.0044s/iter; left time: 30.9268s\n",
      "\titers: 700, epoch: 3 | loss: 0.5197146\n",
      "\tspeed: 0.0039s/iter; left time: 26.9214s\n",
      "\titers: 800, epoch: 3 | loss: 0.6357027\n",
      "\tspeed: 0.0040s/iter; left time: 27.1191s\n",
      "\titers: 900, epoch: 3 | loss: 0.5880994\n",
      "\tspeed: 0.0040s/iter; left time: 26.8010s\n",
      "Epoch: 3 cost time: 4.280365705490112\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.6147362 Vali Loss: 0.9264191 Test Loss: 1.3169925\n",
      "Validation loss decreased (0.926713 --> 0.926419).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5343788\n",
      "\tspeed: 0.2863s/iter; left time: 1873.6094s\n",
      "\titers: 200, epoch: 4 | loss: 0.6728355\n",
      "\tspeed: 0.0047s/iter; left time: 30.3000s\n",
      "\titers: 300, epoch: 4 | loss: 0.6356239\n",
      "\tspeed: 0.0045s/iter; left time: 28.3477s\n",
      "\titers: 400, epoch: 4 | loss: 0.6009871\n",
      "\tspeed: 0.0038s/iter; left time: 23.5002s\n",
      "\titers: 500, epoch: 4 | loss: 0.6077766\n",
      "\tspeed: 0.0037s/iter; left time: 22.4912s\n",
      "\titers: 600, epoch: 4 | loss: 0.6132036\n",
      "\tspeed: 0.0039s/iter; left time: 23.6931s\n",
      "\titers: 700, epoch: 4 | loss: 0.5256234\n",
      "\tspeed: 0.0041s/iter; left time: 24.1720s\n",
      "\titers: 800, epoch: 4 | loss: 0.6465350\n",
      "\tspeed: 0.0036s/iter; left time: 21.1213s\n",
      "\titers: 900, epoch: 4 | loss: 0.5981991\n",
      "\tspeed: 0.0049s/iter; left time: 28.1339s\n",
      "Epoch: 4 cost time: 4.517263650894165\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.6137977 Vali Loss: 0.9221500 Test Loss: 1.3056102\n",
      "Validation loss decreased (0.926419 --> 0.922150).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6510644\n",
      "\tspeed: 0.2395s/iter; left time: 1340.0352s\n",
      "\titers: 200, epoch: 5 | loss: 0.6763455\n",
      "\tspeed: 0.0034s/iter; left time: 18.6248s\n",
      "\titers: 300, epoch: 5 | loss: 0.5828718\n",
      "\tspeed: 0.0034s/iter; left time: 18.4062s\n",
      "\titers: 400, epoch: 5 | loss: 0.5566615\n",
      "\tspeed: 0.0033s/iter; left time: 17.6946s\n",
      "\titers: 500, epoch: 5 | loss: 0.6010539\n",
      "\tspeed: 0.0037s/iter; left time: 19.2772s\n",
      "\titers: 600, epoch: 5 | loss: 0.6751179\n",
      "\tspeed: 0.0037s/iter; left time: 19.0235s\n",
      "\titers: 700, epoch: 5 | loss: 0.6505671\n",
      "\tspeed: 0.0033s/iter; left time: 16.3854s\n",
      "\titers: 800, epoch: 5 | loss: 0.7420129\n",
      "\tspeed: 0.0034s/iter; left time: 16.6984s\n",
      "\titers: 900, epoch: 5 | loss: 0.6346502\n",
      "\tspeed: 0.0034s/iter; left time: 16.1860s\n",
      "Epoch: 5 cost time: 4.020857810974121\n",
      "Epoch: 5, Steps: 949 | Train Loss: 0.6134353 Vali Loss: 0.9217957 Test Loss: 1.3084486\n",
      "Validation loss decreased (0.922150 --> 0.921796).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.5831056\n",
      "\tspeed: 0.2284s/iter; left time: 1061.3214s\n",
      "\titers: 200, epoch: 6 | loss: 0.7405839\n",
      "\tspeed: 0.0039s/iter; left time: 17.6835s\n",
      "\titers: 300, epoch: 6 | loss: 0.6534559\n",
      "\tspeed: 0.0038s/iter; left time: 16.7719s\n",
      "\titers: 400, epoch: 6 | loss: 0.6074966\n",
      "\tspeed: 0.0035s/iter; left time: 15.2515s\n",
      "\titers: 500, epoch: 6 | loss: 0.6262890\n",
      "\tspeed: 0.0033s/iter; left time: 13.9079s\n",
      "\titers: 600, epoch: 6 | loss: 0.5541050\n",
      "\tspeed: 0.0033s/iter; left time: 13.6557s\n",
      "\titers: 700, epoch: 6 | loss: 0.5234795\n",
      "\tspeed: 0.0032s/iter; left time: 13.0650s\n",
      "\titers: 800, epoch: 6 | loss: 0.6815802\n",
      "\tspeed: 0.0033s/iter; left time: 13.1271s\n",
      "\titers: 900, epoch: 6 | loss: 0.7307113\n",
      "\tspeed: 0.0034s/iter; left time: 12.9010s\n",
      "Epoch: 6 cost time: 3.928558826446533\n",
      "Epoch: 6, Steps: 949 | Train Loss: 0.6132466 Vali Loss: 0.9232858 Test Loss: 1.3081024\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.6763971\n",
      "\tspeed: 0.2094s/iter; left time: 774.3313s\n",
      "\titers: 200, epoch: 7 | loss: 0.6046839\n",
      "\tspeed: 0.0084s/iter; left time: 30.0912s\n",
      "\titers: 300, epoch: 7 | loss: 0.6608743\n",
      "\tspeed: 0.0060s/iter; left time: 20.9755s\n",
      "\titers: 400, epoch: 7 | loss: 0.6899745\n",
      "\tspeed: 0.0075s/iter; left time: 25.6292s\n",
      "\titers: 500, epoch: 7 | loss: 0.6244701\n",
      "\tspeed: 0.0061s/iter; left time: 20.1802s\n",
      "\titers: 600, epoch: 7 | loss: 0.6384085\n",
      "\tspeed: 0.0058s/iter; left time: 18.4914s\n",
      "\titers: 700, epoch: 7 | loss: 0.5696022\n",
      "\tspeed: 0.0053s/iter; left time: 16.4661s\n",
      "\titers: 800, epoch: 7 | loss: 0.5350211\n",
      "\tspeed: 0.0049s/iter; left time: 14.5773s\n",
      "\titers: 900, epoch: 7 | loss: 0.6368096\n",
      "\tspeed: 0.0044s/iter; left time: 12.8455s\n",
      "Epoch: 7 cost time: 6.735110521316528\n",
      "Epoch: 7, Steps: 949 | Train Loss: 0.6131511 Vali Loss: 0.9220935 Test Loss: 1.3078815\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.6667309\n",
      "\tspeed: 0.2195s/iter; left time: 603.0775s\n",
      "\titers: 200, epoch: 8 | loss: 0.6033069\n",
      "\tspeed: 0.0077s/iter; left time: 20.3432s\n",
      "\titers: 300, epoch: 8 | loss: 0.5922358\n",
      "\tspeed: 0.0075s/iter; left time: 19.0964s\n",
      "\titers: 400, epoch: 8 | loss: 0.5707684\n",
      "\tspeed: 0.0084s/iter; left time: 20.4608s\n",
      "\titers: 500, epoch: 8 | loss: 0.6419098\n",
      "\tspeed: 0.0074s/iter; left time: 17.3422s\n",
      "\titers: 600, epoch: 8 | loss: 0.6110275\n",
      "\tspeed: 0.0067s/iter; left time: 15.1074s\n",
      "\titers: 700, epoch: 8 | loss: 0.7216200\n",
      "\tspeed: 0.0066s/iter; left time: 14.1060s\n",
      "\titers: 800, epoch: 8 | loss: 0.5937975\n",
      "\tspeed: 0.0067s/iter; left time: 13.7810s\n",
      "\titers: 900, epoch: 8 | loss: 0.7020833\n",
      "\tspeed: 0.0065s/iter; left time: 12.7161s\n",
      "Epoch: 8 cost time: 7.5788140296936035\n",
      "Epoch: 8, Steps: 949 | Train Loss: 0.6131024 Vali Loss: 0.9219027 Test Loss: 1.3076013\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__192_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 21) (8567, 1, 192, 21)\n",
      "test shape: (8567, 192, 21) (8567, 192, 21)\n",
      "mse:1.308445930480957, mae:0.7730171084403992\n",
      "\n",
      "Extracted Part: long_term_forecast__192_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__192_df_only_generation_columns_DLinear_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n"
     ]
    }
   ],
   "source": [
    "# List of data paths and prediction lengths for the grid search\n",
    "data_paths = [\"df_all_columns.csv\", \"df_most_important_columns.csv\", \"df_only_generation_columns.csv\"]\n",
    "prediction_lengths = [\"24\", \"48\", \"96\", \"192\"]\n",
    "for data_path in data_paths:\n",
    "    full_data_path = \"../../../01_datasets/\" + data_path\n",
    "    df = pd.read_csv(full_data_path)\n",
    "    num_columns = len(df.columns)\n",
    "    for pred_len in prediction_lengths:\n",
    "        # Define the script arguments as a list\n",
    "        model_id = f\"_{pred_len}_{data_path.replace('.csv', '')}\"  # Create the model_id\n",
    "        script_arguments = [\n",
    "            \"--task_name\", \"long_term_forecast\",\n",
    "            \"--is_training\", \"1\",\n",
    "            \"--root_path\", \"../../../01_datasets/\",\n",
    "            \"--data_path\", data_path,\n",
    "            \"--model_id\", model_id,\n",
    "            \"--model\", \"DLinear\",\n",
    "            \"--data\", \"custom\",\n",
    "            \"--features\", \"M\",\n",
    "            \"--seq_len\", \"96\",\n",
    "            \"--label_len\", \"48\",\n",
    "            \"--pred_len\", pred_len,\n",
    "            \"--e_layers\", \"2\",\n",
    "            \"--d_layers\", \"5\",\n",
    "            \"--factor\", \"5\",\n",
    "            \"--enc_in\", str((num_columns)-1),\n",
    "            \"--dec_in\", str((num_columns)-1),\n",
    "            \"--c_out\", str((num_columns)-1),\n",
    "            \"--des\", \"Exp\",\n",
    "            \"--itr\", \"2\"\n",
    "        ]\n",
    "\n",
    "        script_output = run_and_capture_script_output(script_path, script_arguments)\n",
    "\n",
    "        # Print the captured output\n",
    "        print(\"Captured Output:\")\n",
    "        print(script_output)\n",
    "\n",
    "        # Extract and save the prints related to the settings variable\n",
    "        settings_prints = extract_settings_prints(script_output.splitlines())\n",
    "\n",
    "        matched_patterns = pattern_matching(settings_prints)\n",
    "\n",
    "        summarize_results(matched_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6040f02-5600-4420-8f65-9a19659c538e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=1, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=1, factor=5, features='S', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_24_DE_load_actual_entsoe_transparency', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=24, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='DE_load_actual_entsoe_transparency', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.5987527\n",
      "\tspeed: 0.0113s/iter; left time: 106.8065s\n",
      "\titers: 200, epoch: 1 | loss: 0.4189038\n",
      "\tspeed: 0.0026s/iter; left time: 24.5278s\n",
      "\titers: 300, epoch: 1 | loss: 0.4135056\n",
      "\tspeed: 0.0026s/iter; left time: 24.0440s\n",
      "\titers: 400, epoch: 1 | loss: 0.3461804\n",
      "\tspeed: 0.0028s/iter; left time: 25.6322s\n",
      "\titers: 500, epoch: 1 | loss: 0.4206334\n",
      "\tspeed: 0.0025s/iter; left time: 22.5974s\n",
      "\titers: 600, epoch: 1 | loss: 0.3735647\n",
      "\tspeed: 0.0025s/iter; left time: 22.2422s\n",
      "\titers: 700, epoch: 1 | loss: 0.2483551\n",
      "\tspeed: 0.0026s/iter; left time: 23.4176s\n",
      "\titers: 800, epoch: 1 | loss: 0.3215957\n",
      "\tspeed: 0.0024s/iter; left time: 20.9671s\n",
      "\titers: 900, epoch: 1 | loss: 0.2733242\n",
      "\tspeed: 0.0033s/iter; left time: 28.8442s\n",
      "Epoch: 1 cost time: 3.5065760612487793\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.3940975 Vali Loss: 0.2620778 Test Loss: 0.2793522\n",
      "Validation loss decreased (inf --> 0.262078).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2774173\n",
      "\tspeed: 0.1789s/iter; left time: 1518.5664s\n",
      "\titers: 200, epoch: 2 | loss: 0.3092009\n",
      "\tspeed: 0.0039s/iter; left time: 32.4416s\n",
      "\titers: 300, epoch: 2 | loss: 0.2007490\n",
      "\tspeed: 0.0040s/iter; left time: 33.1564s\n",
      "\titers: 400, epoch: 2 | loss: 0.2438910\n",
      "\tspeed: 0.0032s/iter; left time: 26.2647s\n",
      "\titers: 500, epoch: 2 | loss: 0.3014842\n",
      "\tspeed: 0.0029s/iter; left time: 23.3048s\n",
      "\titers: 600, epoch: 2 | loss: 0.3606480\n",
      "\tspeed: 0.0027s/iter; left time: 21.1699s\n",
      "\titers: 700, epoch: 2 | loss: 0.3645222\n",
      "\tspeed: 0.0027s/iter; left time: 21.5506s\n",
      "\titers: 800, epoch: 2 | loss: 0.1893804\n",
      "\tspeed: 0.0027s/iter; left time: 21.3144s\n",
      "\titers: 900, epoch: 2 | loss: 0.3271329\n",
      "\tspeed: 0.0027s/iter; left time: 20.7714s\n",
      "Epoch: 2 cost time: 3.428565263748169\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.2693340 Vali Loss: 0.2362270 Test Loss: 0.2518581\n",
      "Validation loss decreased (0.262078 --> 0.236227).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2944123\n",
      "\tspeed: 0.1963s/iter; left time: 1478.6272s\n",
      "\titers: 200, epoch: 3 | loss: 0.2982554\n",
      "\tspeed: 0.0039s/iter; left time: 29.1822s\n",
      "\titers: 300, epoch: 3 | loss: 0.2037187\n",
      "\tspeed: 0.0036s/iter; left time: 26.2627s\n",
      "\titers: 400, epoch: 3 | loss: 0.1929087\n",
      "\tspeed: 0.0037s/iter; left time: 26.8399s\n",
      "\titers: 500, epoch: 3 | loss: 0.3087311\n",
      "\tspeed: 0.0029s/iter; left time: 20.5191s\n",
      "\titers: 600, epoch: 3 | loss: 0.3504612\n",
      "\tspeed: 0.0027s/iter; left time: 18.8854s\n",
      "\titers: 700, epoch: 3 | loss: 0.2508509\n",
      "\tspeed: 0.0027s/iter; left time: 18.4892s\n",
      "\titers: 800, epoch: 3 | loss: 0.2402859\n",
      "\tspeed: 0.0029s/iter; left time: 19.5761s\n",
      "\titers: 900, epoch: 3 | loss: 0.1986448\n",
      "\tspeed: 0.0027s/iter; left time: 17.8637s\n",
      "Epoch: 3 cost time: 3.4650862216949463\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.2548624 Vali Loss: 0.2297928 Test Loss: 0.2448166\n",
      "Validation loss decreased (0.236227 --> 0.229793).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1607059\n",
      "\tspeed: 0.1881s/iter; left time: 1237.3598s\n",
      "\titers: 200, epoch: 4 | loss: 0.1755060\n",
      "\tspeed: 0.0059s/iter; left time: 38.3856s\n",
      "\titers: 300, epoch: 4 | loss: 0.2293358\n",
      "\tspeed: 0.0038s/iter; left time: 24.0271s\n",
      "\titers: 400, epoch: 4 | loss: 0.2398625\n",
      "\tspeed: 0.0032s/iter; left time: 20.2037s\n",
      "\titers: 500, epoch: 4 | loss: 0.3227718\n",
      "\tspeed: 0.0027s/iter; left time: 16.5596s\n",
      "\titers: 600, epoch: 4 | loss: 0.2610574\n",
      "\tspeed: 0.0027s/iter; left time: 16.3122s\n",
      "\titers: 700, epoch: 4 | loss: 0.2122498\n",
      "\tspeed: 0.0035s/iter; left time: 20.9455s\n",
      "\titers: 800, epoch: 4 | loss: 0.2095971\n",
      "\tspeed: 0.0032s/iter; left time: 18.6211s\n",
      "\titers: 900, epoch: 4 | loss: 0.2963974\n",
      "\tspeed: 0.0030s/iter; left time: 17.3562s\n",
      "Epoch: 4 cost time: 3.965886116027832\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.2503711 Vali Loss: 0.2274989 Test Loss: 0.2422928\n",
      "Validation loss decreased (0.229793 --> 0.227499).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2170069\n",
      "\tspeed: 0.1999s/iter; left time: 1124.2424s\n",
      "\titers: 200, epoch: 5 | loss: 0.2548330\n",
      "\tspeed: 0.0029s/iter; left time: 15.8515s\n",
      "\titers: 300, epoch: 5 | loss: 0.1952823\n",
      "\tspeed: 0.0029s/iter; left time: 15.5711s\n",
      "\titers: 400, epoch: 5 | loss: 0.2354862\n",
      "\tspeed: 0.0033s/iter; left time: 17.5993s\n",
      "\titers: 500, epoch: 5 | loss: 0.3756865\n",
      "\tspeed: 0.0036s/iter; left time: 19.0260s\n",
      "\titers: 600, epoch: 5 | loss: 0.2330275\n",
      "\tspeed: 0.0034s/iter; left time: 17.5281s\n",
      "\titers: 700, epoch: 5 | loss: 0.2113644\n",
      "\tspeed: 0.0032s/iter; left time: 16.0804s\n",
      "\titers: 800, epoch: 5 | loss: 0.2582574\n",
      "\tspeed: 0.0028s/iter; left time: 13.9775s\n",
      "\titers: 900, epoch: 5 | loss: 0.2244070\n",
      "\tspeed: 0.0027s/iter; left time: 13.0984s\n",
      "Epoch: 5 cost time: 3.3683857917785645\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.2485566 Vali Loss: 0.2264541 Test Loss: 0.2411741\n",
      "Validation loss decreased (0.227499 --> 0.226454).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2425296\n",
      "\tspeed: 0.1870s/iter; left time: 873.5791s\n",
      "\titers: 200, epoch: 6 | loss: 0.2333851\n",
      "\tspeed: 0.0038s/iter; left time: 17.1477s\n",
      "\titers: 300, epoch: 6 | loss: 0.2393568\n",
      "\tspeed: 0.0032s/iter; left time: 14.1703s\n",
      "\titers: 400, epoch: 6 | loss: 0.1932536\n",
      "\tspeed: 0.0032s/iter; left time: 14.1840s\n",
      "\titers: 500, epoch: 6 | loss: 0.2157643\n",
      "\tspeed: 0.0036s/iter; left time: 15.2717s\n",
      "\titers: 600, epoch: 6 | loss: 0.2430618\n",
      "\tspeed: 0.0033s/iter; left time: 13.9541s\n",
      "\titers: 700, epoch: 6 | loss: 0.2668530\n",
      "\tspeed: 0.0031s/iter; left time: 12.5204s\n",
      "\titers: 800, epoch: 6 | loss: 0.2603140\n",
      "\tspeed: 0.0039s/iter; left time: 15.6340s\n",
      "\titers: 900, epoch: 6 | loss: 0.1978896\n",
      "\tspeed: 0.0032s/iter; left time: 12.4262s\n",
      "Epoch: 6 cost time: 3.7849864959716797\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.2476447 Vali Loss: 0.2261603 Test Loss: 0.2407361\n",
      "Validation loss decreased (0.226454 --> 0.226160).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2370630\n",
      "\tspeed: 0.2374s/iter; left time: 882.5490s\n",
      "\titers: 200, epoch: 7 | loss: 0.2248797\n",
      "\tspeed: 0.0048s/iter; left time: 17.3071s\n",
      "\titers: 300, epoch: 7 | loss: 0.2243896\n",
      "\tspeed: 0.0043s/iter; left time: 15.0371s\n",
      "\titers: 400, epoch: 7 | loss: 0.2705558\n",
      "\tspeed: 0.0037s/iter; left time: 12.6708s\n",
      "\titers: 500, epoch: 7 | loss: 0.2005506\n",
      "\tspeed: 0.0055s/iter; left time: 18.3523s\n",
      "\titers: 600, epoch: 7 | loss: 0.2662007\n",
      "\tspeed: 0.0047s/iter; left time: 15.2094s\n",
      "\titers: 700, epoch: 7 | loss: 0.2166704\n",
      "\tspeed: 0.0042s/iter; left time: 13.0883s\n",
      "\titers: 800, epoch: 7 | loss: 0.2437537\n",
      "\tspeed: 0.0042s/iter; left time: 12.6281s\n",
      "\titers: 900, epoch: 7 | loss: 0.2961848\n",
      "\tspeed: 0.0045s/iter; left time: 13.0784s\n",
      "Epoch: 7 cost time: 4.749915838241577\n",
      "Epoch: 7, Steps: 954 | Train Loss: 0.2472361 Vali Loss: 0.2257752 Test Loss: 0.2404435\n",
      "Validation loss decreased (0.226160 --> 0.225775).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2393439\n",
      "\tspeed: 0.2168s/iter; left time: 598.8961s\n",
      "\titers: 200, epoch: 8 | loss: 0.3330704\n",
      "\tspeed: 0.0043s/iter; left time: 11.3331s\n",
      "\titers: 300, epoch: 8 | loss: 0.2024314\n",
      "\tspeed: 0.0037s/iter; left time: 9.3731s\n",
      "\titers: 400, epoch: 8 | loss: 0.1984025\n",
      "\tspeed: 0.0032s/iter; left time: 8.0000s\n",
      "\titers: 500, epoch: 8 | loss: 0.1965359\n",
      "\tspeed: 0.0037s/iter; left time: 8.7127s\n",
      "\titers: 600, epoch: 8 | loss: 0.2119753\n",
      "\tspeed: 0.0041s/iter; left time: 9.3290s\n",
      "\titers: 700, epoch: 8 | loss: 0.2567915\n",
      "\tspeed: 0.0035s/iter; left time: 7.6619s\n",
      "\titers: 800, epoch: 8 | loss: 0.2250864\n",
      "\tspeed: 0.0037s/iter; left time: 7.6143s\n",
      "\titers: 900, epoch: 8 | loss: 0.2731214\n",
      "\tspeed: 0.0038s/iter; left time: 7.4155s\n",
      "Epoch: 8 cost time: 3.9462413787841797\n",
      "Epoch: 8, Steps: 954 | Train Loss: 0.2470461 Vali Loss: 0.2257122 Test Loss: 0.2402965\n",
      "Validation loss decreased (0.225775 --> 0.225712).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2844865\n",
      "\tspeed: 0.2421s/iter; left time: 437.9229s\n",
      "\titers: 200, epoch: 9 | loss: 0.2586614\n",
      "\tspeed: 0.0032s/iter; left time: 5.5408s\n",
      "\titers: 300, epoch: 9 | loss: 0.3069305\n",
      "\tspeed: 0.0043s/iter; left time: 6.8391s\n",
      "\titers: 400, epoch: 9 | loss: 0.1972503\n",
      "\tspeed: 0.0038s/iter; left time: 5.8027s\n",
      "\titers: 500, epoch: 9 | loss: 0.1993625\n",
      "\tspeed: 0.0044s/iter; left time: 6.2259s\n",
      "\titers: 600, epoch: 9 | loss: 0.2078289\n",
      "\tspeed: 0.0041s/iter; left time: 5.4310s\n",
      "\titers: 700, epoch: 9 | loss: 0.2908339\n",
      "\tspeed: 0.0049s/iter; left time: 5.9633s\n",
      "\titers: 800, epoch: 9 | loss: 0.2540832\n",
      "\tspeed: 0.0046s/iter; left time: 5.0672s\n",
      "\titers: 900, epoch: 9 | loss: 0.1888669\n",
      "\tspeed: 0.0043s/iter; left time: 4.3098s\n",
      "Epoch: 9 cost time: 4.430795431137085\n",
      "Epoch: 9, Steps: 954 | Train Loss: 0.2468380 Vali Loss: 0.2256439 Test Loss: 0.2402255\n",
      "Validation loss decreased (0.225712 --> 0.225644).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2024237\n",
      "\tspeed: 0.2447s/iter; left time: 209.2139s\n",
      "\titers: 200, epoch: 10 | loss: 0.1797341\n",
      "\tspeed: 0.0041s/iter; left time: 3.0587s\n",
      "\titers: 300, epoch: 10 | loss: 0.1698824\n",
      "\tspeed: 0.0037s/iter; left time: 2.4271s\n",
      "\titers: 400, epoch: 10 | loss: 0.2913532\n",
      "\tspeed: 0.0033s/iter; left time: 1.8222s\n",
      "\titers: 500, epoch: 10 | loss: 0.2097488\n",
      "\tspeed: 0.0038s/iter; left time: 1.7442s\n",
      "\titers: 600, epoch: 10 | loss: 0.3022826\n",
      "\tspeed: 0.0038s/iter; left time: 1.3624s\n",
      "\titers: 700, epoch: 10 | loss: 0.2114102\n",
      "\tspeed: 0.0032s/iter; left time: 0.8226s\n",
      "\titers: 800, epoch: 10 | loss: 0.2130479\n",
      "\tspeed: 0.0038s/iter; left time: 0.5869s\n",
      "\titers: 900, epoch: 10 | loss: 0.2187411\n",
      "\tspeed: 0.0032s/iter; left time: 0.1739s\n",
      "Epoch: 10 cost time: 3.8944220542907715\n",
      "Epoch: 10, Steps: 954 | Train Loss: 0.2468684 Vali Loss: 0.2256952 Test Loss: 0.2401927\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__24_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 1) (8735, 1, 24, 1)\n",
      "test shape: (8735, 24, 1) (8735, 24, 1)\n",
      "mse:0.2402254343032837, mae:0.3561086356639862\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__24_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30536\n",
      "val 4357\n",
      "test 8735\n",
      "\titers: 100, epoch: 1 | loss: 0.6032706\n",
      "\tspeed: 0.0078s/iter; left time: 73.3085s\n",
      "\titers: 200, epoch: 1 | loss: 0.4927149\n",
      "\tspeed: 0.0042s/iter; left time: 39.3255s\n",
      "\titers: 300, epoch: 1 | loss: 0.4010225\n",
      "\tspeed: 0.0053s/iter; left time: 48.7917s\n",
      "\titers: 400, epoch: 1 | loss: 0.3270592\n",
      "\tspeed: 0.0059s/iter; left time: 53.9466s\n",
      "\titers: 500, epoch: 1 | loss: 0.3176008\n",
      "\tspeed: 0.0056s/iter; left time: 50.6219s\n",
      "\titers: 600, epoch: 1 | loss: 0.2843894\n",
      "\tspeed: 0.0056s/iter; left time: 50.3447s\n",
      "\titers: 700, epoch: 1 | loss: 0.3940486\n",
      "\tspeed: 0.0056s/iter; left time: 49.1635s\n",
      "\titers: 800, epoch: 1 | loss: 0.2198053\n",
      "\tspeed: 0.0059s/iter; left time: 51.3819s\n",
      "\titers: 900, epoch: 1 | loss: 0.2889094\n",
      "\tspeed: 0.0059s/iter; left time: 50.9904s\n",
      "Epoch: 1 cost time: 5.5195393562316895\n",
      "Epoch: 1, Steps: 954 | Train Loss: 0.3925256 Vali Loss: 0.2604612 Test Loss: 0.2773780\n",
      "Validation loss decreased (inf --> 0.260461).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2840925\n",
      "\tspeed: 0.2322s/iter; left time: 1970.4510s\n",
      "\titers: 200, epoch: 2 | loss: 0.3404402\n",
      "\tspeed: 0.0041s/iter; left time: 34.2696s\n",
      "\titers: 300, epoch: 2 | loss: 0.3150922\n",
      "\tspeed: 0.0041s/iter; left time: 34.0087s\n",
      "\titers: 400, epoch: 2 | loss: 0.2583388\n",
      "\tspeed: 0.0048s/iter; left time: 39.2896s\n",
      "\titers: 500, epoch: 2 | loss: 0.1952375\n",
      "\tspeed: 0.0044s/iter; left time: 35.5818s\n",
      "\titers: 600, epoch: 2 | loss: 0.3294868\n",
      "\tspeed: 0.0046s/iter; left time: 36.7228s\n",
      "\titers: 700, epoch: 2 | loss: 0.2930320\n",
      "\tspeed: 0.0042s/iter; left time: 33.4252s\n",
      "\titers: 800, epoch: 2 | loss: 0.2616132\n",
      "\tspeed: 0.0043s/iter; left time: 33.8261s\n",
      "\titers: 900, epoch: 2 | loss: 0.2190351\n",
      "\tspeed: 0.0042s/iter; left time: 32.4113s\n",
      "Epoch: 2 cost time: 4.645179271697998\n",
      "Epoch: 2, Steps: 954 | Train Loss: 0.2685420 Vali Loss: 0.2366185 Test Loss: 0.2521005\n",
      "Validation loss decreased (0.260461 --> 0.236618).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1170564\n",
      "\tspeed: 0.2320s/iter; left time: 1747.8545s\n",
      "\titers: 200, epoch: 3 | loss: 0.3092390\n",
      "\tspeed: 0.0047s/iter; left time: 35.1142s\n",
      "\titers: 300, epoch: 3 | loss: 0.3020942\n",
      "\tspeed: 0.0048s/iter; left time: 34.9241s\n",
      "\titers: 400, epoch: 3 | loss: 0.2569566\n",
      "\tspeed: 0.0056s/iter; left time: 40.5785s\n",
      "\titers: 500, epoch: 3 | loss: 0.3145992\n",
      "\tspeed: 0.0046s/iter; left time: 33.0527s\n",
      "\titers: 600, epoch: 3 | loss: 0.2388132\n",
      "\tspeed: 0.0047s/iter; left time: 33.1424s\n",
      "\titers: 700, epoch: 3 | loss: 0.2564439\n",
      "\tspeed: 0.0046s/iter; left time: 32.1438s\n",
      "\titers: 800, epoch: 3 | loss: 0.2283828\n",
      "\tspeed: 0.0048s/iter; left time: 33.1034s\n",
      "\titers: 900, epoch: 3 | loss: 0.3615120\n",
      "\tspeed: 0.0053s/iter; left time: 35.7672s\n",
      "Epoch: 3 cost time: 5.157703399658203\n",
      "Epoch: 3, Steps: 954 | Train Loss: 0.2548271 Vali Loss: 0.2294571 Test Loss: 0.2449699\n",
      "Validation loss decreased (0.236618 --> 0.229457).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3724833\n",
      "\tspeed: 0.2559s/iter; left time: 1683.4169s\n",
      "\titers: 200, epoch: 4 | loss: 0.2633063\n",
      "\tspeed: 0.0042s/iter; left time: 26.9537s\n",
      "\titers: 300, epoch: 4 | loss: 0.2244842\n",
      "\tspeed: 0.0041s/iter; left time: 26.3206s\n",
      "\titers: 400, epoch: 4 | loss: 0.2859281\n",
      "\tspeed: 0.0043s/iter; left time: 27.2230s\n",
      "\titers: 500, epoch: 4 | loss: 0.1954232\n",
      "\tspeed: 0.0044s/iter; left time: 27.2895s\n",
      "\titers: 600, epoch: 4 | loss: 0.2754408\n",
      "\tspeed: 0.0046s/iter; left time: 28.0048s\n",
      "\titers: 700, epoch: 4 | loss: 0.2680587\n",
      "\tspeed: 0.0043s/iter; left time: 25.8781s\n",
      "\titers: 800, epoch: 4 | loss: 0.1775146\n",
      "\tspeed: 0.0046s/iter; left time: 26.8988s\n",
      "\titers: 900, epoch: 4 | loss: 0.1946908\n",
      "\tspeed: 0.0042s/iter; left time: 24.0200s\n",
      "Epoch: 4 cost time: 4.56308388710022\n",
      "Epoch: 4, Steps: 954 | Train Loss: 0.2504433 Vali Loss: 0.2272786 Test Loss: 0.2423220\n",
      "Validation loss decreased (0.229457 --> 0.227279).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2433163\n",
      "\tspeed: 0.2377s/iter; left time: 1337.1204s\n",
      "\titers: 200, epoch: 5 | loss: 0.2358552\n",
      "\tspeed: 0.0036s/iter; left time: 20.0024s\n",
      "\titers: 300, epoch: 5 | loss: 0.2076288\n",
      "\tspeed: 0.0032s/iter; left time: 17.5989s\n",
      "\titers: 400, epoch: 5 | loss: 0.2471544\n",
      "\tspeed: 0.0038s/iter; left time: 20.2294s\n",
      "\titers: 500, epoch: 5 | loss: 0.2000457\n",
      "\tspeed: 0.0050s/iter; left time: 26.1611s\n",
      "\titers: 600, epoch: 5 | loss: 0.2261793\n",
      "\tspeed: 0.0043s/iter; left time: 22.2475s\n",
      "\titers: 700, epoch: 5 | loss: 0.2217331\n",
      "\tspeed: 0.0046s/iter; left time: 23.1785s\n",
      "\titers: 800, epoch: 5 | loss: 0.3469454\n",
      "\tspeed: 0.0049s/iter; left time: 24.0190s\n",
      "\titers: 900, epoch: 5 | loss: 0.2460412\n",
      "\tspeed: 0.0043s/iter; left time: 20.6554s\n",
      "Epoch: 5 cost time: 4.428484678268433\n",
      "Epoch: 5, Steps: 954 | Train Loss: 0.2485371 Vali Loss: 0.2266095 Test Loss: 0.2411207\n",
      "Validation loss decreased (0.227279 --> 0.226610).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2639185\n",
      "\tspeed: 0.2294s/iter; left time: 1071.5356s\n",
      "\titers: 200, epoch: 6 | loss: 0.2500672\n",
      "\tspeed: 0.0049s/iter; left time: 22.5464s\n",
      "\titers: 300, epoch: 6 | loss: 0.1935929\n",
      "\tspeed: 0.0049s/iter; left time: 21.9833s\n",
      "\titers: 400, epoch: 6 | loss: 0.2098074\n",
      "\tspeed: 0.0048s/iter; left time: 20.7664s\n",
      "\titers: 500, epoch: 6 | loss: 0.2022929\n",
      "\tspeed: 0.0048s/iter; left time: 20.3659s\n",
      "\titers: 600, epoch: 6 | loss: 0.2842636\n",
      "\tspeed: 0.0043s/iter; left time: 18.0139s\n",
      "\titers: 700, epoch: 6 | loss: 0.3039063\n",
      "\tspeed: 0.0050s/iter; left time: 20.4902s\n",
      "\titers: 800, epoch: 6 | loss: 0.2805157\n",
      "\tspeed: 0.0043s/iter; left time: 17.1971s\n",
      "\titers: 900, epoch: 6 | loss: 0.2306467\n",
      "\tspeed: 0.0042s/iter; left time: 16.3730s\n",
      "Epoch: 6 cost time: 4.9451024532318115\n",
      "Epoch: 6, Steps: 954 | Train Loss: 0.2476655 Vali Loss: 0.2259718 Test Loss: 0.2406314\n",
      "Validation loss decreased (0.226610 --> 0.225972).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2377140\n",
      "\tspeed: 0.2441s/iter; left time: 907.3583s\n",
      "\titers: 200, epoch: 7 | loss: 0.2592627\n",
      "\tspeed: 0.0044s/iter; left time: 15.9915s\n",
      "\titers: 300, epoch: 7 | loss: 0.1800911\n",
      "\tspeed: 0.0046s/iter; left time: 16.2637s\n",
      "\titers: 400, epoch: 7 | loss: 0.2018416\n",
      "\tspeed: 0.0044s/iter; left time: 15.1877s\n",
      "\titers: 500, epoch: 7 | loss: 0.2360248\n",
      "\tspeed: 0.0046s/iter; left time: 15.4000s\n",
      "\titers: 600, epoch: 7 | loss: 0.3220438\n",
      "\tspeed: 0.0043s/iter; left time: 13.8246s\n",
      "\titers: 700, epoch: 7 | loss: 0.2952327\n",
      "\tspeed: 0.0047s/iter; left time: 14.7504s\n",
      "\titers: 800, epoch: 7 | loss: 0.2467743\n",
      "\tspeed: 0.0046s/iter; left time: 13.9934s\n",
      "\titers: 900, epoch: 7 | loss: 0.3248645\n",
      "\tspeed: 0.0050s/iter; left time: 14.6380s\n",
      "Epoch: 7 cost time: 4.9066901206970215\n",
      "Epoch: 7, Steps: 954 | Train Loss: 0.2472452 Vali Loss: 0.2258733 Test Loss: 0.2403492\n",
      "Validation loss decreased (0.225972 --> 0.225873).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2402979\n",
      "\tspeed: 0.2380s/iter; left time: 657.5599s\n",
      "\titers: 200, epoch: 8 | loss: 0.3007331\n",
      "\tspeed: 0.0064s/iter; left time: 17.0008s\n",
      "\titers: 300, epoch: 8 | loss: 0.2317726\n",
      "\tspeed: 0.0060s/iter; left time: 15.4129s\n",
      "\titers: 400, epoch: 8 | loss: 0.2753295\n",
      "\tspeed: 0.0052s/iter; left time: 12.8572s\n",
      "\titers: 500, epoch: 8 | loss: 0.2213706\n",
      "\tspeed: 0.0053s/iter; left time: 12.5334s\n",
      "\titers: 600, epoch: 8 | loss: 0.2359652\n",
      "\tspeed: 0.0053s/iter; left time: 11.8973s\n",
      "\titers: 700, epoch: 8 | loss: 0.2999655\n",
      "\tspeed: 0.0049s/iter; left time: 10.6956s\n",
      "\titers: 800, epoch: 8 | loss: 0.2202488\n",
      "\tspeed: 0.0051s/iter; left time: 10.4867s\n",
      "\titers: 900, epoch: 8 | loss: 0.2334533\n",
      "\tspeed: 0.0055s/iter; left time: 10.7030s\n",
      "Epoch: 8 cost time: 5.68979024887085\n",
      "Epoch: 8, Steps: 954 | Train Loss: 0.2469698 Vali Loss: 0.2257282 Test Loss: 0.2402315\n",
      "Validation loss decreased (0.225873 --> 0.225728).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1669523\n",
      "\tspeed: 0.2752s/iter; left time: 497.8310s\n",
      "\titers: 200, epoch: 9 | loss: 0.2475642\n",
      "\tspeed: 0.0043s/iter; left time: 7.4195s\n",
      "\titers: 300, epoch: 9 | loss: 0.1954539\n",
      "\tspeed: 0.0040s/iter; left time: 6.4840s\n",
      "\titers: 400, epoch: 9 | loss: 0.2467249\n",
      "\tspeed: 0.0041s/iter; left time: 6.1557s\n",
      "\titers: 500, epoch: 9 | loss: 0.2601802\n",
      "\tspeed: 0.0055s/iter; left time: 7.7161s\n",
      "\titers: 600, epoch: 9 | loss: 0.2264744\n",
      "\tspeed: 0.0053s/iter; left time: 6.8968s\n",
      "\titers: 700, epoch: 9 | loss: 0.2437355\n",
      "\tspeed: 0.0059s/iter; left time: 7.0923s\n",
      "\titers: 800, epoch: 9 | loss: 0.2412566\n",
      "\tspeed: 0.0060s/iter; left time: 6.6290s\n",
      "\titers: 900, epoch: 9 | loss: 0.2621567\n",
      "\tspeed: 0.0061s/iter; left time: 6.1472s\n",
      "Epoch: 9 cost time: 5.389156818389893\n",
      "Epoch: 9, Steps: 954 | Train Loss: 0.2469238 Vali Loss: 0.2256546 Test Loss: 0.2401654\n",
      "Validation loss decreased (0.225728 --> 0.225655).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1911185\n",
      "\tspeed: 0.2276s/iter; left time: 194.6166s\n",
      "\titers: 200, epoch: 10 | loss: 0.2103782\n",
      "\tspeed: 0.0043s/iter; left time: 3.2338s\n",
      "\titers: 300, epoch: 10 | loss: 0.2354681\n",
      "\tspeed: 0.0040s/iter; left time: 2.5897s\n",
      "\titers: 400, epoch: 10 | loss: 0.2540981\n",
      "\tspeed: 0.0048s/iter; left time: 2.6747s\n",
      "\titers: 500, epoch: 10 | loss: 0.2591368\n",
      "\tspeed: 0.0049s/iter; left time: 2.2492s\n",
      "\titers: 600, epoch: 10 | loss: 0.1987353\n",
      "\tspeed: 0.0056s/iter; left time: 1.9707s\n",
      "\titers: 700, epoch: 10 | loss: 0.2641152\n",
      "\tspeed: 0.0060s/iter; left time: 1.5274s\n",
      "\titers: 800, epoch: 10 | loss: 0.2903523\n",
      "\tspeed: 0.0062s/iter; left time: 0.9559s\n",
      "\titers: 900, epoch: 10 | loss: 0.1923893\n",
      "\tspeed: 0.0059s/iter; left time: 0.3254s\n",
      "Epoch: 10 cost time: 5.431034564971924\n",
      "Epoch: 10, Steps: 954 | Train Loss: 0.2468344 Vali Loss: 0.2254500 Test Loss: 0.2401343\n",
      "Validation loss decreased (0.225655 --> 0.225450).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__24_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8735\n",
      "test shape: (8735, 1, 24, 1) (8735, 1, 24, 1)\n",
      "test shape: (8735, 24, 1) (8735, 24, 1)\n",
      "mse:0.24013423919677734, mae:0.3561345934867859\n",
      "\n",
      "Extracted Part: long_term_forecast__24_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__24_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl24_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=1, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=1, factor=5, features='S', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_48_DE_load_actual_entsoe_transparency', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=48, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='DE_load_actual_entsoe_transparency', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.7441232\n",
      "\tspeed: 0.0117s/iter; left time: 110.6222s\n",
      "\titers: 200, epoch: 1 | loss: 0.4165238\n",
      "\tspeed: 0.0037s/iter; left time: 34.8778s\n",
      "\titers: 300, epoch: 1 | loss: 0.4995746\n",
      "\tspeed: 0.0031s/iter; left time: 29.0725s\n",
      "\titers: 400, epoch: 1 | loss: 0.4482241\n",
      "\tspeed: 0.0032s/iter; left time: 29.2120s\n",
      "\titers: 500, epoch: 1 | loss: 0.2958984\n",
      "\tspeed: 0.0038s/iter; left time: 34.0229s\n",
      "\titers: 600, epoch: 1 | loss: 0.3224748\n",
      "\tspeed: 0.0040s/iter; left time: 35.5449s\n",
      "\titers: 700, epoch: 1 | loss: 0.3437203\n",
      "\tspeed: 0.0026s/iter; left time: 23.3749s\n",
      "\titers: 800, epoch: 1 | loss: 0.5073780\n",
      "\tspeed: 0.0028s/iter; left time: 24.3750s\n",
      "\titers: 900, epoch: 1 | loss: 0.3764785\n",
      "\tspeed: 0.0030s/iter; left time: 25.9397s\n",
      "Epoch: 1 cost time: 4.004591941833496\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.4743451 Vali Loss: 0.3516920 Test Loss: 0.3766444\n",
      "Validation loss decreased (inf --> 0.351692).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4349896\n",
      "\tspeed: 0.1952s/iter; left time: 1654.9884s\n",
      "\titers: 200, epoch: 2 | loss: 0.4691011\n",
      "\tspeed: 0.0036s/iter; left time: 30.4896s\n",
      "\titers: 300, epoch: 2 | loss: 0.3115906\n",
      "\tspeed: 0.0035s/iter; left time: 28.8168s\n",
      "\titers: 400, epoch: 2 | loss: 0.3514560\n",
      "\tspeed: 0.0029s/iter; left time: 24.0497s\n",
      "\titers: 500, epoch: 2 | loss: 0.3802286\n",
      "\tspeed: 0.0041s/iter; left time: 33.2180s\n",
      "\titers: 600, epoch: 2 | loss: 0.3824807\n",
      "\tspeed: 0.0043s/iter; left time: 34.3418s\n",
      "\titers: 700, epoch: 2 | loss: 0.3333313\n",
      "\tspeed: 0.0040s/iter; left time: 31.1282s\n",
      "\titers: 800, epoch: 2 | loss: 0.3037347\n",
      "\tspeed: 0.0038s/iter; left time: 29.3870s\n",
      "\titers: 900, epoch: 2 | loss: 0.3435412\n",
      "\tspeed: 0.0056s/iter; left time: 43.2256s\n",
      "Epoch: 2 cost time: 4.210476875305176\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.3643966 Vali Loss: 0.3292651 Test Loss: 0.3530052\n",
      "Validation loss decreased (0.351692 --> 0.329265).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3965859\n",
      "\tspeed: 0.1893s/iter; left time: 1424.2606s\n",
      "\titers: 200, epoch: 3 | loss: 0.3076957\n",
      "\tspeed: 0.0029s/iter; left time: 21.7805s\n",
      "\titers: 300, epoch: 3 | loss: 0.2702196\n",
      "\tspeed: 0.0032s/iter; left time: 23.4223s\n",
      "\titers: 400, epoch: 3 | loss: 0.3521485\n",
      "\tspeed: 0.0029s/iter; left time: 20.6243s\n",
      "\titers: 500, epoch: 3 | loss: 0.3300475\n",
      "\tspeed: 0.0032s/iter; left time: 22.7586s\n",
      "\titers: 600, epoch: 3 | loss: 0.2188557\n",
      "\tspeed: 0.0037s/iter; left time: 25.9567s\n",
      "\titers: 700, epoch: 3 | loss: 0.4804107\n",
      "\tspeed: 0.0028s/iter; left time: 19.6643s\n",
      "\titers: 800, epoch: 3 | loss: 0.3244131\n",
      "\tspeed: 0.0035s/iter; left time: 23.6640s\n",
      "\titers: 900, epoch: 3 | loss: 0.2904626\n",
      "\tspeed: 0.0030s/iter; left time: 20.2883s\n",
      "Epoch: 3 cost time: 3.4743807315826416\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.3519787 Vali Loss: 0.3232310 Test Loss: 0.3471628\n",
      "Validation loss decreased (0.329265 --> 0.323231).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3701384\n",
      "\tspeed: 0.1854s/iter; left time: 1218.1674s\n",
      "\titers: 200, epoch: 4 | loss: 0.4160828\n",
      "\tspeed: 0.0030s/iter; left time: 19.1338s\n",
      "\titers: 300, epoch: 4 | loss: 0.3205028\n",
      "\tspeed: 0.0030s/iter; left time: 19.2122s\n",
      "\titers: 400, epoch: 4 | loss: 0.3263111\n",
      "\tspeed: 0.0034s/iter; left time: 21.6284s\n",
      "\titers: 500, epoch: 4 | loss: 0.3299715\n",
      "\tspeed: 0.0032s/iter; left time: 19.6003s\n",
      "\titers: 600, epoch: 4 | loss: 0.4321035\n",
      "\tspeed: 0.0035s/iter; left time: 21.4532s\n",
      "\titers: 700, epoch: 4 | loss: 0.3413666\n",
      "\tspeed: 0.0030s/iter; left time: 18.2107s\n",
      "\titers: 800, epoch: 4 | loss: 0.4409718\n",
      "\tspeed: 0.0035s/iter; left time: 20.5763s\n",
      "\titers: 900, epoch: 4 | loss: 0.3107872\n",
      "\tspeed: 0.0035s/iter; left time: 20.0934s\n",
      "Epoch: 4 cost time: 3.771221876144409\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.3480968 Vali Loss: 0.3213374 Test Loss: 0.3446071\n",
      "Validation loss decreased (0.323231 --> 0.321337).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4327618\n",
      "\tspeed: 0.1849s/iter; left time: 1038.9555s\n",
      "\titers: 200, epoch: 5 | loss: 0.4368951\n",
      "\tspeed: 0.0026s/iter; left time: 14.6021s\n",
      "\titers: 300, epoch: 5 | loss: 0.3011927\n",
      "\tspeed: 0.0028s/iter; left time: 15.1657s\n",
      "\titers: 400, epoch: 5 | loss: 0.3200778\n",
      "\tspeed: 0.0025s/iter; left time: 13.1962s\n",
      "\titers: 500, epoch: 5 | loss: 0.3073424\n",
      "\tspeed: 0.0026s/iter; left time: 13.4142s\n",
      "\titers: 600, epoch: 5 | loss: 0.3555641\n",
      "\tspeed: 0.0027s/iter; left time: 14.0745s\n",
      "\titers: 700, epoch: 5 | loss: 0.4007463\n",
      "\tspeed: 0.0028s/iter; left time: 14.2172s\n",
      "\titers: 800, epoch: 5 | loss: 0.2990958\n",
      "\tspeed: 0.0028s/iter; left time: 13.6736s\n",
      "\titers: 900, epoch: 5 | loss: 0.3585167\n",
      "\tspeed: 0.0029s/iter; left time: 13.7935s\n",
      "Epoch: 5 cost time: 3.0679147243499756\n",
      "Epoch: 5, Steps: 953 | Train Loss: 0.3464827 Vali Loss: 0.3200326 Test Loss: 0.3437161\n",
      "Validation loss decreased (0.321337 --> 0.320033).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3430438\n",
      "\tspeed: 0.1870s/iter; left time: 872.6733s\n",
      "\titers: 200, epoch: 6 | loss: 0.3598139\n",
      "\tspeed: 0.0037s/iter; left time: 17.0429s\n",
      "\titers: 300, epoch: 6 | loss: 0.3050074\n",
      "\tspeed: 0.0038s/iter; left time: 17.1873s\n",
      "\titers: 400, epoch: 6 | loss: 0.2886235\n",
      "\tspeed: 0.0040s/iter; left time: 17.3917s\n",
      "\titers: 500, epoch: 6 | loss: 0.3503401\n",
      "\tspeed: 0.0034s/iter; left time: 14.6557s\n",
      "\titers: 600, epoch: 6 | loss: 0.3005466\n",
      "\tspeed: 0.0037s/iter; left time: 15.2564s\n",
      "\titers: 700, epoch: 6 | loss: 0.4082739\n",
      "\tspeed: 0.0035s/iter; left time: 14.3171s\n",
      "\titers: 800, epoch: 6 | loss: 0.3534085\n",
      "\tspeed: 0.0036s/iter; left time: 14.0973s\n",
      "\titers: 900, epoch: 6 | loss: 0.3698967\n",
      "\tspeed: 0.0041s/iter; left time: 15.7776s\n",
      "Epoch: 6 cost time: 3.980217218399048\n",
      "Epoch: 6, Steps: 953 | Train Loss: 0.3457539 Vali Loss: 0.3197238 Test Loss: 0.3433127\n",
      "Validation loss decreased (0.320033 --> 0.319724).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3418930\n",
      "\tspeed: 0.1810s/iter; left time: 672.0796s\n",
      "\titers: 200, epoch: 7 | loss: 0.2786316\n",
      "\tspeed: 0.0034s/iter; left time: 12.4448s\n",
      "\titers: 300, epoch: 7 | loss: 0.3361766\n",
      "\tspeed: 0.0037s/iter; left time: 13.0936s\n",
      "\titers: 400, epoch: 7 | loss: 0.2970461\n",
      "\tspeed: 0.0039s/iter; left time: 13.1480s\n",
      "\titers: 500, epoch: 7 | loss: 0.3351756\n",
      "\tspeed: 0.0034s/iter; left time: 11.3637s\n",
      "\titers: 600, epoch: 7 | loss: 0.3803256\n",
      "\tspeed: 0.0034s/iter; left time: 10.9926s\n",
      "\titers: 700, epoch: 7 | loss: 0.2115686\n",
      "\tspeed: 0.0034s/iter; left time: 10.7394s\n",
      "\titers: 800, epoch: 7 | loss: 0.3943199\n",
      "\tspeed: 0.0028s/iter; left time: 8.5556s\n",
      "\titers: 900, epoch: 7 | loss: 0.2881115\n",
      "\tspeed: 0.0030s/iter; left time: 8.7115s\n",
      "Epoch: 7 cost time: 3.656442165374756\n",
      "Epoch: 7, Steps: 953 | Train Loss: 0.3453329 Vali Loss: 0.3197584 Test Loss: 0.3431000\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3054177\n",
      "\tspeed: 0.1849s/iter; left time: 510.2383s\n",
      "\titers: 200, epoch: 8 | loss: 0.3426923\n",
      "\tspeed: 0.0028s/iter; left time: 7.4540s\n",
      "\titers: 300, epoch: 8 | loss: 0.3190992\n",
      "\tspeed: 0.0029s/iter; left time: 7.5351s\n",
      "\titers: 400, epoch: 8 | loss: 0.2962984\n",
      "\tspeed: 0.0031s/iter; left time: 7.7217s\n",
      "\titers: 500, epoch: 8 | loss: 0.3873568\n",
      "\tspeed: 0.0029s/iter; left time: 6.8805s\n",
      "\titers: 600, epoch: 8 | loss: 0.3058670\n",
      "\tspeed: 0.0028s/iter; left time: 6.4394s\n",
      "\titers: 700, epoch: 8 | loss: 0.2247408\n",
      "\tspeed: 0.0030s/iter; left time: 6.5712s\n",
      "\titers: 800, epoch: 8 | loss: 0.2848975\n",
      "\tspeed: 0.0033s/iter; left time: 6.7866s\n",
      "\titers: 900, epoch: 8 | loss: 0.3025133\n",
      "\tspeed: 0.0036s/iter; left time: 7.0043s\n",
      "Epoch: 8 cost time: 3.3821730613708496\n",
      "Epoch: 8, Steps: 953 | Train Loss: 0.3452361 Vali Loss: 0.3196090 Test Loss: 0.3429652\n",
      "Validation loss decreased (0.319724 --> 0.319609).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.3095482\n",
      "\tspeed: 0.1892s/iter; left time: 341.8441s\n",
      "\titers: 200, epoch: 9 | loss: 0.4168519\n",
      "\tspeed: 0.0029s/iter; left time: 4.8845s\n",
      "\titers: 300, epoch: 9 | loss: 0.2574266\n",
      "\tspeed: 0.0025s/iter; left time: 4.0786s\n",
      "\titers: 400, epoch: 9 | loss: 0.2863042\n",
      "\tspeed: 0.0042s/iter; left time: 6.2928s\n",
      "\titers: 500, epoch: 9 | loss: 0.3467037\n",
      "\tspeed: 0.0031s/iter; left time: 4.3886s\n",
      "\titers: 600, epoch: 9 | loss: 0.3447107\n",
      "\tspeed: 0.0035s/iter; left time: 4.5344s\n",
      "\titers: 700, epoch: 9 | loss: 0.3544288\n",
      "\tspeed: 0.0037s/iter; left time: 4.4718s\n",
      "\titers: 800, epoch: 9 | loss: 0.3006296\n",
      "\tspeed: 0.0045s/iter; left time: 4.9693s\n",
      "\titers: 900, epoch: 9 | loss: 0.3164161\n",
      "\tspeed: 0.0033s/iter; left time: 3.3544s\n",
      "Epoch: 9 cost time: 3.62514591217041\n",
      "Epoch: 9, Steps: 953 | Train Loss: 0.3450388 Vali Loss: 0.3193954 Test Loss: 0.3428941\n",
      "Validation loss decreased (0.319609 --> 0.319395).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.3485057\n",
      "\tspeed: 0.1831s/iter; left time: 156.4048s\n",
      "\titers: 200, epoch: 10 | loss: 0.2725600\n",
      "\tspeed: 0.0028s/iter; left time: 2.0937s\n",
      "\titers: 300, epoch: 10 | loss: 0.2935918\n",
      "\tspeed: 0.0028s/iter; left time: 1.8091s\n",
      "\titers: 400, epoch: 10 | loss: 0.5091110\n",
      "\tspeed: 0.0035s/iter; left time: 1.9210s\n",
      "\titers: 500, epoch: 10 | loss: 0.2947946\n",
      "\tspeed: 0.0036s/iter; left time: 1.6236s\n",
      "\titers: 600, epoch: 10 | loss: 0.3486243\n",
      "\tspeed: 0.0035s/iter; left time: 1.2317s\n",
      "\titers: 700, epoch: 10 | loss: 0.2688591\n",
      "\tspeed: 0.0036s/iter; left time: 0.9145s\n",
      "\titers: 800, epoch: 10 | loss: 0.2557632\n",
      "\tspeed: 0.0039s/iter; left time: 0.6056s\n",
      "\titers: 900, epoch: 10 | loss: 0.3222969\n",
      "\tspeed: 0.0044s/iter; left time: 0.2391s\n",
      "Epoch: 10 cost time: 3.609086036682129\n",
      "Epoch: 10, Steps: 953 | Train Loss: 0.3450445 Vali Loss: 0.3196412 Test Loss: 0.3428627\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__48_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 1) (8711, 1, 48, 1)\n",
      "test shape: (8711, 48, 1) (8711, 48, 1)\n",
      "mse:0.34289413690567017, mae:0.44494104385375977\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__48_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30512\n",
      "val 4333\n",
      "test 8711\n",
      "\titers: 100, epoch: 1 | loss: 0.5794484\n",
      "\tspeed: 0.0075s/iter; left time: 70.8889s\n",
      "\titers: 200, epoch: 1 | loss: 0.4436660\n",
      "\tspeed: 0.0042s/iter; left time: 39.1626s\n",
      "\titers: 300, epoch: 1 | loss: 0.4118876\n",
      "\tspeed: 0.0051s/iter; left time: 46.9780s\n",
      "\titers: 400, epoch: 1 | loss: 0.4053136\n",
      "\tspeed: 0.0051s/iter; left time: 46.3907s\n",
      "\titers: 500, epoch: 1 | loss: 0.3453888\n",
      "\tspeed: 0.0050s/iter; left time: 44.9465s\n",
      "\titers: 600, epoch: 1 | loss: 0.4019594\n",
      "\tspeed: 0.0037s/iter; left time: 33.4585s\n",
      "\titers: 700, epoch: 1 | loss: 0.4139456\n",
      "\tspeed: 0.0043s/iter; left time: 37.8533s\n",
      "\titers: 800, epoch: 1 | loss: 0.3606279\n",
      "\tspeed: 0.0037s/iter; left time: 32.3519s\n",
      "\titers: 900, epoch: 1 | loss: 0.4493662\n",
      "\tspeed: 0.0041s/iter; left time: 35.1681s\n",
      "Epoch: 1 cost time: 4.582366704940796\n",
      "Epoch: 1, Steps: 953 | Train Loss: 0.4746469 Vali Loss: 0.3517088 Test Loss: 0.3763808\n",
      "Validation loss decreased (inf --> 0.351709).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2897351\n",
      "\tspeed: 0.2201s/iter; left time: 1865.6570s\n",
      "\titers: 200, epoch: 2 | loss: 0.3147719\n",
      "\tspeed: 0.0032s/iter; left time: 26.9749s\n",
      "\titers: 300, epoch: 2 | loss: 0.3648238\n",
      "\tspeed: 0.0036s/iter; left time: 30.2032s\n",
      "\titers: 400, epoch: 2 | loss: 0.3429701\n",
      "\tspeed: 0.0033s/iter; left time: 27.1817s\n",
      "\titers: 500, epoch: 2 | loss: 0.3222184\n",
      "\tspeed: 0.0033s/iter; left time: 26.2849s\n",
      "\titers: 600, epoch: 2 | loss: 0.4222496\n",
      "\tspeed: 0.0032s/iter; left time: 25.1442s\n",
      "\titers: 700, epoch: 2 | loss: 0.3215702\n",
      "\tspeed: 0.0030s/iter; left time: 23.6285s\n",
      "\titers: 800, epoch: 2 | loss: 0.2643302\n",
      "\tspeed: 0.0031s/iter; left time: 23.7623s\n",
      "\titers: 900, epoch: 2 | loss: 0.3884929\n",
      "\tspeed: 0.0033s/iter; left time: 25.3711s\n",
      "Epoch: 2 cost time: 3.6527698040008545\n",
      "Epoch: 2, Steps: 953 | Train Loss: 0.3642498 Vali Loss: 0.3285203 Test Loss: 0.3536970\n",
      "Validation loss decreased (0.351709 --> 0.328520).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3541498\n",
      "\tspeed: 0.2267s/iter; left time: 1706.1278s\n",
      "\titers: 200, epoch: 3 | loss: 0.2968740\n",
      "\tspeed: 0.0031s/iter; left time: 22.7441s\n",
      "\titers: 300, epoch: 3 | loss: 0.3587474\n",
      "\tspeed: 0.0028s/iter; left time: 20.4149s\n",
      "\titers: 400, epoch: 3 | loss: 0.3784089\n",
      "\tspeed: 0.0034s/iter; left time: 24.3740s\n",
      "\titers: 500, epoch: 3 | loss: 0.4630342\n",
      "\tspeed: 0.0030s/iter; left time: 21.2824s\n",
      "\titers: 600, epoch: 3 | loss: 0.3038165\n",
      "\tspeed: 0.0031s/iter; left time: 21.7532s\n",
      "\titers: 700, epoch: 3 | loss: 0.3431920\n",
      "\tspeed: 0.0035s/iter; left time: 24.1911s\n",
      "\titers: 800, epoch: 3 | loss: 0.3914534\n",
      "\tspeed: 0.0044s/iter; left time: 30.3571s\n",
      "\titers: 900, epoch: 3 | loss: 0.2940673\n",
      "\tspeed: 0.0039s/iter; left time: 25.9437s\n",
      "Epoch: 3 cost time: 3.874410390853882\n",
      "Epoch: 3, Steps: 953 | Train Loss: 0.3519865 Vali Loss: 0.3234381 Test Loss: 0.3470270\n",
      "Validation loss decreased (0.328520 --> 0.323438).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4195802\n",
      "\tspeed: 0.2517s/iter; left time: 1654.3151s\n",
      "\titers: 200, epoch: 4 | loss: 0.2856985\n",
      "\tspeed: 0.0047s/iter; left time: 30.1073s\n",
      "\titers: 300, epoch: 4 | loss: 0.3551238\n",
      "\tspeed: 0.0044s/iter; left time: 28.1662s\n",
      "\titers: 400, epoch: 4 | loss: 0.5067807\n",
      "\tspeed: 0.0043s/iter; left time: 26.8716s\n",
      "\titers: 500, epoch: 4 | loss: 0.3482971\n",
      "\tspeed: 0.0043s/iter; left time: 26.4846s\n",
      "\titers: 600, epoch: 4 | loss: 0.3497117\n",
      "\tspeed: 0.0042s/iter; left time: 25.3338s\n",
      "\titers: 700, epoch: 4 | loss: 0.3774060\n",
      "\tspeed: 0.0044s/iter; left time: 26.5306s\n",
      "\titers: 800, epoch: 4 | loss: 0.3716452\n",
      "\tspeed: 0.0041s/iter; left time: 24.3414s\n",
      "\titers: 900, epoch: 4 | loss: 0.3777080\n",
      "\tspeed: 0.0041s/iter; left time: 23.8001s\n",
      "Epoch: 4 cost time: 4.5845232009887695\n",
      "Epoch: 4, Steps: 953 | Train Loss: 0.3481328 Vali Loss: 0.3211913 Test Loss: 0.3444673\n",
      "Validation loss decreased (0.323438 --> 0.321191).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3516126\n",
      "\tspeed: 0.2228s/iter; left time: 1251.8502s\n",
      "\titers: 200, epoch: 5 | loss: 0.3065441\n",
      "\tspeed: 0.0042s/iter; left time: 23.2390s\n",
      "\titers: 300, epoch: 5 | loss: 0.3903895\n",
      "\tspeed: 0.0046s/iter; left time: 24.8426s\n",
      "\titers: 400, epoch: 5 | loss: 0.2761741\n",
      "\tspeed: 0.0042s/iter; left time: 22.1528s\n",
      "\titers: 500, epoch: 5 | loss: 0.4462455\n",
      "\tspeed: 0.0045s/iter; left time: 23.6355s\n",
      "\titers: 600, epoch: 5 | loss: 0.3317452\n",
      "\tspeed: 0.0042s/iter; left time: 21.7502s\n",
      "\titers: 700, epoch: 5 | loss: 0.3575871\n",
      "\tspeed: 0.0040s/iter; left time: 19.8913s\n",
      "\titers: 800, epoch: 5 | loss: 0.3289428\n",
      "\tspeed: 0.0040s/iter; left time: 19.4614s\n",
      "\titers: 900, epoch: 5 | loss: 0.3841184\n",
      "\tspeed: 0.0040s/iter; left time: 19.0906s\n",
      "Epoch: 5 cost time: 4.487617015838623\n",
      "Epoch: 5, Steps: 953 | Train Loss: 0.3464480 Vali Loss: 0.3197705 Test Loss: 0.3438537\n",
      "Validation loss decreased (0.321191 --> 0.319771).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3565381\n",
      "\tspeed: 0.2181s/iter; left time: 1017.6287s\n",
      "\titers: 200, epoch: 6 | loss: 0.3347099\n",
      "\tspeed: 0.0041s/iter; left time: 18.8652s\n",
      "\titers: 300, epoch: 6 | loss: 0.4099342\n",
      "\tspeed: 0.0045s/iter; left time: 20.2216s\n",
      "\titers: 400, epoch: 6 | loss: 0.2968165\n",
      "\tspeed: 0.0042s/iter; left time: 18.2032s\n",
      "\titers: 500, epoch: 6 | loss: 0.3123651\n",
      "\tspeed: 0.0042s/iter; left time: 17.8050s\n",
      "\titers: 600, epoch: 6 | loss: 0.2863533\n",
      "\tspeed: 0.0041s/iter; left time: 17.1943s\n",
      "\titers: 700, epoch: 6 | loss: 0.3210952\n",
      "\tspeed: 0.0040s/iter; left time: 16.4583s\n",
      "\titers: 800, epoch: 6 | loss: 0.3005061\n",
      "\tspeed: 0.0052s/iter; left time: 20.6925s\n",
      "\titers: 900, epoch: 6 | loss: 0.3537320\n",
      "\tspeed: 0.0046s/iter; left time: 17.7736s\n",
      "Epoch: 6 cost time: 4.758313417434692\n",
      "Epoch: 6, Steps: 953 | Train Loss: 0.3457373 Vali Loss: 0.3200594 Test Loss: 0.3432893\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2645897\n",
      "\tspeed: 0.2305s/iter; left time: 855.8262s\n",
      "\titers: 200, epoch: 7 | loss: 0.4402950\n",
      "\tspeed: 0.0043s/iter; left time: 15.6269s\n",
      "\titers: 300, epoch: 7 | loss: 0.4222063\n",
      "\tspeed: 0.0043s/iter; left time: 14.9327s\n",
      "\titers: 400, epoch: 7 | loss: 0.3606925\n",
      "\tspeed: 0.0041s/iter; left time: 13.9899s\n",
      "\titers: 500, epoch: 7 | loss: 0.4954229\n",
      "\tspeed: 0.0041s/iter; left time: 13.6887s\n",
      "\titers: 600, epoch: 7 | loss: 0.4717860\n",
      "\tspeed: 0.0038s/iter; left time: 12.3692s\n",
      "\titers: 700, epoch: 7 | loss: 0.2623867\n",
      "\tspeed: 0.0040s/iter; left time: 12.5038s\n",
      "\titers: 800, epoch: 7 | loss: 0.3269992\n",
      "\tspeed: 0.0041s/iter; left time: 12.2440s\n",
      "\titers: 900, epoch: 7 | loss: 0.3094979\n",
      "\tspeed: 0.0044s/iter; left time: 12.6842s\n",
      "Epoch: 7 cost time: 4.468693017959595\n",
      "Epoch: 7, Steps: 953 | Train Loss: 0.3453416 Vali Loss: 0.3190767 Test Loss: 0.3430048\n",
      "Validation loss decreased (0.319771 --> 0.319077).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3133784\n",
      "\tspeed: 0.2409s/iter; left time: 664.8762s\n",
      "\titers: 200, epoch: 8 | loss: 0.4563907\n",
      "\tspeed: 0.0044s/iter; left time: 11.6112s\n",
      "\titers: 300, epoch: 8 | loss: 0.2799674\n",
      "\tspeed: 0.0048s/iter; left time: 12.4084s\n",
      "\titers: 400, epoch: 8 | loss: 0.3624806\n",
      "\tspeed: 0.0042s/iter; left time: 10.3325s\n",
      "\titers: 500, epoch: 8 | loss: 0.4254039\n",
      "\tspeed: 0.0040s/iter; left time: 9.3721s\n",
      "\titers: 600, epoch: 8 | loss: 0.4157344\n",
      "\tspeed: 0.0046s/iter; left time: 10.4482s\n",
      "\titers: 700, epoch: 8 | loss: 0.3340049\n",
      "\tspeed: 0.0040s/iter; left time: 8.5621s\n",
      "\titers: 800, epoch: 8 | loss: 0.3067065\n",
      "\tspeed: 0.0041s/iter; left time: 8.3458s\n",
      "\titers: 900, epoch: 8 | loss: 0.3996292\n",
      "\tspeed: 0.0040s/iter; left time: 7.8200s\n",
      "Epoch: 8 cost time: 4.5595667362213135\n",
      "Epoch: 8, Steps: 953 | Train Loss: 0.3451311 Vali Loss: 0.3189213 Test Loss: 0.3428911\n",
      "Validation loss decreased (0.319077 --> 0.318921).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2580324\n",
      "\tspeed: 0.2225s/iter; left time: 402.0774s\n",
      "\titers: 200, epoch: 9 | loss: 0.3699148\n",
      "\tspeed: 0.0045s/iter; left time: 7.6588s\n",
      "\titers: 300, epoch: 9 | loss: 0.3098447\n",
      "\tspeed: 0.0047s/iter; left time: 7.5088s\n",
      "\titers: 400, epoch: 9 | loss: 0.2185139\n",
      "\tspeed: 0.0040s/iter; left time: 6.0041s\n",
      "\titers: 500, epoch: 9 | loss: 0.3399366\n",
      "\tspeed: 0.0042s/iter; left time: 5.8834s\n",
      "\titers: 600, epoch: 9 | loss: 0.2918634\n",
      "\tspeed: 0.0043s/iter; left time: 5.6579s\n",
      "\titers: 700, epoch: 9 | loss: 0.2467695\n",
      "\tspeed: 0.0041s/iter; left time: 4.9513s\n",
      "\titers: 800, epoch: 9 | loss: 0.2266109\n",
      "\tspeed: 0.0040s/iter; left time: 4.4267s\n",
      "\titers: 900, epoch: 9 | loss: 0.2509633\n",
      "\tspeed: 0.0040s/iter; left time: 4.0332s\n",
      "Epoch: 9 cost time: 4.503238677978516\n",
      "Epoch: 9, Steps: 953 | Train Loss: 0.3449424 Vali Loss: 0.3194745 Test Loss: 0.3428303\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.3934744\n",
      "\tspeed: 0.2210s/iter; left time: 188.7643s\n",
      "\titers: 200, epoch: 10 | loss: 0.2788468\n",
      "\tspeed: 0.0045s/iter; left time: 3.3709s\n",
      "\titers: 300, epoch: 10 | loss: 0.2737827\n",
      "\tspeed: 0.0041s/iter; left time: 2.6777s\n",
      "\titers: 400, epoch: 10 | loss: 0.3301009\n",
      "\tspeed: 0.0043s/iter; left time: 2.3954s\n",
      "\titers: 500, epoch: 10 | loss: 0.3742171\n",
      "\tspeed: 0.0047s/iter; left time: 2.1188s\n",
      "\titers: 600, epoch: 10 | loss: 0.3815980\n",
      "\tspeed: 0.0043s/iter; left time: 1.5358s\n",
      "\titers: 700, epoch: 10 | loss: 0.3053613\n",
      "\tspeed: 0.0038s/iter; left time: 0.9671s\n",
      "\titers: 800, epoch: 10 | loss: 0.3744104\n",
      "\tspeed: 0.0036s/iter; left time: 0.5566s\n",
      "\titers: 900, epoch: 10 | loss: 0.3708250\n",
      "\tspeed: 0.0039s/iter; left time: 0.2125s\n",
      "Epoch: 10 cost time: 4.420045375823975\n",
      "Epoch: 10, Steps: 953 | Train Loss: 0.3450035 Vali Loss: 0.3196218 Test Loss: 0.3428030\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__48_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8711\n",
      "test shape: (8711, 1, 48, 1) (8711, 1, 48, 1)\n",
      "test shape: (8711, 48, 1) (8711, 48, 1)\n",
      "mse:0.3428911566734314, mae:0.44489696621894836\n",
      "\n",
      "Extracted Part: long_term_forecast__48_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__48_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl48_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=1, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=1, factor=5, features='S', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_96_DE_load_actual_entsoe_transparency', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='DE_load_actual_entsoe_transparency', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.5416483\n",
      "\tspeed: 0.0112s/iter; left time: 105.4911s\n",
      "\titers: 200, epoch: 1 | loss: 0.4404818\n",
      "\tspeed: 0.0027s/iter; left time: 25.0234s\n",
      "\titers: 300, epoch: 1 | loss: 0.3755811\n",
      "\tspeed: 0.0028s/iter; left time: 25.9713s\n",
      "\titers: 400, epoch: 1 | loss: 0.4306796\n",
      "\tspeed: 0.0026s/iter; left time: 24.1016s\n",
      "\titers: 500, epoch: 1 | loss: 0.3911155\n",
      "\tspeed: 0.0030s/iter; left time: 27.0270s\n",
      "\titers: 600, epoch: 1 | loss: 0.3451095\n",
      "\tspeed: 0.0031s/iter; left time: 27.8477s\n",
      "\titers: 700, epoch: 1 | loss: 0.3645096\n",
      "\tspeed: 0.0029s/iter; left time: 25.1962s\n",
      "\titers: 800, epoch: 1 | loss: 0.4032925\n",
      "\tspeed: 0.0029s/iter; left time: 25.4020s\n",
      "\titers: 900, epoch: 1 | loss: 0.3546929\n",
      "\tspeed: 0.0027s/iter; left time: 23.4704s\n",
      "Epoch: 1 cost time: 3.620448589324951\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.4178940 Vali Loss: 0.2985012 Test Loss: 0.3287762\n",
      "Validation loss decreased (inf --> 0.298501).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2549083\n",
      "\tspeed: 0.1773s/iter; left time: 1501.3211s\n",
      "\titers: 200, epoch: 2 | loss: 0.3916061\n",
      "\tspeed: 0.0029s/iter; left time: 24.1459s\n",
      "\titers: 300, epoch: 2 | loss: 0.3826965\n",
      "\tspeed: 0.0030s/iter; left time: 24.8970s\n",
      "\titers: 400, epoch: 2 | loss: 0.3373305\n",
      "\tspeed: 0.0029s/iter; left time: 24.0037s\n",
      "\titers: 500, epoch: 2 | loss: 0.3420898\n",
      "\tspeed: 0.0038s/iter; left time: 30.4296s\n",
      "\titers: 600, epoch: 2 | loss: 0.2990924\n",
      "\tspeed: 0.0040s/iter; left time: 31.6835s\n",
      "\titers: 700, epoch: 2 | loss: 0.3572310\n",
      "\tspeed: 0.0037s/iter; left time: 29.3215s\n",
      "\titers: 800, epoch: 2 | loss: 0.2573572\n",
      "\tspeed: 0.0036s/iter; left time: 28.3432s\n",
      "\titers: 900, epoch: 2 | loss: 0.3512514\n",
      "\tspeed: 0.0036s/iter; left time: 27.7798s\n",
      "Epoch: 2 cost time: 3.662357807159424\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.3127878 Vali Loss: 0.2788639 Test Loss: 0.3092455\n",
      "Validation loss decreased (0.298501 --> 0.278864).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3073783\n",
      "\tspeed: 0.1859s/iter; left time: 1397.3898s\n",
      "\titers: 200, epoch: 3 | loss: 0.3104327\n",
      "\tspeed: 0.0032s/iter; left time: 24.0710s\n",
      "\titers: 300, epoch: 3 | loss: 0.3857300\n",
      "\tspeed: 0.0027s/iter; left time: 19.4194s\n",
      "\titers: 400, epoch: 3 | loss: 0.2589498\n",
      "\tspeed: 0.0029s/iter; left time: 20.7994s\n",
      "\titers: 500, epoch: 3 | loss: 0.3063097\n",
      "\tspeed: 0.0028s/iter; left time: 19.9813s\n",
      "\titers: 600, epoch: 3 | loss: 0.2267780\n",
      "\tspeed: 0.0028s/iter; left time: 19.5383s\n",
      "\titers: 700, epoch: 3 | loss: 0.2990578\n",
      "\tspeed: 0.0027s/iter; left time: 18.4020s\n",
      "\titers: 800, epoch: 3 | loss: 0.2986731\n",
      "\tspeed: 0.0035s/iter; left time: 23.6006s\n",
      "\titers: 900, epoch: 3 | loss: 0.2500142\n",
      "\tspeed: 0.0033s/iter; left time: 22.4381s\n",
      "Epoch: 3 cost time: 3.248533248901367\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.3022200 Vali Loss: 0.2735765 Test Loss: 0.3041151\n",
      "Validation loss decreased (0.278864 --> 0.273576).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2702754\n",
      "\tspeed: 0.1962s/iter; left time: 1287.9098s\n",
      "\titers: 200, epoch: 4 | loss: 0.2404916\n",
      "\tspeed: 0.0026s/iter; left time: 16.9931s\n",
      "\titers: 300, epoch: 4 | loss: 0.3400567\n",
      "\tspeed: 0.0026s/iter; left time: 16.7016s\n",
      "\titers: 400, epoch: 4 | loss: 0.3657741\n",
      "\tspeed: 0.0032s/iter; left time: 19.7559s\n",
      "\titers: 500, epoch: 4 | loss: 0.3048160\n",
      "\tspeed: 0.0028s/iter; left time: 17.5501s\n",
      "\titers: 600, epoch: 4 | loss: 0.3222447\n",
      "\tspeed: 0.0029s/iter; left time: 17.8688s\n",
      "\titers: 700, epoch: 4 | loss: 0.3073009\n",
      "\tspeed: 0.0029s/iter; left time: 17.1797s\n",
      "\titers: 800, epoch: 4 | loss: 0.2823257\n",
      "\tspeed: 0.0027s/iter; left time: 16.0563s\n",
      "\titers: 900, epoch: 4 | loss: 0.2131283\n",
      "\tspeed: 0.0030s/iter; left time: 17.5789s\n",
      "Epoch: 4 cost time: 3.2994675636291504\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.2988510 Vali Loss: 0.2711562 Test Loss: 0.3024941\n",
      "Validation loss decreased (0.273576 --> 0.271156).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2553352\n",
      "\tspeed: 0.1962s/iter; left time: 1101.0065s\n",
      "\titers: 200, epoch: 5 | loss: 0.3331393\n",
      "\tspeed: 0.0038s/iter; left time: 20.8578s\n",
      "\titers: 300, epoch: 5 | loss: 0.3006000\n",
      "\tspeed: 0.0040s/iter; left time: 21.8389s\n",
      "\titers: 400, epoch: 5 | loss: 0.3043792\n",
      "\tspeed: 0.0033s/iter; left time: 17.5378s\n",
      "\titers: 500, epoch: 5 | loss: 0.2697914\n",
      "\tspeed: 0.0038s/iter; left time: 19.9322s\n",
      "\titers: 600, epoch: 5 | loss: 0.2181438\n",
      "\tspeed: 0.0047s/iter; left time: 24.1147s\n",
      "\titers: 700, epoch: 5 | loss: 0.2827705\n",
      "\tspeed: 0.0039s/iter; left time: 19.3662s\n",
      "\titers: 800, epoch: 5 | loss: 0.3486407\n",
      "\tspeed: 0.0037s/iter; left time: 18.0024s\n",
      "\titers: 900, epoch: 5 | loss: 0.2802406\n",
      "\tspeed: 0.0034s/iter; left time: 16.3367s\n",
      "Epoch: 5 cost time: 4.015216827392578\n",
      "Epoch: 5, Steps: 952 | Train Loss: 0.2974788 Vali Loss: 0.2703140 Test Loss: 0.3015670\n",
      "Validation loss decreased (0.271156 --> 0.270314).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2876968\n",
      "\tspeed: 0.2001s/iter; left time: 932.4448s\n",
      "\titers: 200, epoch: 6 | loss: 0.2892461\n",
      "\tspeed: 0.0027s/iter; left time: 12.1209s\n",
      "\titers: 300, epoch: 6 | loss: 0.2785837\n",
      "\tspeed: 0.0027s/iter; left time: 12.0458s\n",
      "\titers: 400, epoch: 6 | loss: 0.2676924\n",
      "\tspeed: 0.0027s/iter; left time: 11.9630s\n",
      "\titers: 500, epoch: 6 | loss: 0.3521698\n",
      "\tspeed: 0.0030s/iter; left time: 12.9290s\n",
      "\titers: 600, epoch: 6 | loss: 0.3492099\n",
      "\tspeed: 0.0025s/iter; left time: 10.5271s\n",
      "\titers: 700, epoch: 6 | loss: 0.2533143\n",
      "\tspeed: 0.0029s/iter; left time: 11.7198s\n",
      "\titers: 800, epoch: 6 | loss: 0.2808461\n",
      "\tspeed: 0.0039s/iter; left time: 15.4772s\n",
      "\titers: 900, epoch: 6 | loss: 0.3064159\n",
      "\tspeed: 0.0037s/iter; left time: 14.2094s\n",
      "Epoch: 6 cost time: 3.2998011112213135\n",
      "Epoch: 6, Steps: 952 | Train Loss: 0.2968117 Vali Loss: 0.2701535 Test Loss: 0.3011880\n",
      "Validation loss decreased (0.270314 --> 0.270153).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2973682\n",
      "\tspeed: 0.2054s/iter; left time: 761.7532s\n",
      "\titers: 200, epoch: 7 | loss: 0.2501145\n",
      "\tspeed: 0.0043s/iter; left time: 15.3655s\n",
      "\titers: 300, epoch: 7 | loss: 0.3089769\n",
      "\tspeed: 0.0031s/iter; left time: 10.8937s\n",
      "\titers: 400, epoch: 7 | loss: 0.3021318\n",
      "\tspeed: 0.0036s/iter; left time: 12.2233s\n",
      "\titers: 500, epoch: 7 | loss: 0.3343670\n",
      "\tspeed: 0.0031s/iter; left time: 10.1838s\n",
      "\titers: 600, epoch: 7 | loss: 0.2736097\n",
      "\tspeed: 0.0032s/iter; left time: 10.2827s\n",
      "\titers: 700, epoch: 7 | loss: 0.3368345\n",
      "\tspeed: 0.0033s/iter; left time: 10.2739s\n",
      "\titers: 800, epoch: 7 | loss: 0.3030918\n",
      "\tspeed: 0.0039s/iter; left time: 11.7260s\n",
      "\titers: 900, epoch: 7 | loss: 0.3934451\n",
      "\tspeed: 0.0034s/iter; left time: 9.9252s\n",
      "Epoch: 7 cost time: 3.7725725173950195\n",
      "Epoch: 7, Steps: 952 | Train Loss: 0.2964879 Vali Loss: 0.2698185 Test Loss: 0.3009863\n",
      "Validation loss decreased (0.270153 --> 0.269818).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2652488\n",
      "\tspeed: 0.1841s/iter; left time: 507.4994s\n",
      "\titers: 200, epoch: 8 | loss: 0.2547857\n",
      "\tspeed: 0.0031s/iter; left time: 8.3655s\n",
      "\titers: 300, epoch: 8 | loss: 0.3499007\n",
      "\tspeed: 0.0042s/iter; left time: 10.6124s\n",
      "\titers: 400, epoch: 8 | loss: 0.3043557\n",
      "\tspeed: 0.0044s/iter; left time: 10.8157s\n",
      "\titers: 500, epoch: 8 | loss: 0.3732868\n",
      "\tspeed: 0.0047s/iter; left time: 11.1076s\n",
      "\titers: 600, epoch: 8 | loss: 0.2560501\n",
      "\tspeed: 0.0040s/iter; left time: 8.9683s\n",
      "\titers: 700, epoch: 8 | loss: 0.3148220\n",
      "\tspeed: 0.0041s/iter; left time: 8.7456s\n",
      "\titers: 800, epoch: 8 | loss: 0.3047091\n",
      "\tspeed: 0.0038s/iter; left time: 7.7458s\n",
      "\titers: 900, epoch: 8 | loss: 0.2356232\n",
      "\tspeed: 0.0029s/iter; left time: 5.6310s\n",
      "Epoch: 8 cost time: 4.0537614822387695\n",
      "Epoch: 8, Steps: 952 | Train Loss: 0.2963280 Vali Loss: 0.2703348 Test Loss: 0.3008912\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.3096442\n",
      "\tspeed: 0.1850s/iter; left time: 333.8675s\n",
      "\titers: 200, epoch: 9 | loss: 0.3048101\n",
      "\tspeed: 0.0028s/iter; left time: 4.7360s\n",
      "\titers: 300, epoch: 9 | loss: 0.3310599\n",
      "\tspeed: 0.0028s/iter; left time: 4.4483s\n",
      "\titers: 400, epoch: 9 | loss: 0.2649810\n",
      "\tspeed: 0.0026s/iter; left time: 3.9830s\n",
      "\titers: 500, epoch: 9 | loss: 0.3020346\n",
      "\tspeed: 0.0027s/iter; left time: 3.7566s\n",
      "\titers: 600, epoch: 9 | loss: 0.2708266\n",
      "\tspeed: 0.0027s/iter; left time: 3.5191s\n",
      "\titers: 700, epoch: 9 | loss: 0.2490807\n",
      "\tspeed: 0.0027s/iter; left time: 3.2043s\n",
      "\titers: 800, epoch: 9 | loss: 0.2742422\n",
      "\tspeed: 0.0026s/iter; left time: 2.9143s\n",
      "\titers: 900, epoch: 9 | loss: 0.2855975\n",
      "\tspeed: 0.0027s/iter; left time: 2.6965s\n",
      "Epoch: 9 cost time: 3.1127350330352783\n",
      "Epoch: 9, Steps: 952 | Train Loss: 0.2962477 Vali Loss: 0.2700379 Test Loss: 0.3008436\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.3062916\n",
      "\tspeed: 0.1933s/iter; left time: 164.8925s\n",
      "\titers: 200, epoch: 10 | loss: 0.2932409\n",
      "\tspeed: 0.0032s/iter; left time: 2.4439s\n",
      "\titers: 300, epoch: 10 | loss: 0.2697848\n",
      "\tspeed: 0.0034s/iter; left time: 2.1909s\n",
      "\titers: 400, epoch: 10 | loss: 0.2427281\n",
      "\tspeed: 0.0034s/iter; left time: 1.9007s\n",
      "\titers: 500, epoch: 10 | loss: 0.4251556\n",
      "\tspeed: 0.0029s/iter; left time: 1.3292s\n",
      "\titers: 600, epoch: 10 | loss: 0.3293964\n",
      "\tspeed: 0.0037s/iter; left time: 1.3235s\n",
      "\titers: 700, epoch: 10 | loss: 0.2624053\n",
      "\tspeed: 0.0036s/iter; left time: 0.9234s\n",
      "\titers: 800, epoch: 10 | loss: 0.3221359\n",
      "\tspeed: 0.0038s/iter; left time: 0.5806s\n",
      "\titers: 900, epoch: 10 | loss: 0.3159755\n",
      "\tspeed: 0.0039s/iter; left time: 0.2068s\n",
      "Epoch: 10 cost time: 3.7756121158599854\n",
      "Epoch: 10, Steps: 952 | Train Loss: 0.2962079 Vali Loss: 0.2702409 Test Loss: 0.3008199\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast__96_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 1) (8663, 1, 96, 1)\n",
      "test shape: (8663, 96, 1) (8663, 96, 1)\n",
      "mse:0.30098623037338257, mae:0.3969716727733612\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__96_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30464\n",
      "val 4285\n",
      "test 8663\n",
      "\titers: 100, epoch: 1 | loss: 0.5861878\n",
      "\tspeed: 0.0078s/iter; left time: 73.6891s\n",
      "\titers: 200, epoch: 1 | loss: 0.4638647\n",
      "\tspeed: 0.0028s/iter; left time: 26.1131s\n",
      "\titers: 300, epoch: 1 | loss: 0.4452649\n",
      "\tspeed: 0.0031s/iter; left time: 28.6031s\n",
      "\titers: 400, epoch: 1 | loss: 0.3942702\n",
      "\tspeed: 0.0030s/iter; left time: 26.9543s\n",
      "\titers: 500, epoch: 1 | loss: 0.3389717\n",
      "\tspeed: 0.0033s/iter; left time: 29.5255s\n",
      "\titers: 600, epoch: 1 | loss: 0.4025976\n",
      "\tspeed: 0.0031s/iter; left time: 27.8068s\n",
      "\titers: 700, epoch: 1 | loss: 0.2448682\n",
      "\tspeed: 0.0033s/iter; left time: 28.9565s\n",
      "\titers: 800, epoch: 1 | loss: 0.3935757\n",
      "\tspeed: 0.0030s/iter; left time: 25.7324s\n",
      "\titers: 900, epoch: 1 | loss: 0.3167554\n",
      "\tspeed: 0.0033s/iter; left time: 28.1047s\n",
      "Epoch: 1 cost time: 3.4984564781188965\n",
      "Epoch: 1, Steps: 952 | Train Loss: 0.4188357 Vali Loss: 0.2988108 Test Loss: 0.3288666\n",
      "Validation loss decreased (inf --> 0.298811).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3527183\n",
      "\tspeed: 0.1969s/iter; left time: 1667.9160s\n",
      "\titers: 200, epoch: 2 | loss: 0.2662706\n",
      "\tspeed: 0.0031s/iter; left time: 25.6609s\n",
      "\titers: 300, epoch: 2 | loss: 0.3964643\n",
      "\tspeed: 0.0029s/iter; left time: 24.1318s\n",
      "\titers: 400, epoch: 2 | loss: 0.2628619\n",
      "\tspeed: 0.0032s/iter; left time: 26.1478s\n",
      "\titers: 500, epoch: 2 | loss: 0.3887374\n",
      "\tspeed: 0.0036s/iter; left time: 29.4123s\n",
      "\titers: 600, epoch: 2 | loss: 0.3260078\n",
      "\tspeed: 0.0035s/iter; left time: 27.7006s\n",
      "\titers: 700, epoch: 2 | loss: 0.3520636\n",
      "\tspeed: 0.0029s/iter; left time: 22.9132s\n",
      "\titers: 800, epoch: 2 | loss: 0.3029759\n",
      "\tspeed: 0.0031s/iter; left time: 23.7618s\n",
      "\titers: 900, epoch: 2 | loss: 0.3201455\n",
      "\tspeed: 0.0026s/iter; left time: 19.8343s\n",
      "Epoch: 2 cost time: 3.54961895942688\n",
      "Epoch: 2, Steps: 952 | Train Loss: 0.3129311 Vali Loss: 0.2783982 Test Loss: 0.3095965\n",
      "Validation loss decreased (0.298811 --> 0.278398).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2740394\n",
      "\tspeed: 0.1957s/iter; left time: 1471.2463s\n",
      "\titers: 200, epoch: 3 | loss: 0.2608654\n",
      "\tspeed: 0.0041s/iter; left time: 30.6573s\n",
      "\titers: 300, epoch: 3 | loss: 0.2947579\n",
      "\tspeed: 0.0035s/iter; left time: 25.4947s\n",
      "\titers: 400, epoch: 3 | loss: 0.2801216\n",
      "\tspeed: 0.0034s/iter; left time: 24.5163s\n",
      "\titers: 500, epoch: 3 | loss: 0.2867466\n",
      "\tspeed: 0.0036s/iter; left time: 25.5020s\n",
      "\titers: 600, epoch: 3 | loss: 0.2947472\n",
      "\tspeed: 0.0037s/iter; left time: 26.1705s\n",
      "\titers: 700, epoch: 3 | loss: 0.3253255\n",
      "\tspeed: 0.0036s/iter; left time: 24.6973s\n",
      "\titers: 800, epoch: 3 | loss: 0.4219858\n",
      "\tspeed: 0.0032s/iter; left time: 21.8549s\n",
      "\titers: 900, epoch: 3 | loss: 0.3144127\n",
      "\tspeed: 0.0026s/iter; left time: 17.3328s\n",
      "Epoch: 3 cost time: 3.952565908432007\n",
      "Epoch: 3, Steps: 952 | Train Loss: 0.3022968 Vali Loss: 0.2740202 Test Loss: 0.3042711\n",
      "Validation loss decreased (0.278398 --> 0.274020).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3037758\n",
      "\tspeed: 0.1959s/iter; left time: 1286.2239s\n",
      "\titers: 200, epoch: 4 | loss: 0.3645265\n",
      "\tspeed: 0.0036s/iter; left time: 23.4590s\n",
      "\titers: 300, epoch: 4 | loss: 0.3503242\n",
      "\tspeed: 0.0038s/iter; left time: 24.0173s\n",
      "\titers: 400, epoch: 4 | loss: 0.2850572\n",
      "\tspeed: 0.0034s/iter; left time: 21.3477s\n",
      "\titers: 500, epoch: 4 | loss: 0.2478863\n",
      "\tspeed: 0.0034s/iter; left time: 21.1630s\n",
      "\titers: 600, epoch: 4 | loss: 0.3327864\n",
      "\tspeed: 0.0032s/iter; left time: 19.4433s\n",
      "\titers: 700, epoch: 4 | loss: 0.3777077\n",
      "\tspeed: 0.0030s/iter; left time: 18.1709s\n",
      "\titers: 800, epoch: 4 | loss: 0.3010570\n",
      "\tspeed: 0.0029s/iter; left time: 17.1514s\n",
      "\titers: 900, epoch: 4 | loss: 0.2613633\n",
      "\tspeed: 0.0028s/iter; left time: 16.1106s\n",
      "Epoch: 4 cost time: 3.726138114929199\n",
      "Epoch: 4, Steps: 952 | Train Loss: 0.2989558 Vali Loss: 0.2722592 Test Loss: 0.3024387\n",
      "Validation loss decreased (0.274020 --> 0.272259).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3616190\n",
      "\tspeed: 0.1923s/iter; left time: 1079.4439s\n",
      "\titers: 200, epoch: 5 | loss: 0.3291225\n",
      "\tspeed: 0.0033s/iter; left time: 18.1781s\n",
      "\titers: 300, epoch: 5 | loss: 0.2779782\n",
      "\tspeed: 0.0027s/iter; left time: 14.3529s\n",
      "\titers: 400, epoch: 5 | loss: 0.3663831\n",
      "\tspeed: 0.0030s/iter; left time: 15.8780s\n",
      "\titers: 500, epoch: 5 | loss: 0.2865638\n",
      "\tspeed: 0.0027s/iter; left time: 14.1466s\n",
      "\titers: 600, epoch: 5 | loss: 0.2840874\n",
      "\tspeed: 0.0028s/iter; left time: 14.5540s\n",
      "\titers: 700, epoch: 5 | loss: 0.2860807\n",
      "\tspeed: 0.0029s/iter; left time: 14.6839s\n",
      "\titers: 800, epoch: 5 | loss: 0.3687666\n",
      "\tspeed: 0.0027s/iter; left time: 13.4805s\n",
      "\titers: 900, epoch: 5 | loss: 0.2997613\n",
      "\tspeed: 0.0030s/iter; left time: 14.5367s\n",
      "Epoch: 5 cost time: 3.487050771713257\n",
      "Epoch: 5, Steps: 952 | Train Loss: 0.2975398 Vali Loss: 0.2715341 Test Loss: 0.3015890\n",
      "Validation loss decreased (0.272259 --> 0.271534).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2850980\n",
      "\tspeed: 0.2053s/iter; left time: 956.8144s\n",
      "\titers: 200, epoch: 6 | loss: 0.2745470\n",
      "\tspeed: 0.0032s/iter; left time: 14.6170s\n",
      "\titers: 300, epoch: 6 | loss: 0.2185898\n",
      "\tspeed: 0.0033s/iter; left time: 14.8830s\n",
      "\titers: 400, epoch: 6 | loss: 0.2974835\n",
      "\tspeed: 0.0034s/iter; left time: 14.6690s\n",
      "\titers: 500, epoch: 6 | loss: 0.3268745\n",
      "\tspeed: 0.0033s/iter; left time: 14.1886s\n",
      "\titers: 600, epoch: 6 | loss: 0.2813999\n",
      "\tspeed: 0.0041s/iter; left time: 17.0148s\n",
      "\titers: 700, epoch: 6 | loss: 0.3258954\n",
      "\tspeed: 0.0036s/iter; left time: 14.7093s\n",
      "\titers: 800, epoch: 6 | loss: 0.2687174\n",
      "\tspeed: 0.0041s/iter; left time: 16.3462s\n",
      "\titers: 900, epoch: 6 | loss: 0.2177137\n",
      "\tspeed: 0.0033s/iter; left time: 12.5769s\n",
      "Epoch: 6 cost time: 3.939418077468872\n",
      "Epoch: 6, Steps: 952 | Train Loss: 0.2968697 Vali Loss: 0.2703073 Test Loss: 0.3012500\n",
      "Validation loss decreased (0.271534 --> 0.270307).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2613086\n",
      "\tspeed: 0.2003s/iter; left time: 742.7656s\n",
      "\titers: 200, epoch: 7 | loss: 0.2826271\n",
      "\tspeed: 0.0044s/iter; left time: 15.9927s\n",
      "\titers: 300, epoch: 7 | loss: 0.2518991\n",
      "\tspeed: 0.0047s/iter; left time: 16.6524s\n",
      "\titers: 400, epoch: 7 | loss: 0.3117344\n",
      "\tspeed: 0.0040s/iter; left time: 13.7637s\n",
      "\titers: 500, epoch: 7 | loss: 0.2666545\n",
      "\tspeed: 0.0040s/iter; left time: 13.2760s\n",
      "\titers: 600, epoch: 7 | loss: 0.2881833\n",
      "\tspeed: 0.0044s/iter; left time: 14.0533s\n",
      "\titers: 700, epoch: 7 | loss: 0.3306586\n",
      "\tspeed: 0.0043s/iter; left time: 13.3850s\n",
      "\titers: 800, epoch: 7 | loss: 0.2737682\n",
      "\tspeed: 0.0032s/iter; left time: 9.7334s\n",
      "\titers: 900, epoch: 7 | loss: 0.2772969\n",
      "\tspeed: 0.0034s/iter; left time: 9.7696s\n",
      "Epoch: 7 cost time: 4.461774587631226\n",
      "Epoch: 7, Steps: 952 | Train Loss: 0.2965456 Vali Loss: 0.2702379 Test Loss: 0.3010500\n",
      "Validation loss decreased (0.270307 --> 0.270238).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2835805\n",
      "\tspeed: 0.1995s/iter; left time: 550.0728s\n",
      "\titers: 200, epoch: 8 | loss: 0.2517373\n",
      "\tspeed: 0.0037s/iter; left time: 9.7016s\n",
      "\titers: 300, epoch: 8 | loss: 0.2840233\n",
      "\tspeed: 0.0032s/iter; left time: 8.1200s\n",
      "\titers: 400, epoch: 8 | loss: 0.2882312\n",
      "\tspeed: 0.0032s/iter; left time: 7.9438s\n",
      "\titers: 500, epoch: 8 | loss: 0.2953485\n",
      "\tspeed: 0.0034s/iter; left time: 7.9611s\n",
      "\titers: 600, epoch: 8 | loss: 0.2653220\n",
      "\tspeed: 0.0038s/iter; left time: 8.4939s\n",
      "\titers: 700, epoch: 8 | loss: 0.3694920\n",
      "\tspeed: 0.0036s/iter; left time: 7.7244s\n",
      "\titers: 800, epoch: 8 | loss: 0.2627639\n",
      "\tspeed: 0.0034s/iter; left time: 7.0258s\n",
      "\titers: 900, epoch: 8 | loss: 0.2723469\n",
      "\tspeed: 0.0036s/iter; left time: 7.0762s\n",
      "Epoch: 8 cost time: 3.961409330368042\n",
      "Epoch: 8, Steps: 952 | Train Loss: 0.2963816 Vali Loss: 0.2706469 Test Loss: 0.3009497\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2847880\n",
      "\tspeed: 0.2015s/iter; left time: 363.7725s\n",
      "\titers: 200, epoch: 9 | loss: 0.3290078\n",
      "\tspeed: 0.0036s/iter; left time: 6.1039s\n",
      "\titers: 300, epoch: 9 | loss: 0.3611604\n",
      "\tspeed: 0.0029s/iter; left time: 4.6816s\n",
      "\titers: 400, epoch: 9 | loss: 0.2981732\n",
      "\tspeed: 0.0030s/iter; left time: 4.5465s\n",
      "\titers: 500, epoch: 9 | loss: 0.3121352\n",
      "\tspeed: 0.0029s/iter; left time: 4.0086s\n",
      "\titers: 600, epoch: 9 | loss: 0.2489078\n",
      "\tspeed: 0.0029s/iter; left time: 3.7693s\n",
      "\titers: 700, epoch: 9 | loss: 0.2804585\n",
      "\tspeed: 0.0029s/iter; left time: 3.4764s\n",
      "\titers: 800, epoch: 9 | loss: 0.2583295\n",
      "\tspeed: 0.0031s/iter; left time: 3.4672s\n",
      "\titers: 900, epoch: 9 | loss: 0.2771518\n",
      "\tspeed: 0.0032s/iter; left time: 3.2085s\n",
      "Epoch: 9 cost time: 3.6251063346862793\n",
      "Epoch: 9, Steps: 952 | Train Loss: 0.2963017 Vali Loss: 0.2702124 Test Loss: 0.3009038\n",
      "Validation loss decreased (0.270238 --> 0.270212).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.3223052\n",
      "\tspeed: 0.2062s/iter; left time: 175.9026s\n",
      "\titers: 200, epoch: 10 | loss: 0.2823382\n",
      "\tspeed: 0.0039s/iter; left time: 2.9732s\n",
      "\titers: 300, epoch: 10 | loss: 0.2507031\n",
      "\tspeed: 0.0037s/iter; left time: 2.4068s\n",
      "\titers: 400, epoch: 10 | loss: 0.3069330\n",
      "\tspeed: 0.0035s/iter; left time: 1.9202s\n",
      "\titers: 500, epoch: 10 | loss: 0.2716610\n",
      "\tspeed: 0.0038s/iter; left time: 1.7224s\n",
      "\titers: 600, epoch: 10 | loss: 0.3016508\n",
      "\tspeed: 0.0038s/iter; left time: 1.3473s\n",
      "\titers: 700, epoch: 10 | loss: 0.3530062\n",
      "\tspeed: 0.0034s/iter; left time: 0.8551s\n",
      "\titers: 800, epoch: 10 | loss: 0.3339677\n",
      "\tspeed: 0.0036s/iter; left time: 0.5559s\n",
      "\titers: 900, epoch: 10 | loss: 0.2232997\n",
      "\tspeed: 0.0035s/iter; left time: 0.1855s\n",
      "Epoch: 10 cost time: 4.16617226600647\n",
      "Epoch: 10, Steps: 952 | Train Loss: 0.2962611 Vali Loss: 0.2704611 Test Loss: 0.3008805\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__96_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8663\n",
      "test shape: (8663, 1, 96, 1) (8663, 1, 96, 1)\n",
      "test shape: (8663, 96, 1) (8663, 96, 1)\n",
      "mse:0.3009037673473358, mae:0.39689964056015015\n",
      "\n",
      "Extracted Part: long_term_forecast__96_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__96_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n",
      "Captured Output:\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=32, c_out=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=5, d_model=512, data='custom', data_path='df_most_important_columns.csv', dec_in=1, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=1, factor=5, features='S', freq='h', gpu=0, inverse=False, is_training=1, itr=2, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='DLinear', model_id='_192_DE_load_actual_entsoe_transparency', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../dataset/Open-Power-System/', seasonal_patterns='Monthly', seq_len=96, target='DE_load_actual_entsoe_transparency', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.5487942\n",
      "\tspeed: 0.0111s/iter; left time: 104.2028s\n",
      "\titers: 200, epoch: 1 | loss: 0.3590825\n",
      "\tspeed: 0.0038s/iter; left time: 35.4284s\n",
      "\titers: 300, epoch: 1 | loss: 0.4031224\n",
      "\tspeed: 0.0033s/iter; left time: 30.0133s\n",
      "\titers: 400, epoch: 1 | loss: 0.3067705\n",
      "\tspeed: 0.0028s/iter; left time: 25.1681s\n",
      "\titers: 500, epoch: 1 | loss: 0.2894672\n",
      "\tspeed: 0.0031s/iter; left time: 27.7639s\n",
      "\titers: 600, epoch: 1 | loss: 0.3101564\n",
      "\tspeed: 0.0028s/iter; left time: 25.1964s\n",
      "\titers: 700, epoch: 1 | loss: 0.3423720\n",
      "\tspeed: 0.0028s/iter; left time: 24.9802s\n",
      "\titers: 800, epoch: 1 | loss: 0.2642122\n",
      "\tspeed: 0.0027s/iter; left time: 23.7276s\n",
      "\titers: 900, epoch: 1 | loss: 0.2955890\n",
      "\tspeed: 0.0026s/iter; left time: 22.6695s\n",
      "Epoch: 1 cost time: 3.7128047943115234\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.3664931 Vali Loss: 0.2460305 Test Loss: 0.2830833\n",
      "Validation loss decreased (inf --> 0.246030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2451186\n",
      "\tspeed: 0.1892s/iter; left time: 1597.1959s\n",
      "\titers: 200, epoch: 2 | loss: 0.2785044\n",
      "\tspeed: 0.0036s/iter; left time: 30.3472s\n",
      "\titers: 300, epoch: 2 | loss: 0.2767771\n",
      "\tspeed: 0.0038s/iter; left time: 31.4422s\n",
      "\titers: 400, epoch: 2 | loss: 0.2747570\n",
      "\tspeed: 0.0026s/iter; left time: 21.5454s\n",
      "\titers: 500, epoch: 2 | loss: 0.2365823\n",
      "\tspeed: 0.0033s/iter; left time: 26.3529s\n",
      "\titers: 600, epoch: 2 | loss: 0.2745945\n",
      "\tspeed: 0.0038s/iter; left time: 30.5474s\n",
      "\titers: 700, epoch: 2 | loss: 0.2635836\n",
      "\tspeed: 0.0036s/iter; left time: 28.1855s\n",
      "\titers: 800, epoch: 2 | loss: 0.1721225\n",
      "\tspeed: 0.0035s/iter; left time: 26.8882s\n",
      "\titers: 900, epoch: 2 | loss: 0.1883184\n",
      "\tspeed: 0.0033s/iter; left time: 25.1585s\n",
      "Epoch: 2 cost time: 3.7150352001190186\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.2663608 Vali Loss: 0.2282237 Test Loss: 0.2665018\n",
      "Validation loss decreased (0.246030 --> 0.228224).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2562599\n",
      "\tspeed: 0.1887s/iter; left time: 1414.0372s\n",
      "\titers: 200, epoch: 3 | loss: 0.1973146\n",
      "\tspeed: 0.0033s/iter; left time: 24.5566s\n",
      "\titers: 300, epoch: 3 | loss: 0.3202107\n",
      "\tspeed: 0.0041s/iter; left time: 29.7629s\n",
      "\titers: 400, epoch: 3 | loss: 0.2543088\n",
      "\tspeed: 0.0038s/iter; left time: 27.4353s\n",
      "\titers: 500, epoch: 3 | loss: 0.2570223\n",
      "\tspeed: 0.0038s/iter; left time: 27.0741s\n",
      "\titers: 600, epoch: 3 | loss: 0.2282967\n",
      "\tspeed: 0.0039s/iter; left time: 26.9945s\n",
      "\titers: 700, epoch: 3 | loss: 0.2890575\n",
      "\tspeed: 0.0048s/iter; left time: 33.3167s\n",
      "\titers: 800, epoch: 3 | loss: 0.2878284\n",
      "\tspeed: 0.0039s/iter; left time: 26.4557s\n",
      "\titers: 900, epoch: 3 | loss: 0.2353472\n",
      "\tspeed: 0.0034s/iter; left time: 22.5715s\n",
      "Epoch: 3 cost time: 4.026767730712891\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.2571762 Vali Loss: 0.2229658 Test Loss: 0.2622760\n",
      "Validation loss decreased (0.228224 --> 0.222966).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2274154\n",
      "\tspeed: 0.2085s/iter; left time: 1364.5856s\n",
      "\titers: 200, epoch: 4 | loss: 0.3154635\n",
      "\tspeed: 0.0055s/iter; left time: 35.1864s\n",
      "\titers: 300, epoch: 4 | loss: 0.2138948\n",
      "\tspeed: 0.0040s/iter; left time: 25.1164s\n",
      "\titers: 400, epoch: 4 | loss: 0.2943476\n",
      "\tspeed: 0.0044s/iter; left time: 27.1653s\n",
      "\titers: 500, epoch: 4 | loss: 0.2414039\n",
      "\tspeed: 0.0029s/iter; left time: 18.0086s\n",
      "\titers: 600, epoch: 4 | loss: 0.2343106\n",
      "\tspeed: 0.0030s/iter; left time: 17.9083s\n",
      "\titers: 700, epoch: 4 | loss: 0.2263565\n",
      "\tspeed: 0.0030s/iter; left time: 18.0628s\n",
      "\titers: 800, epoch: 4 | loss: 0.2819897\n",
      "\tspeed: 0.0030s/iter; left time: 17.3437s\n",
      "\titers: 900, epoch: 4 | loss: 0.2220884\n",
      "\tspeed: 0.0030s/iter; left time: 17.0474s\n",
      "Epoch: 4 cost time: 3.9727118015289307\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.2543439 Vali Loss: 0.2216344 Test Loss: 0.2607272\n",
      "Validation loss decreased (0.222966 --> 0.221634).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2341653\n",
      "\tspeed: 0.1944s/iter; left time: 1087.7691s\n",
      "\titers: 200, epoch: 5 | loss: 0.1884256\n",
      "\tspeed: 0.0030s/iter; left time: 16.5031s\n",
      "\titers: 300, epoch: 5 | loss: 0.2250696\n",
      "\tspeed: 0.0036s/iter; left time: 19.6851s\n",
      "\titers: 400, epoch: 5 | loss: 0.2532205\n",
      "\tspeed: 0.0032s/iter; left time: 16.9561s\n",
      "\titers: 500, epoch: 5 | loss: 0.2546824\n",
      "\tspeed: 0.0032s/iter; left time: 16.6415s\n",
      "\titers: 600, epoch: 5 | loss: 0.2603957\n",
      "\tspeed: 0.0030s/iter; left time: 15.4364s\n",
      "\titers: 700, epoch: 5 | loss: 0.3050687\n",
      "\tspeed: 0.0032s/iter; left time: 15.8721s\n",
      "\titers: 800, epoch: 5 | loss: 0.2762421\n",
      "\tspeed: 0.0032s/iter; left time: 15.8190s\n",
      "\titers: 900, epoch: 5 | loss: 0.2026290\n",
      "\tspeed: 0.0032s/iter; left time: 15.2486s\n",
      "Epoch: 5 cost time: 3.5158026218414307\n",
      "Epoch: 5, Steps: 949 | Train Loss: 0.2531208 Vali Loss: 0.2211466 Test Loss: 0.2599475\n",
      "Validation loss decreased (0.221634 --> 0.221147).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2187565\n",
      "\tspeed: 0.2385s/iter; left time: 1108.2049s\n",
      "\titers: 200, epoch: 6 | loss: 0.3059033\n",
      "\tspeed: 0.0043s/iter; left time: 19.4867s\n",
      "\titers: 300, epoch: 6 | loss: 0.2035789\n",
      "\tspeed: 0.0038s/iter; left time: 16.8241s\n",
      "\titers: 400, epoch: 6 | loss: 0.2424698\n",
      "\tspeed: 0.0038s/iter; left time: 16.3369s\n",
      "\titers: 500, epoch: 6 | loss: 0.2675619\n",
      "\tspeed: 0.0041s/iter; left time: 17.4960s\n",
      "\titers: 600, epoch: 6 | loss: 0.2902733\n",
      "\tspeed: 0.0040s/iter; left time: 16.6645s\n",
      "\titers: 700, epoch: 6 | loss: 0.2295368\n",
      "\tspeed: 0.0036s/iter; left time: 14.6152s\n",
      "\titers: 800, epoch: 6 | loss: 0.1928070\n",
      "\tspeed: 0.0041s/iter; left time: 16.0257s\n",
      "\titers: 900, epoch: 6 | loss: 0.3113213\n",
      "\tspeed: 0.0041s/iter; left time: 15.6042s\n",
      "Epoch: 6 cost time: 4.172866106033325\n",
      "Epoch: 6, Steps: 949 | Train Loss: 0.2525483 Vali Loss: 0.2209188 Test Loss: 0.2596243\n",
      "Validation loss decreased (0.221147 --> 0.220919).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2717768\n",
      "\tspeed: 0.2412s/iter; left time: 891.5779s\n",
      "\titers: 200, epoch: 7 | loss: 0.2251961\n",
      "\tspeed: 0.0044s/iter; left time: 15.8450s\n",
      "\titers: 300, epoch: 7 | loss: 0.2281474\n",
      "\tspeed: 0.0042s/iter; left time: 14.8488s\n",
      "\titers: 400, epoch: 7 | loss: 0.2805265\n",
      "\tspeed: 0.0043s/iter; left time: 14.4674s\n",
      "\titers: 500, epoch: 7 | loss: 0.2212772\n",
      "\tspeed: 0.0041s/iter; left time: 13.5878s\n",
      "\titers: 600, epoch: 7 | loss: 0.2554237\n",
      "\tspeed: 0.0041s/iter; left time: 12.9621s\n",
      "\titers: 700, epoch: 7 | loss: 0.2578186\n",
      "\tspeed: 0.0043s/iter; left time: 13.2580s\n",
      "\titers: 800, epoch: 7 | loss: 0.2550587\n",
      "\tspeed: 0.0043s/iter; left time: 12.9084s\n",
      "\titers: 900, epoch: 7 | loss: 0.2612337\n",
      "\tspeed: 0.0044s/iter; left time: 12.8411s\n",
      "Epoch: 7 cost time: 4.46509051322937\n",
      "Epoch: 7, Steps: 949 | Train Loss: 0.2522599 Vali Loss: 0.2204945 Test Loss: 0.2594669\n",
      "Validation loss decreased (0.220919 --> 0.220494).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2324834\n",
      "\tspeed: 0.2398s/iter; left time: 659.0409s\n",
      "\titers: 200, epoch: 8 | loss: 0.2486383\n",
      "\tspeed: 0.0044s/iter; left time: 11.6748s\n",
      "\titers: 300, epoch: 8 | loss: 0.2509308\n",
      "\tspeed: 0.0047s/iter; left time: 11.9117s\n",
      "\titers: 400, epoch: 8 | loss: 0.2299158\n",
      "\tspeed: 0.0049s/iter; left time: 11.9632s\n",
      "\titers: 500, epoch: 8 | loss: 0.2221013\n",
      "\tspeed: 0.0044s/iter; left time: 10.4426s\n",
      "\titers: 600, epoch: 8 | loss: 0.2643705\n",
      "\tspeed: 0.0046s/iter; left time: 10.2616s\n",
      "\titers: 700, epoch: 8 | loss: 0.2161778\n",
      "\tspeed: 0.0044s/iter; left time: 9.5292s\n",
      "\titers: 800, epoch: 8 | loss: 0.3051078\n",
      "\tspeed: 0.0045s/iter; left time: 9.1728s\n",
      "\titers: 900, epoch: 8 | loss: 0.2568229\n",
      "\tspeed: 0.0045s/iter; left time: 8.8286s\n",
      "Epoch: 8 cost time: 4.643469333648682\n",
      "Epoch: 8, Steps: 949 | Train Loss: 0.2521212 Vali Loss: 0.2207048 Test Loss: 0.2593822\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2580907\n",
      "\tspeed: 0.2175s/iter; left time: 391.2416s\n",
      "\titers: 200, epoch: 9 | loss: 0.2455937\n",
      "\tspeed: 0.0034s/iter; left time: 5.7888s\n",
      "\titers: 300, epoch: 9 | loss: 0.2121369\n",
      "\tspeed: 0.0036s/iter; left time: 5.6882s\n",
      "\titers: 400, epoch: 9 | loss: 0.1877927\n",
      "\tspeed: 0.0035s/iter; left time: 5.2113s\n",
      "\titers: 500, epoch: 9 | loss: 0.2665063\n",
      "\tspeed: 0.0029s/iter; left time: 4.1230s\n",
      "\titers: 600, epoch: 9 | loss: 0.2651731\n",
      "\tspeed: 0.0033s/iter; left time: 4.3234s\n",
      "\titers: 700, epoch: 9 | loss: 0.2706491\n",
      "\tspeed: 0.0031s/iter; left time: 3.7178s\n",
      "\titers: 800, epoch: 9 | loss: 0.2340790\n",
      "\tspeed: 0.0032s/iter; left time: 3.5567s\n",
      "\titers: 900, epoch: 9 | loss: 0.2346333\n",
      "\tspeed: 0.0035s/iter; left time: 3.4599s\n",
      "Epoch: 9 cost time: 3.616621732711792\n",
      "Epoch: 9, Steps: 949 | Train Loss: 0.2520509 Vali Loss: 0.2204782 Test Loss: 0.2593425\n",
      "Validation loss decreased (0.220494 --> 0.220478).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2047286\n",
      "\tspeed: 0.1846s/iter; left time: 156.8904s\n",
      "\titers: 200, epoch: 10 | loss: 0.2592711\n",
      "\tspeed: 0.0036s/iter; left time: 2.6721s\n",
      "\titers: 300, epoch: 10 | loss: 0.2252514\n",
      "\tspeed: 0.0037s/iter; left time: 2.3780s\n",
      "\titers: 400, epoch: 10 | loss: 0.2784326\n",
      "\tspeed: 0.0036s/iter; left time: 1.9825s\n",
      "\titers: 500, epoch: 10 | loss: 0.2037713\n",
      "\tspeed: 0.0038s/iter; left time: 1.7188s\n",
      "\titers: 600, epoch: 10 | loss: 0.2700133\n",
      "\tspeed: 0.0030s/iter; left time: 1.0540s\n",
      "\titers: 700, epoch: 10 | loss: 0.2217070\n",
      "\tspeed: 0.0028s/iter; left time: 0.7096s\n",
      "\titers: 800, epoch: 10 | loss: 0.2089878\n",
      "\tspeed: 0.0031s/iter; left time: 0.4724s\n",
      "\titers: 900, epoch: 10 | loss: 0.2326696\n",
      "\tspeed: 0.0036s/iter; left time: 0.1791s\n",
      "Epoch: 10 cost time: 3.6313533782958984\n",
      "Epoch: 10, Steps: 949 | Train Loss: 0.2520160 Vali Loss: 0.2202933 Test Loss: 0.2593228\n",
      "Validation loss decreased (0.220478 --> 0.220293).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__192_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 1) (8567, 1, 192, 1)\n",
      "test shape: (8567, 192, 1) (8567, 192, 1)\n",
      "mse:0.259322851896286, mae:0.3539797067642212\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast__192_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 30368\n",
      "val 4189\n",
      "test 8567\n",
      "\titers: 100, epoch: 1 | loss: 0.5552301\n",
      "\tspeed: 0.0078s/iter; left time: 73.5649s\n",
      "\titers: 200, epoch: 1 | loss: 0.3999768\n",
      "\tspeed: 0.0027s/iter; left time: 25.1967s\n",
      "\titers: 300, epoch: 1 | loss: 0.3347613\n",
      "\tspeed: 0.0025s/iter; left time: 23.2476s\n",
      "\titers: 400, epoch: 1 | loss: 0.2955336\n",
      "\tspeed: 0.0029s/iter; left time: 26.3696s\n",
      "\titers: 500, epoch: 1 | loss: 0.3451540\n",
      "\tspeed: 0.0028s/iter; left time: 24.8449s\n",
      "\titers: 600, epoch: 1 | loss: 0.3195068\n",
      "\tspeed: 0.0028s/iter; left time: 24.5040s\n",
      "\titers: 700, epoch: 1 | loss: 0.2926636\n",
      "\tspeed: 0.0028s/iter; left time: 24.1788s\n",
      "\titers: 800, epoch: 1 | loss: 0.3153944\n",
      "\tspeed: 0.0030s/iter; left time: 25.9992s\n",
      "\titers: 900, epoch: 1 | loss: 0.3265514\n",
      "\tspeed: 0.0029s/iter; left time: 24.8863s\n",
      "Epoch: 1 cost time: 3.2252583503723145\n",
      "Epoch: 1, Steps: 949 | Train Loss: 0.3667282 Vali Loss: 0.2460218 Test Loss: 0.2828923\n",
      "Validation loss decreased (inf --> 0.246022).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2856122\n",
      "\tspeed: 0.1893s/iter; left time: 1597.9746s\n",
      "\titers: 200, epoch: 2 | loss: 0.3025596\n",
      "\tspeed: 0.0030s/iter; left time: 25.2974s\n",
      "\titers: 300, epoch: 2 | loss: 0.2691732\n",
      "\tspeed: 0.0035s/iter; left time: 28.6217s\n",
      "\titers: 400, epoch: 2 | loss: 0.2766677\n",
      "\tspeed: 0.0031s/iter; left time: 25.1985s\n",
      "\titers: 500, epoch: 2 | loss: 0.2536259\n",
      "\tspeed: 0.0030s/iter; left time: 24.1604s\n",
      "\titers: 600, epoch: 2 | loss: 0.2440818\n",
      "\tspeed: 0.0029s/iter; left time: 22.8708s\n",
      "\titers: 700, epoch: 2 | loss: 0.2417667\n",
      "\tspeed: 0.0028s/iter; left time: 22.3434s\n",
      "\titers: 800, epoch: 2 | loss: 0.2706692\n",
      "\tspeed: 0.0030s/iter; left time: 23.3330s\n",
      "\titers: 900, epoch: 2 | loss: 0.2429156\n",
      "\tspeed: 0.0027s/iter; left time: 20.5215s\n",
      "Epoch: 2 cost time: 3.5241756439208984\n",
      "Epoch: 2, Steps: 949 | Train Loss: 0.2663273 Vali Loss: 0.2280378 Test Loss: 0.2663794\n",
      "Validation loss decreased (0.246022 --> 0.228038).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2199419\n",
      "\tspeed: 0.1931s/iter; left time: 1446.8187s\n",
      "\titers: 200, epoch: 3 | loss: 0.2816979\n",
      "\tspeed: 0.0030s/iter; left time: 21.8151s\n",
      "\titers: 300, epoch: 3 | loss: 0.2305073\n",
      "\tspeed: 0.0031s/iter; left time: 22.2736s\n",
      "\titers: 400, epoch: 3 | loss: 0.2840161\n",
      "\tspeed: 0.0034s/iter; left time: 24.2869s\n",
      "\titers: 500, epoch: 3 | loss: 0.2715158\n",
      "\tspeed: 0.0029s/iter; left time: 20.6133s\n",
      "\titers: 600, epoch: 3 | loss: 0.2396771\n",
      "\tspeed: 0.0032s/iter; left time: 22.2735s\n",
      "\titers: 700, epoch: 3 | loss: 0.1915396\n",
      "\tspeed: 0.0029s/iter; left time: 20.2083s\n",
      "\titers: 800, epoch: 3 | loss: 0.3450021\n",
      "\tspeed: 0.0029s/iter; left time: 19.4604s\n",
      "\titers: 900, epoch: 3 | loss: 0.3017751\n",
      "\tspeed: 0.0029s/iter; left time: 19.3758s\n",
      "Epoch: 3 cost time: 3.5685231685638428\n",
      "Epoch: 3, Steps: 949 | Train Loss: 0.2571845 Vali Loss: 0.2237130 Test Loss: 0.2624283\n",
      "Validation loss decreased (0.228038 --> 0.223713).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2255042\n",
      "\tspeed: 0.1984s/iter; left time: 1298.6097s\n",
      "\titers: 200, epoch: 4 | loss: 0.2693331\n",
      "\tspeed: 0.0049s/iter; left time: 31.6882s\n",
      "\titers: 300, epoch: 4 | loss: 0.2513584\n",
      "\tspeed: 0.0038s/iter; left time: 23.9600s\n",
      "\titers: 400, epoch: 4 | loss: 0.2693682\n",
      "\tspeed: 0.0035s/iter; left time: 22.1400s\n",
      "\titers: 500, epoch: 4 | loss: 0.3048391\n",
      "\tspeed: 0.0031s/iter; left time: 18.9139s\n",
      "\titers: 600, epoch: 4 | loss: 0.2267612\n",
      "\tspeed: 0.0033s/iter; left time: 19.8106s\n",
      "\titers: 700, epoch: 4 | loss: 0.2512320\n",
      "\tspeed: 0.0032s/iter; left time: 19.0638s\n",
      "\titers: 800, epoch: 4 | loss: 0.2053838\n",
      "\tspeed: 0.0034s/iter; left time: 19.6971s\n",
      "\titers: 900, epoch: 4 | loss: 0.3049618\n",
      "\tspeed: 0.0036s/iter; left time: 20.5723s\n",
      "Epoch: 4 cost time: 4.223850965499878\n",
      "Epoch: 4, Steps: 949 | Train Loss: 0.2543458 Vali Loss: 0.2220843 Test Loss: 0.2606810\n",
      "Validation loss decreased (0.223713 --> 0.222084).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2257618\n",
      "\tspeed: 0.1977s/iter; left time: 1106.2702s\n",
      "\titers: 200, epoch: 5 | loss: 0.2648610\n",
      "\tspeed: 0.0028s/iter; left time: 15.5519s\n",
      "\titers: 300, epoch: 5 | loss: 0.2395951\n",
      "\tspeed: 0.0034s/iter; left time: 18.5566s\n",
      "\titers: 400, epoch: 5 | loss: 0.2953400\n",
      "\tspeed: 0.0029s/iter; left time: 15.1504s\n",
      "\titers: 500, epoch: 5 | loss: 0.2505755\n",
      "\tspeed: 0.0035s/iter; left time: 18.1199s\n",
      "\titers: 600, epoch: 5 | loss: 0.2817691\n",
      "\tspeed: 0.0030s/iter; left time: 15.0524s\n",
      "\titers: 700, epoch: 5 | loss: 0.2517064\n",
      "\tspeed: 0.0033s/iter; left time: 16.4650s\n",
      "\titers: 800, epoch: 5 | loss: 0.2825764\n",
      "\tspeed: 0.0031s/iter; left time: 15.3467s\n",
      "\titers: 900, epoch: 5 | loss: 0.3195829\n",
      "\tspeed: 0.0030s/iter; left time: 14.2071s\n",
      "Epoch: 5 cost time: 3.6541056632995605\n",
      "Epoch: 5, Steps: 949 | Train Loss: 0.2530967 Vali Loss: 0.2207701 Test Loss: 0.2599485\n",
      "Validation loss decreased (0.222084 --> 0.220770).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2258046\n",
      "\tspeed: 0.1949s/iter; left time: 905.2802s\n",
      "\titers: 200, epoch: 6 | loss: 0.2621791\n",
      "\tspeed: 0.0029s/iter; left time: 13.2814s\n",
      "\titers: 300, epoch: 6 | loss: 0.1891151\n",
      "\tspeed: 0.0028s/iter; left time: 12.6466s\n",
      "\titers: 400, epoch: 6 | loss: 0.2708897\n",
      "\tspeed: 0.0030s/iter; left time: 13.1604s\n",
      "\titers: 500, epoch: 6 | loss: 0.2817280\n",
      "\tspeed: 0.0028s/iter; left time: 12.0610s\n",
      "\titers: 600, epoch: 6 | loss: 0.2232600\n",
      "\tspeed: 0.0031s/iter; left time: 12.8303s\n",
      "\titers: 700, epoch: 6 | loss: 0.2504275\n",
      "\tspeed: 0.0030s/iter; left time: 11.9990s\n",
      "\titers: 800, epoch: 6 | loss: 0.2538477\n",
      "\tspeed: 0.0031s/iter; left time: 12.0894s\n",
      "\titers: 900, epoch: 6 | loss: 0.2488746\n",
      "\tspeed: 0.0028s/iter; left time: 10.8753s\n",
      "Epoch: 6 cost time: 3.4194514751434326\n",
      "Epoch: 6, Steps: 949 | Train Loss: 0.2525270 Vali Loss: 0.2205346 Test Loss: 0.2596034\n",
      "Validation loss decreased (0.220770 --> 0.220535).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3121537\n",
      "\tspeed: 0.2006s/iter; left time: 741.6487s\n",
      "\titers: 200, epoch: 7 | loss: 0.2639518\n",
      "\tspeed: 0.0034s/iter; left time: 12.3356s\n",
      "\titers: 300, epoch: 7 | loss: 0.2368321\n",
      "\tspeed: 0.0039s/iter; left time: 13.7317s\n",
      "\titers: 400, epoch: 7 | loss: 0.2314333\n",
      "\tspeed: 0.0045s/iter; left time: 15.3787s\n",
      "\titers: 500, epoch: 7 | loss: 0.2384779\n",
      "\tspeed: 0.0043s/iter; left time: 14.0769s\n",
      "\titers: 600, epoch: 7 | loss: 0.2927498\n",
      "\tspeed: 0.0030s/iter; left time: 9.5359s\n",
      "\titers: 700, epoch: 7 | loss: 0.2332591\n",
      "\tspeed: 0.0031s/iter; left time: 9.5372s\n",
      "\titers: 800, epoch: 7 | loss: 0.2036439\n",
      "\tspeed: 0.0031s/iter; left time: 9.3553s\n",
      "\titers: 900, epoch: 7 | loss: 0.2456484\n",
      "\tspeed: 0.0032s/iter; left time: 9.2725s\n",
      "Epoch: 7 cost time: 3.9580018520355225\n",
      "Epoch: 7, Steps: 949 | Train Loss: 0.2522460 Vali Loss: 0.2208694 Test Loss: 0.2594388\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2437367\n",
      "\tspeed: 0.2120s/iter; left time: 582.4524s\n",
      "\titers: 200, epoch: 8 | loss: 0.2402960\n",
      "\tspeed: 0.0048s/iter; left time: 12.8066s\n",
      "\titers: 300, epoch: 8 | loss: 0.2335191\n",
      "\tspeed: 0.0042s/iter; left time: 10.6606s\n",
      "\titers: 400, epoch: 8 | loss: 0.2600810\n",
      "\tspeed: 0.0038s/iter; left time: 9.4131s\n",
      "\titers: 500, epoch: 8 | loss: 0.2389963\n",
      "\tspeed: 0.0043s/iter; left time: 10.1523s\n",
      "\titers: 600, epoch: 8 | loss: 0.2574480\n",
      "\tspeed: 0.0038s/iter; left time: 8.5764s\n",
      "\titers: 700, epoch: 8 | loss: 0.2377409\n",
      "\tspeed: 0.0036s/iter; left time: 7.7859s\n",
      "\titers: 800, epoch: 8 | loss: 0.2872743\n",
      "\tspeed: 0.0035s/iter; left time: 7.0663s\n",
      "\titers: 900, epoch: 8 | loss: 0.2535925\n",
      "\tspeed: 0.0037s/iter; left time: 7.1175s\n",
      "Epoch: 8 cost time: 4.421080827713013\n",
      "Epoch: 8, Steps: 949 | Train Loss: 0.2521039 Vali Loss: 0.2202201 Test Loss: 0.2593598\n",
      "Validation loss decreased (0.220535 --> 0.220220).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2838202\n",
      "\tspeed: 0.2026s/iter; left time: 364.4330s\n",
      "\titers: 200, epoch: 9 | loss: 0.2618224\n",
      "\tspeed: 0.0033s/iter; left time: 5.5944s\n",
      "\titers: 300, epoch: 9 | loss: 0.2910765\n",
      "\tspeed: 0.0032s/iter; left time: 5.0745s\n",
      "\titers: 400, epoch: 9 | loss: 0.2638137\n",
      "\tspeed: 0.0037s/iter; left time: 5.5262s\n",
      "\titers: 500, epoch: 9 | loss: 0.2693705\n",
      "\tspeed: 0.0033s/iter; left time: 4.6561s\n",
      "\titers: 600, epoch: 9 | loss: 0.2742593\n",
      "\tspeed: 0.0030s/iter; left time: 3.8641s\n",
      "\titers: 700, epoch: 9 | loss: 0.2178579\n",
      "\tspeed: 0.0031s/iter; left time: 3.7618s\n",
      "\titers: 800, epoch: 9 | loss: 0.2599862\n",
      "\tspeed: 0.0032s/iter; left time: 3.4627s\n",
      "\titers: 900, epoch: 9 | loss: 0.2258805\n",
      "\tspeed: 0.0029s/iter; left time: 2.9287s\n",
      "Epoch: 9 cost time: 3.655315637588501\n",
      "Epoch: 9, Steps: 949 | Train Loss: 0.2520334 Vali Loss: 0.2199908 Test Loss: 0.2593210\n",
      "Validation loss decreased (0.220220 --> 0.219991).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2219876\n",
      "\tspeed: 0.2103s/iter; left time: 178.7138s\n",
      "\titers: 200, epoch: 10 | loss: 0.2538407\n",
      "\tspeed: 0.0038s/iter; left time: 2.8157s\n",
      "\titers: 300, epoch: 10 | loss: 0.2762253\n",
      "\tspeed: 0.0037s/iter; left time: 2.3739s\n",
      "\titers: 400, epoch: 10 | loss: 0.2459940\n",
      "\tspeed: 0.0029s/iter; left time: 1.5794s\n",
      "\titers: 500, epoch: 10 | loss: 0.2523862\n",
      "\tspeed: 0.0028s/iter; left time: 1.2755s\n",
      "\titers: 600, epoch: 10 | loss: 0.2385063\n",
      "\tspeed: 0.0032s/iter; left time: 1.1241s\n",
      "\titers: 700, epoch: 10 | loss: 0.2287172\n",
      "\tspeed: 0.0033s/iter; left time: 0.8185s\n",
      "\titers: 800, epoch: 10 | loss: 0.3955850\n",
      "\tspeed: 0.0029s/iter; left time: 0.4281s\n",
      "\titers: 900, epoch: 10 | loss: 0.2642301\n",
      "\tspeed: 0.0028s/iter; left time: 0.1375s\n",
      "Epoch: 10 cost time: 3.7507097721099854\n",
      "Epoch: 10, Steps: 949 | Train Loss: 0.2519986 Vali Loss: 0.2206360 Test Loss: 0.2593017\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast__192_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 8567\n",
      "test shape: (8567, 1, 192, 1) (8567, 1, 192, 1)\n",
      "test shape: (8567, 192, 1) (8567, 192, 1)\n",
      "mse:0.25932103395462036, mae:0.3539370596408844\n",
      "\n",
      "Extracted Part: long_term_forecast__192_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_0\n",
      "Extracted Part: long_term_forecast__192_DE_load_actual_entsoe_transparency_DLinear_custom_ftS_sl96_ll48_pl192_dm512_nh8_el2_dl5_df2048_fc5_ebtimeF_dtTrue_Exp_1\n",
      "Results saved to: transformer_results_averaged_over_iterations.txt\n"
     ]
    }
   ],
   "source": [
    "# List of columns and prediction lengths for the grid search\n",
    "columns = [\"DE_load_actual_entsoe_transparency\", \"DE_solar_generation_actual\", \"DE_wind_generation_actual\"]\n",
    "prediction_lengths = [\"24\", \"48\", \"96\", \"192\"]\n",
    "for column in columns:\n",
    "    for pred_len in prediction_lengths:\n",
    "        # Define the script arguments as a list\n",
    "        model_id = f\"_{pred_len}_{column}\"  # Create the model_id\n",
    "        script_arguments = [\n",
    "            \"--task_name\", \"long_term_forecast\",\n",
    "            \"--is_training\", \"1\",\n",
    "            \"--root_path\", \"../../../01_datasets/\",\n",
    "            \"--data_path\", \"df_most_important_columns.csv\",\n",
    "            \"--model_id\", model_id,\n",
    "            \"--model\", \"DLinear\",\n",
    "            \"--data\", \"custom\",\n",
    "            \"--features\", \"S\",\n",
    "            \"--target\", str(column),\n",
    "            \"--seq_len\", \"96\",\n",
    "            \"--label_len\", \"48\",\n",
    "            \"--pred_len\", pred_len,\n",
    "            \"--e_layers\", \"2\",\n",
    "            \"--d_layers\", \"5\",\n",
    "            \"--factor\", \"5\",\n",
    "            \"--enc_in\", \"1\",\n",
    "            \"--dec_in\", \"1\",\n",
    "            \"--c_out\", \"1\",\n",
    "            \"--des\", \"Exp\",\n",
    "            \"--itr\", \"2\"\n",
    "        ]\n",
    "\n",
    "        script_output = run_and_capture_script_output(script_path, script_arguments)\n",
    "\n",
    "        print(\"Captured Output:\")\n",
    "        print(script_output)\n",
    "\n",
    "        # Extract and save the prints related to the settings variable\n",
    "        settings_prints = extract_settings_prints(script_output.splitlines())\n",
    "\n",
    "        matched_patterns = pattern_matching(settings_prints)\n",
    "\n",
    "        summarize_results(matched_patterns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
